<html>
    <head>
        <meta charset="utf-8">
        
            <script src="lib/bindings/utils.js"></script>
            <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/dist/vis-network.min.css" integrity="sha512-WgxfT5LWjfszlPHXRmBWHkV2eceiWTOBvrKCNbdgDYTHrT2AeLCGbF4sZlZw3UMN3WtL0tGUoIAKsu8mllg/XA==" crossorigin="anonymous" referrerpolicy="no-referrer" />
            <script src="https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/vis-network.min.js" integrity="sha512-LnvoEWDFrqGHlHmDD2101OrLcbsfkrzoSpvtSQtxK3RMnRV0eOkhhBN2dXHKRrUU8p2DGRTk35n4O8nWSVe1mQ==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
            
        
<center>
<h1></h1>
</center>

<!-- <link rel="stylesheet" href="../node_modules/vis/dist/vis.min.css" type="text/css" />
<script type="text/javascript" src="../node_modules/vis/dist/vis.js"> </script>-->
        <link
          href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/css/bootstrap.min.css"
          rel="stylesheet"
          integrity="sha384-eOJMYsd53ii+scO/bJGFsiCZc+5NDVN2yr8+0RDqr0Ql0h+rP48ckxlpbzKgwra6"
          crossorigin="anonymous"
        />
        <script
          src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/js/bootstrap.bundle.min.js"
          integrity="sha384-JEW9xMcG8R+pH31jmWH6WWP0WintQrMb4s7ZOdauHnUtxwoG2vI5DkLtS3qm9Ekf"
          crossorigin="anonymous"
        ></script>


        <center>
          <h1></h1>
        </center>
        <style type="text/css">

             #mynetwork {
                 width: 100%;
                 height: 600px;
                 background-color: #ffffff;
                 border: 1px solid lightgray;
                 position: relative;
                 float: left;
             }

             
             #loadingBar {
                 position:absolute;
                 top:0px;
                 left:0px;
                 width: 100%;
                 height: 600px;
                 background-color:rgba(200,200,200,0.8);
                 -webkit-transition: all 0.5s ease;
                 -moz-transition: all 0.5s ease;
                 -ms-transition: all 0.5s ease;
                 -o-transition: all 0.5s ease;
                 transition: all 0.5s ease;
                 opacity:1;
             }

             #bar {
                 position:absolute;
                 top:0px;
                 left:0px;
                 width:20px;
                 height:20px;
                 margin:auto auto auto auto;
                 border-radius:11px;
                 border:2px solid rgba(30,30,30,0.05);
                 background: rgb(0, 173, 246); /* Old browsers */
                 box-shadow: 2px 0px 4px rgba(0,0,0,0.4);
             }

             #border {
                 position:absolute;
                 top:10px;
                 left:10px;
                 width:500px;
                 height:23px;
                 margin:auto auto auto auto;
                 box-shadow: 0px 0px 4px rgba(0,0,0,0.2);
                 border-radius:10px;
             }

             #text {
                 position:absolute;
                 top:8px;
                 left:530px;
                 width:30px;
                 height:50px;
                 margin:auto auto auto auto;
                 font-size:22px;
                 color: #000000;
             }

             div.outerBorder {
                 position:relative;
                 top:400px;
                 width:600px;
                 height:44px;
                 margin:auto auto auto auto;
                 border:8px solid rgba(0,0,0,0.1);
                 background: rgb(252,252,252); /* Old browsers */
                 background: -moz-linear-gradient(top,  rgba(252,252,252,1) 0%, rgba(237,237,237,1) 100%); /* FF3.6+ */
                 background: -webkit-gradient(linear, left top, left bottom, color-stop(0%,rgba(252,252,252,1)), color-stop(100%,rgba(237,237,237,1))); /* Chrome,Safari4+ */
                 background: -webkit-linear-gradient(top,  rgba(252,252,252,1) 0%,rgba(237,237,237,1) 100%); /* Chrome10+,Safari5.1+ */
                 background: -o-linear-gradient(top,  rgba(252,252,252,1) 0%,rgba(237,237,237,1) 100%); /* Opera 11.10+ */
                 background: -ms-linear-gradient(top,  rgba(252,252,252,1) 0%,rgba(237,237,237,1) 100%); /* IE10+ */
                 background: linear-gradient(to bottom,  rgba(252,252,252,1) 0%,rgba(237,237,237,1) 100%); /* W3C */
                 filter: progid:DXImageTransform.Microsoft.gradient( startColorstr='#fcfcfc', endColorstr='#ededed',GradientType=0 ); /* IE6-9 */
                 border-radius:72px;
                 box-shadow: 0px 0px 10px rgba(0,0,0,0.2);
             }
             

             

             
        </style>
    </head>


    <body>
        <div class="card" style="width: 100%">
            
            
            <div id="mynetwork" class="card-body"></div>
        </div>

        
            <div id="loadingBar">
              <div class="outerBorder">
                <div id="text">0%</div>
                <div id="border">
                  <div id="bar"></div>
                </div>
              </div>
            </div>
        
        

        <script type="text/javascript">

              // initialize global variables.
              var edges;
              var nodes;
              var allNodes;
              var allEdges;
              var nodeColors;
              var originalNodes;
              var network;
              var container;
              var options, data;
              var filter = {
                  item : '',
                  property : '',
                  value : []
              };

              

              

              // This method is responsible for drawing the graph, returns the drawn network
              function drawGraph() {
                  var container = document.getElementById('mynetwork');

                  

                  // parsing and collecting nodes and edges from the python
                  nodes = new vis.DataSet([{"color": "#97c2fc", "description": "\"\u6570\u636e\u683c\u5f0f refers to the format in which data is structured and organized within a dataset, crucial for model parameter tuning.\"", "entity_type": "\"CONCEPT\"", "id": "\"\u6570\u636e\u683c\u5f0f\"", "label": "\"\u6570\u636e\u683c\u5f0f\"", "shape": "dot", "size": 10, "source_id": "chunk-6e8e06e2596da07feeb6804400bd7f39"}, {"color": "#97c2fc", "description": "\"\u6a21\u578b\u53c2\u6570 encompasses various settings and configurations used when training machine learning models.\"", "entity_type": "\"CONCEPT\"", "id": "\"\u6a21\u578b\u53c2\u6570\"", "label": "\"\u6a21\u578b\u53c2\u6570\"", "shape": "dot", "size": 10, "source_id": "chunk-6e8e06e2596da07feeb6804400bd7f39"}, {"color": "#97c2fc", "description": "\"\u6587\u672c\u6570\u636e\u96c6\u662f\u7c7b\u4f3c\u4e8eCommon Crawl\u7684\u5927\u89c4\u6a21\u7f51\u9875\u6587\u672c\u96c6\u5408\uff0c\u53ef\u4ee5\u7528\u4e8e\u8bed\u8a00\u6a21\u578b\u7684\u8bad\u7ec3\u3002\"", "entity_type": "\"ORGANIZATION\"", "id": "\"\u6587\u672c\u6570\u636e\u96c6\"", "label": "\"\u6587\u672c\u6570\u636e\u96c6\"", "shape": "dot", "size": 10, "source_id": "chunk-c9c11d3ee2bf51fe807387d8004e7aec"}, {"color": "#97c2fc", "description": "\"\u6587\u672c\u6570\u636e\u96c6\u53ef\u4ee5\u4e3a\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e30\u5bcc\u7684\u7f51\u9875\u6587\u672c\u7528\u4e8e\u8bad\u7ec3.\"", "entity_type": "\"UNKNOWN\"", "id": "\"\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\"", "label": "\"\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\"", "shape": "dot", "size": 10, "source_id": "chunk-c9c11d3ee2bf51fe807387d8004e7aec"}, {"color": "#97c2fc", "description": "\"\u9886\u57df\u7279\u5b9a\u6570\u636e\u96c6\u662f\u6307\u6839\u636e\u5177\u4f53\u4efb\u52a1\u548c\u5e94\u7528\u76ee\u6807\u4e13\u95e8\u6311\u9009\u7684\u6587\u672c\u6570\u636e\u96c6\u5408\uff0c\u4f8b\u5982\u533b\u5b66\u6587\u732e\u6216\u6cd5\u5f8b\u6587\u4e66\u7b49\u3002\"", "entity_type": "\"ORGANIZATION\"", "id": "\"\u9886\u57df\u7279\u5b9a\u6570\u636e\u96c6\"", "label": "\"\u9886\u57df\u7279\u5b9a\u6570\u636e\u96c6\"", "shape": "dot", "size": 10, "source_id": "chunk-c9c11d3ee2bf51fe807387d8004e7aec"}, {"color": "#97c2fc", "description": "\"BookCorpus\u662f\u4e00\u4e2a\u5305\u542b\u4e86\u5927\u91cf\u56fe\u4e66\u6587\u672c\u7684\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u8bed\u8a00\u6a21\u578b\u7684\u8bad\u7ec3\uff0c\u6db5\u76d6\u4e86\u5e7f\u6cdb\u7684\u4e3b\u9898\u548c\u9886\u57df\u3002\"", "entity_type": "\"ORGANIZATION\"", "id": "\"BOOKCORPUS\"", "label": "\"BOOKCORPUS\"", "shape": "dot", "size": 10, "source_id": "chunk-c9c11d3ee2bf51fe807387d8004e7aec"}, {"color": "#97c2fc", "description": "\"\u65b0\u95fb\u6587\u7ae0\u662f\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u4e2d\u5e38\u7528\u7684\u4e00\u79cd\u6570\u636e\u7c7b\u578b\uff0c\u53ef\u4ee5\u4ece\u591a\u4e2a\u6765\u6e90\u6536\u96c6\u6765\u6784\u5efa\u8bad\u7ec3\u96c6\u3002\"", "entity_type": "\"EVENT\"", "id": "\"\u65b0\u95fb\u6587\u7ae0\"", "label": "\"\u65b0\u95fb\u6587\u7ae0\"", "shape": "dot", "size": 10, "source_id": "chunk-c9c11d3ee2bf51fe807387d8004e7aec"}, {"color": "#97c2fc", "description": "\"Sam Rivera is a member of a team working on communicating with an unknown intelligence, showing a mix of awe and anxiety.\"", "entity_type": "\"PERSON\"", "id": "\"SAM RIVERA\"", "label": "\"SAM RIVERA\"", "shape": "dot", "size": 10, "source_id": "chunk-c9c11d3ee2bf51fe807387d8004e7aec"}, {"color": "#97c2fc", "description": "\"Sam Rivera works on communicating with an unknown intelligence, dealing with the profound implications for humanity.\"", "entity_type": "\"UNKNOWN\"", "id": "\"INTELLIGENCE\"", "label": "\"INTELLIGENCE\"", "shape": "dot", "size": 10, "source_id": "chunk-c9c11d3ee2bf51fe807387d8004e7aec"}, {"color": "#97c2fc", "description": "\"Sam Rivera \u548c Alex \u90fd\u662f\u8be5\u56e2\u961f\u7684\u6210\u5458\uff0c\u8d1f\u8d23\u4e0e\u672a\u77e5\u667a\u80fd\u8fdb\u884c\u6c9f\u901a\u3002\"", "entity_type": "\"ORGANIZATION\"", "id": "\"\u56e2\u961f\"", "label": "\"\u56e2\u961f\"", "shape": "dot", "size": 10, "source_id": "chunk-c9c11d3ee2bf51fe807387d8004e7aec"}, {"color": "#97c2fc", "description": "\"\u56e2\u961f\u7684\u4efb\u52a1\u662f\u9996\u6b21\u63a5\u89e6\u672a\u77e5\u667a\u80fd\uff0c\u5e76\u4e14\u8fd9\u9879\u4efb\u52a1\u5177\u6709\u91cd\u5927\u7684\u5386\u53f2\u610f\u4e49\u548c\u5b87\u5b99\u91cd\u8981\u6027\u3002\"", "entity_type": "\"EVENT\"", "id": "\"\u4efb\u52a1\"", "label": "\"\u4efb\u52a1\"", "shape": "dot", "size": 10, "source_id": "chunk-c9c11d3ee2bf51fe807387d8004e7aec"}, {"color": "#97c2fc", "description": "\"Alex is the leader of a team attempting first contact with an unknown intelligence, acknowledging the significance of their task.\"", "entity_type": "\"PERSON\"", "id": "\"ALEX\"", "label": "\"ALEX\"", "shape": "dot", "size": 10, "source_id": "chunk-c9c11d3ee2bf51fe807387d8004e7aec"}, {"color": "#97c2fc", "description": "\"A potential historic moment where humanity attempts to communicate with an unknown intelligence for the first time.\"\u003cSEP\u003e\"Alex is leading a team in making first contact with an unknown intelligence, recognizing its historical importance.\"", "entity_type": "\"EVENT\"", "id": "\"FIRST CONTACT\"", "label": "\"FIRST CONTACT\"", "shape": "dot", "size": 10, "source_id": "chunk-c9c11d3ee2bf51fe807387d8004e7aec\u003cSEP\u003echunk-2ca6daea6a4f0f4a4352f8eba1bc3e4e"}, {"color": "#97c2fc", "description": "\"The entity or intelligence attempting first contact, showing respect and a willingness to learn new rules.\"", "entity_type": "\"CONCEPT\"", "id": "\"UNKNOWN INTELLIGENCE\"", "label": "\"UNKNOWN INTELLIGENCE\"", "shape": "dot", "size": 10, "source_id": "chunk-2ca6daea6a4f0f4a4352f8eba1bc3e4e"}, {"color": "#97c2fc", "description": "\"\u6e05\u534e\u5927\u5b66\u662f\u4e3e\u529e\u5927\u6a21\u578b\u516c\u5f00\u8bfe\u7684\u673a\u6784\uff0c\u63d0\u4f9b\u5173\u4e8e\u81ea\u7136\u8bed\u8a00\u5904\u7406\u3001\u795e\u7ecf\u7f51\u7edc\u548cTransformer\u57fa\u7840\u7b49\u8bfe\u7a0b\u3002\"", "entity_type": "\"ORGANIZATION\"", "id": "\"\u6e05\u534e\u5927\u5b66\"", "label": "\"\u6e05\u534e\u5927\u5b66\"", "shape": "dot", "size": 10, "source_id": "chunk-b598bb5c01c68c8a357b43ff47895be0"}, {"color": "#97c2fc", "description": "\"NLP\u0026\u5927\u6a21\u578b\u57fa\u7840\u662f\u4e00\u95e8\u5173\u4e8e\u81ea\u7136\u8bed\u8a00\u5904\u7406\u548c\u5927\u578b\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u57fa\u7840\u77e5\u8bc6\u7684\u8bfe\u7a0b\u3002\"", "entity_type": "\"EVENT\"", "id": "\"NLP\u0026\u5927\u6a21\u578b\u57fa\u7840\"", "label": "\"NLP\u0026\u5927\u6a21\u578b\u57fa\u7840\"", "shape": "dot", "size": 10, "source_id": "chunk-b598bb5c01c68c8a357b43ff47895be0"}, {"color": "#97c2fc", "description": "\"NLP\u57fa\u7840\u8bfe\u7a0b\u4ecb\u7ecd\u81ea\u7136\u8bed\u8a00\u5904\u7406\u7684\u57fa\u672c\u6982\u5ff5\u4e0e\u6280\u672f\u3002\"", "entity_type": "\"EVENT\"", "id": "\"NLP\u57fa\u7840\"", "label": "\"NLP\u57fa\u7840\"", "shape": "dot", "size": 10, "source_id": "chunk-b598bb5c01c68c8a357b43ff47895be0"}, {"color": "#97c2fc", "description": "\"\u6df1\u5ea6\u5b66\u4e60\u57fa\u7840\u8bfe\u7a0b\u8bb2\u89e3\u7528\u4e8eNLP\u4efb\u52a1\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u548c\u7b97\u6cd5\u7684\u57fa\u7840\u77e5\u8bc6\u3002\"", "entity_type": "\"EVENT\"", "id": "\"\u6df1\u5ea6\u5b66\u4e60\u57fa\u7840\"", "label": "\"\u6df1\u5ea6\u5b66\u4e60\u57fa\u7840\"", "shape": "dot", "size": 10, "source_id": "chunk-b598bb5c01c68c8a357b43ff47895be0"}, {"color": "#97c2fc", "description": "\"\u4ecb\u7ecd\u9ad8\u6548\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6280\u672f\uff0c\u4f8b\u5982\u51cf\u5c11\u8ba1\u7b97\u91cf\u548c\u63d0\u9ad8\u54cd\u5e94\u901f\u5ea6\u3002\"", "entity_type": "\"EVENT\"", "id": "\"\u9ad8\u6548\u63a8\u7406\"", "label": "\"\u9ad8\u6548\u63a8\u7406\"", "shape": "dot", "size": 10, "source_id": "chunk-b598bb5c01c68c8a357b43ff47895be0"}, {"color": "#97c2fc", "description": "\"\u8ba8\u8bba\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6280\u672f\u5728\u6784\u5efa\u667a\u80fd\u5bf9\u8bdd\u7cfb\u7edf\u4e2d\u7684\u5e94\u7528\u3002\"", "entity_type": "\"EVENT\"", "id": "\"NLP\u4e0e\u5bf9\u8bdd\u7cfb\u7edf\"", "label": "\"NLP\u4e0e\u5bf9\u8bdd\u7cfb\u7edf\"", "shape": "dot", "size": 10, "source_id": "chunk-b598bb5c01c68c8a357b43ff47895be0"}, {"color": "#97c2fc", "description": "\"OpenBMB\u662f\u4e00\u4e2a\u8ba9\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u6a21\u578b\u666e\u53ca\u5316\u7684\u9879\u76ee\u6216\u5e73\u53f0\uff0c\u94fe\u63a5\u63d0\u4f9b\u4e86\u66f4\u591a\u793e\u533a\u8d44\u6e90\u4e0e\u8bfe\u7a0b\u8d44\u6599\u3002\"", "entity_type": "\"ORGANIZATION\"", "id": "\"OPENBMB\"", "label": "\"OPENBMB\"", "shape": "dot", "size": 10, "source_id": "chunk-b598bb5c01c68c8a357b43ff47895be0"}, {"color": "#97c2fc", "description": "\"\u9ad8\u6548\u8bad\u7ec3\u53ca\u6a21\u578b\u538b\u7f29\u8bfe\u7a0b\u6db5\u76d6\u4e86\u5982\u4f55\u6709\u6548\u7387\u5730\u8bad\u7ec3\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u6a21\u578b\u4ee5\u53ca\u51cf\u5c11\u5176\u5927\u5c0f\u7684\u65b9\u6cd5\u3002\"", "entity_type": "\"EVENT\"", "id": "\"\u9ad8\u6548\u8bad\u7ec3\u0026\u6a21\u578b\u538b\u7f29\"", "label": "\"\u9ad8\u6548\u8bad\u7ec3\u0026\u6a21\u578b\u538b\u7f29\"", "shape": "dot", "size": 10, "source_id": "chunk-b598bb5c01c68c8a357b43ff47895be0"}, {"color": "#97c2fc", "description": "\"Prompt Tuning\u548cDelta Tuning\u662f\u4e00\u7cfb\u5217\u6280\u672f\uff0c\u7528\u4e8e\u8c03\u6574\u548c\u4f18\u5316\u5927\u6a21\u578b\u7684\u8868\u73b0\u4ee5\u9002\u5e94\u7279\u5b9a\u4efb\u52a1\u6216\u573a\u666f\u3002\"\u003cSEP\u003e\"\u63a2\u8ba8\u5982\u4f55\u4f18\u5316\u9884\u8bad\u7ec3\u6a21\u578b\u4ee5\u9002\u5e94\u7279\u5b9a\u4efb\u52a1\u7684\u6280\u672f\u3002\"", "entity_type": "\"EVENT\"", "id": "\"PROMPT TUNING \u0026 DELTA TUNING\"", "label": "\"PROMPT TUNING \u0026 DELTA TUNING\"", "shape": "dot", "size": 10, "source_id": "chunk-b598bb5c01c68c8a357b43ff47895be0"}, {"color": "#97c2fc", "description": "\"\u5c55\u793a\u5982\u4f55\u5229\u7528NLP\u6a21\u578b\u8fdb\u884c\u9ad8\u8d28\u91cf\u7684\u6587\u672c\u751f\u6210\u3002\"", "entity_type": "\"EVENT\"", "id": "\"\u6587\u672c\u751f\u6210\"", "label": "\"\u6587\u672c\u751f\u6210\"", "shape": "dot", "size": 10, "source_id": "chunk-b598bb5c01c68c8a357b43ff47895be0"}, {"color": "#97c2fc", "description": "\"The n-2 layer scheme refers to a method of fixing n-2 layers on a GPU and using the remaining 2 layers for scheduling, aimed at reducing loading parameter overhead.\"", "entity_type": "\"CONCEPT\"", "id": "\"N-2\u5c42\u65b9\u6848\"", "label": "\"N-2\u5c42\u65b9\u6848\"", "shape": "dot", "size": 10, "source_id": "chunk-cb8cae2c05a476558bae2291e8b82de7"}, {"color": "#97c2fc", "description": "\"A GPU (Graphics Processing Unit) is used in this context as a hardware component for running deep learning models with optimized performance.\"", "entity_type": "\"TECHNOLOGY\"", "id": "\"GPU\"", "label": "\"GPU\"", "shape": "dot", "size": 10, "source_id": "chunk-cb8cae2c05a476558bae2291e8b82de7"}, {"color": "#97c2fc", "description": "\"Deep learning models refer to complex neural network architectures used for various machine learning tasks such as image recognition, natural language processing, etc.\"", "entity_type": "\"CONCEPT\"", "id": "\"DEEP LEARNING MODELS\"", "label": "\"DEEP LEARNING MODELS\"", "shape": "dot", "size": 10, "source_id": "chunk-cb8cae2c05a476558bae2291e8b82de7"}, {"color": "#97c2fc", "description": "\"Layer scheduling is an approach in deep learning where different layers of a neural network are scheduled for execution based on resource availability and optimization goals.\"", "entity_type": "\"CONCEPT\"", "id": "\"LAYER SCHEDULING\"", "label": "\"LAYER SCHEDULING\"", "shape": "dot", "size": 10, "source_id": "chunk-cb8cae2c05a476558bae2291e8b82de7"}, {"color": "#97c2fc", "description": "\"BMInf package refers to a tool or library developed to facilitate the execution of large-scale models on limited hardware resources such as GTX1060 GPUs.\"", "entity_type": "\"ORGANIZATION\"", "id": "\"BMINF\u5305\"", "label": "\"BMINF\u5305\"", "shape": "dot", "size": 10, "source_id": "chunk-cb8cae2c05a476558bae2291e8b82de7"}, {"color": "#97c2fc", "description": "\"A GTX1060 is a specific model of GPU designed for gaming and deep learning applications.\"", "entity_type": "\"TECHNOLOGY\"", "id": "\"GTX1060\"", "label": "\"GTX1060\"", "shape": "dot", "size": 10, "source_id": "chunk-cb8cae2c05a476558bae2291e8b82de7"}, {"color": "#97c2fc", "description": "\"Loading parameter overhead refers to the time and computational resources required to load model parameters into memory before executing a deep learning model.\"", "entity_type": "\"TECHNOLOGY\"", "id": "\"LOADING PARAMETER OVERHEAD\"", "label": "\"LOADING PARAMETER OVERHEAD\"", "shape": "dot", "size": 10, "source_id": "chunk-cb8cae2c05a476558bae2291e8b82de7"}, {"color": "#97c2fc", "description": "\"Skip-gram is a method in word embedding models that predicts context words from a central word.\"", "entity_type": "\"CONCEPT\"", "id": "\"SKIP-GRAM\"", "label": "\"SKIP-GRAM\"", "shape": "dot", "size": 10, "source_id": "chunk-a5bc016656f4a03d7267cf14d747240b"}, {"color": "#97c2fc", "description": "\"Skip-gram models predict context words from a central word, while CBOW predicts the central word based on its context.\"", "entity_type": "\"UNKNOWN\"", "id": "\"CBOW\"", "label": "\"CBOW\"", "shape": "dot", "size": 10, "source_id": "chunk-a5bc016656f4a03d7267cf14d747240b"}, {"color": "#97c2fc", "description": "\"Word2Vec is a toolkit for computing vector representations of words based on neural networks.\"\u003cSEP\u003e\"Word2Vec\u662f\u4e00\u79cd\u8bcd\u5411\u91cf\u751f\u6210\u5de5\u5177\uff0c\u7528\u6765\u8ba1\u7b97\u6587\u672c\u4e2d\u8bcd\u8bed\u7684\u5206\u5e03\u5f0f\u8868\u793a\u3002\"", "entity_type": "\"MODEL\"", "id": "\"WORD2VEC\"", "label": "\"WORD2VEC\"", "shape": "dot", "size": 10, "source_id": "chunk-a5bc016656f4a03d7267cf14d747240b\u003cSEP\u003echunk-83f4aea6a8402d9c9f99736cbb2135d4"}, {"color": "#97c2fc", "description": "\"The Transformer architecture enables models to reach parameters in the tens of millions.\"\u003cSEP\u003e\"The Transformer is an advanced deep learning architecture that has replaced shallow RNNs for various natural language tasks.\"\u003cSEP\u003e\"Transformer\u662f\u4e00\u79cd\u57fa\u4e8e\u6ce8\u610f\u529b\u673a\u5236\u7684\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\uff0c\u5e7f\u6cdb\u5e94\u7528\u4e8e\u5e8f\u5217\u5efa\u6a21\u4efb\u52a1\u4e2d\u3002\"\u003cSEP\u003e\"Transformer is a type of neural network architecture that outperforms both CNN and RNN in terms of overall task effectiveness.\"", "entity_type": "\"TECHNOLOGY\"", "id": "\"TRANSFORMER\"", "label": "\"TRANSFORMER\"", "shape": "dot", "size": 10, "source_id": "chunk-83f4aea6a8402d9c9f99736cbb2135d4\u003cSEP\u003echunk-bcf7c68cd902ea546596acd01bf558cf\u003cSEP\u003echunk-a5bc016656f4a03d7267cf14d747240b\u003cSEP\u003echunk-5474069465781f541726c53600f1b4f7"}, {"color": "#97c2fc", "description": "\"A transformer-based model that heavily relies on the dropout technique to prevent overfitting.\"\u003cSEP\u003e\"BERT is a pre-training approach for language models using masked language modeling and next sentence prediction tasks.\"\u003cSEP\u003e\"BERT\u662f\u4e00\u79cd\u9884\u8bad\u7ec3\u7684\u8bed\u8a00\u8868\u793a\u6a21\u578b\uff0c\u4e3b\u8981\u7528\u4e8e\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1\u3002\"\u003cSEP\u003e\"The Transformer architecture, particularly its attention mechanism, is fundamental to the development of BERT.\"", "entity_type": "\"CONCEPT\"", "id": "\"BERT\"", "label": "\"BERT\"", "shape": "dot", "size": 10, "source_id": "chunk-8e8cfc5ae7b8cf839dfcb6baedbbf29d\u003cSEP\u003echunk-a5bc016656f4a03d7267cf14d747240b\u003cSEP\u003echunk-9c1eb6ec6cc7c8742be47f032e1488fc\u003cSEP\u003echunk-83f4aea6a8402d9c9f99736cbb2135d4"}, {"color": "#97c2fc", "description": "\"MOE builds upon or complements the Transformer architecture to achieve even larger parameter scales.\"", "entity_type": "\"UNKNOWN\"", "id": "\"MOE\"", "label": "\"MOE\"", "shape": "dot", "size": 10, "source_id": "chunk-5474069465781f541726c53600f1b4f7"}, {"color": "#97c2fc", "description": "\"\u5927\u8bed\u8a00\u6a21\u578b\u662f\u6307\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u7684\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u5e38\u7528\u4e8e\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1\u3002\"", "entity_type": "\"CONCEPT\"", "id": "\"\u5927\u8bed\u8a00\u6a21\u578b\"", "label": "\"\u5927\u8bed\u8a00\u6a21\u578b\"", "shape": "dot", "size": 10, "source_id": "chunk-83f4aea6a8402d9c9f99736cbb2135d4"}, {"color": "#97c2fc", "description": "\"Transformer\u6a21\u578b\u9996\u6b21\u5f15\u5165\u4e86\u6ce8\u610f\u529b\u673a\u5236\u6765\u6539\u8fdb\u6587\u672c\u7406\u89e3\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u3002\"\u003cSEP\u003e\"\u6ce8\u610f\u529b\u673a\u5236\u662f\u6307\u5728\u5904\u7406\u957f\u6587\u672c\u65f6\uff0c\u6a21\u578b\u80fd\u591f\u5173\u6ce8\u8f93\u5165\u4e2d\u7684\u91cd\u8981\u90e8\u5206\u3002\"", "entity_type": "\"CONCEPT\"", "id": "\"\u6ce8\u610f\u529b\u673a\u5236\"", "label": "\"\u6ce8\u610f\u529b\u673a\u5236\"", "shape": "dot", "size": 10, "source_id": "chunk-83f4aea6a8402d9c9f99736cbb2135d4\u003cSEP\u003echunk-b3e463d24adf84b28a5376fc9c10716b"}, {"color": "#97c2fc", "description": "\"CNN (Convolutional Neural Network) is another type of neural network that slightly outperforms RNN but is less effective compared to Transformer.\"", "entity_type": "\"TECHNOLOGY\"", "id": "\"CNN\"", "label": "\"CNN\"", "shape": "dot", "size": 10, "source_id": "chunk-bcf7c68cd902ea546596acd01bf558cf"}, {"color": "#97c2fc", "description": "\"ELMo uses RNNs to generate context-specific embeddings for word predictions in natural language processing tasks.\"\u003cSEP\u003e\"RNN (Recurrent Neural Network) performs the worst among the three, especially in terms of speed.\"", "entity_type": "\"TECHNOLOGY\"", "id": "\"RNN\"", "label": "\"RNN\"", "shape": "dot", "size": 10, "source_id": "chunk-bcf7c68cd902ea546596acd01bf558cf\u003cSEP\u003echunk-a5bc016656f4a03d7267cf14d747240b"}, {"color": "#97c2fc", "description": "\"Word2Vec\u7528\u4e8e\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u8bcd\u5411\u91cf\uff0c\u4ee5\u652f\u6301NLP\u4efb\u52a1.\"", "entity_type": "\"UNKNOWN\"", "id": "\"\u8bcd\u5411\u91cf\"", "label": "\"\u8bcd\u5411\u91cf\"", "shape": "dot", "size": 10, "source_id": "chunk-83f4aea6a8402d9c9f99736cbb2135d4"}, {"color": "#97c2fc", "description": "\"ELMo uses RNNs to generate context-specific embeddings for word predictions in natural language processing tasks.\"", "entity_type": "\"UNKNOWN\"", "id": "\"ELMO\"", "label": "\"ELMO\"", "shape": "dot", "size": 10, "source_id": "chunk-a5bc016656f4a03d7267cf14d747240b"}, {"color": "#97c2fc", "description": "\"An extension of BERT that uses more data and longer training periods, effectively handling multi-epoch training without significant performance degradation.\"", "entity_type": "\"CONCEPT\"", "id": "\"ROBERTA\"", "label": "\"ROBERTA\"", "shape": "dot", "size": 10, "source_id": "chunk-9c1eb6ec6cc7c8742be47f032e1488fc"}, {"color": "#97c2fc", "description": "\"FP16 is a half-precision floating point format used in training large-scale models but prone to numerical instability.\"", "entity_type": "\"CONCEPT\"", "id": "\"FP16\"", "label": "\"FP16\"", "shape": "dot", "size": 10, "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825"}, {"color": "#97c2fc", "description": "\"Training with FP16 faces significant numerical instability issues, often resulting in overflow.\"", "entity_type": "\"UNKNOWN\"", "id": "\"NUMERICAL STABILITY CHALLENGES\"", "label": "\"NUMERICAL STABILITY CHALLENGES\"", "shape": "dot", "size": 10, "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825"}, {"color": "#97c2fc", "description": "\"BF16 is an alternative float format provided by NVIDIA GPUs that helps mitigate issues with FP16, though it\u0027s not universally supported.\"", "entity_type": "\"CONCEPT\"", "id": "\"BF16\"", "label": "\"BF16\"", "shape": "dot", "size": 10, "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825"}, {"color": "#97c2fc", "description": "\"BF16 addresses some of the limitations faced by FP16 training in terms of stability and precision.\"", "entity_type": "\"UNKNOWN\"", "id": "\"FP16 LIMITATIONS\"", "label": "\"FP16 LIMITATIONS\"", "shape": "dot", "size": 10, "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825"}, {"color": "#97c2fc", "description": "\"A technique used to prevent overflow in FP16 training by scaling the loss function.\"", "entity_type": "\"TECHNIQUE\"", "id": "\"LOSS SCALING\"", "label": "\"LOSS SCALING\"", "shape": "dot", "size": 10, "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825"}, {"color": "#97c2fc", "description": "\"The loss scaling technique is applied to mitigate instability issues during FP16 training.\"", "entity_type": "\"UNKNOWN\"", "id": "\"FP16 TRAINING\"", "label": "\"FP16 TRAINING\"", "shape": "dot", "size": 10, "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825"}, {"color": "#97c2fc", "description": "\"Frameworks and hardware solutions like those provided by NVIDIA Ampere GPUs offer BF16 support to improve model stability during training.\"", "entity_type": "\"ORGANIZATION\"", "id": "\"OPTIMIZATION FRAMEWORKS (E.G., NVIDIA AMPERE)\"", "label": "\"OPTIMIZATION FRAMEWORKS (E.G., NVIDIA AMPERE)\"", "shape": "dot", "size": 10, "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825"}, {"color": "#97c2fc", "description": "\"NVIDIA Ampere GPUs provide BF16 support, improving the stability and efficiency of large-scale model training.\"", "entity_type": "\"UNKNOWN\"", "id": "\"BF16 TRAINING\"", "label": "\"BF16 TRAINING\"", "shape": "dot", "size": 10, "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825"}, {"color": "#97c2fc", "description": "\"A prominent Chinese startup company known for developing the \u0027Smart Brain\u0027 AI system.\"", "entity_type": "\"ORGANIZATION\"", "id": "\"UNICORN TECH CO.\"", "label": "\"UNICORN TECH CO.\"", "shape": "dot", "size": 10, "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825"}, {"color": "#97c2fc", "description": "\"Unicorn Tech Co. is recognized for its development of the \u0027Smart Brain,\u0027 an AI system capable of complex cognitive tasks and autonomous learning.\"", "entity_type": "\"UNKNOWN\"", "id": "\"AI INNOVATION\"", "label": "\"AI INNOVATION\"", "shape": "dot", "size": 10, "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825"}, {"color": "#97c2fc", "description": "\"Chinese tech giant that develops advanced processors, contributing to China\u0027s technological advancements and global presence.\"\u003cSEP\u003e\"Leading Chinese tech company known for innovation in 5G technology.\"", "entity_type": "\"ORGANIZATION\"", "id": "\"HUAWEI\"", "label": "\"HUAWEI\"", "shape": "dot", "size": 10, "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825"}, {"color": "#97c2fc", "description": "\"Huawei\u0027s latest Kirin processor series represents a significant advancement in computing power and energy efficiency, especially within the AI domain.\"", "entity_type": "\"UNKNOWN\"", "id": "\"TECHNOLOGICAL ADVANCEMENTS\"", "label": "\"TECHNOLOGICAL ADVANCEMENTS\"", "shape": "dot", "size": 10, "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825"}, {"color": "#97c2fc", "description": "\"Huawei plays a critical role in advancing 5G technology and has released several innovative products and solutions.\"", "entity_type": "\"UNKNOWN\"", "id": "\"5G TECHNOLOGY DEVELOPMENT\"", "label": "\"5G TECHNOLOGY DEVELOPMENT\"", "shape": "dot", "size": 10, "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825"}, {"color": "#97c2fc", "description": "\"The United Nations Framework Convention on Climate Change, an international treaty aimed at combating climate change.\"", "entity_type": "\"ORGANIZATION\"", "id": "\"UNFCCC\"", "label": "\"UNFCCC\"", "shape": "dot", "size": 10, "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825"}, {"color": "#97c2fc", "description": "\"The UNFCCC emphasizes the urgency of reducing carbon emissions through international cooperation and policy implementation.\"", "entity_type": "\"UNKNOWN\"", "id": "\"GLOBAL CLIMATE ACTION\"", "label": "\"GLOBAL CLIMATE ACTION\"", "shape": "dot", "size": 10, "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825"}, {"color": "#97c2fc", "description": "\"A critical issue highlighted by the UNFCCC involving efforts to reduce greenhouse gases and combat global warming.\"", "entity_type": "\"CONCEPT\"", "id": "\"CARBON EMISSIONS REDUCTION\"", "label": "\"CARBON EMISSIONS REDUCTION\"", "shape": "dot", "size": 10, "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825"}, {"color": "#97c2fc", "description": "\"Country implementing effective environmental regulations promoting green energy development and reducing fossil fuel dependency.\"", "entity_type": "\"GEO\"", "id": "\"DENMARK\"", "label": "\"DENMARK\"", "shape": "dot", "size": 10, "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825"}, {"color": "#97c2fc", "description": "\"China\u0027s leading scientific research institution.\"", "entity_type": "\"ORGANIZATION\"", "id": "\"CAS (CHINESE ACADEMY OF SCIENCES)\"", "label": "\"CAS (CHINESE ACADEMY OF SCIENCES)\"", "shape": "dot", "size": 10, "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825"}, {"color": "#97c2fc", "description": "\"The CAS continues to achieve significant scientific breakthroughs, as evidenced by the Nobel Prize win.\"", "entity_type": "\"UNKNOWN\"", "id": "\"SCIENTIFIC BREAKTHROUGHS\"", "label": "\"SCIENTIFIC BREAKTHROUGHS\"", "shape": "dot", "size": 10, "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825"}, {"color": "#97c2fc", "description": "\"A scientist from CAS who won the Nobel Prize in Chemistry, contributing to China\u2019s growing influence in global science and technology.\"", "entity_type": "\"PERSON\"", "id": "\"ZHANG PROFESSOR\"", "label": "\"ZHANG PROFESSOR\"", "shape": "dot", "size": 10, "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825"}, {"color": "#97c2fc", "description": "\"Professor Zhang from CAS was awarded the Nobel Prize in Chemistry, highlighting China\u0027s growing presence in global science research.\"", "entity_type": "\"UNKNOWN\"", "id": "\"NOBEL PRIZE IN CHEMISTRY\"", "label": "\"NOBEL PRIZE IN CHEMISTRY\"", "shape": "dot", "size": 10, "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825"}, {"color": "#97c2fc", "description": "\"Chinese scientist who received the Nobel Prize in Physics for pioneering work in quantum science.\"", "entity_type": "\"PERSON\"", "id": "\"PROFESSOR CHEN\"", "label": "\"PROFESSOR CHEN\"", "shape": "dot", "size": 10, "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825"}, {"color": "#97c2fc", "description": "\"Professor Chen\u0027s work in quantum science has received international recognition through the Nobel Prize, contributing to global advancements in this field.\"", "entity_type": "\"UNKNOWN\"", "id": "\"QUANTUM SCIENCE\"", "label": "\"QUANTUM SCIENCE\"", "shape": "dot", "size": 10, "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825"}, {"color": "#97c2fc", "description": "\"Leading Chinese company dominating global e-commerce and expanding its influence in cloud computing, financial technology\u7b49\u9886\u57df\u3002\"", "entity_type": "\"ORGANIZATION\"", "id": "\"ALIBABA GROUP\"", "label": "\"ALIBABA GROUP\"", "shape": "dot", "size": 10, "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825"}, {"color": "#97c2fc", "description": "\"Alibaba Group holds a dominant position in the global e-commerce market and is expanding its influence into cloud computing and financial technology sectors.\"", "entity_type": "\"UNKNOWN\"", "id": "\"GLOBAL E-COMMERCE MARKET\"", "label": "\"GLOBAL E-COMMERCE MARKET\"", "shape": "dot", "size": 10, "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825"}, {"color": "#97c2fc", "description": "\"Chinese tech giant with significant success in social media and online gaming.\"", "entity_type": "\"ORGANIZATION\"", "id": "\"TENCENT\"", "label": "\"TENCENT\"", "shape": "dot", "size": 10, "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825"}, {"color": "#97c2fc", "description": "\"Tencent has achieved significant success in social media platforms and online gaming, establishing itself as a major player in these industries.\"", "entity_type": "\"UNKNOWN\"", "id": "\"SOCIAL MEDIA AND ONLINE GAMING\"", "label": "\"SOCIAL MEDIA AND ONLINE GAMING\"", "shape": "dot", "size": 10, "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825"}, {"color": "#97c2fc", "description": "\"International body promoting environmental sustainability and addressing global environmental challenges.\"", "entity_type": "\"ORGANIZATION\"", "id": "\"UNEP (UNITED NATIONS ENVIRONMENT PROGRAMME)\"", "label": "\"UNEP (UNITED NATIONS ENVIRONMENT PROGRAMME)\"", "shape": "dot", "size": 10, "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825"}, {"color": "#97c2fc", "description": "\"UNEP emphasizes the urgency of climate change action and calls for immediate measures to reduce carbon emissions and protect natural resources.\"", "entity_type": "\"UNKNOWN\"", "id": "\"CLIMATE CHANGE ACTION\"", "label": "\"CLIMATE CHANGE ACTION\"", "shape": "dot", "size": 10, "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825"}, {"color": "#97c2fc", "description": "\"A series of new policies announced by the Chinese government aimed at enhancing environmental protection, including investment in renewable energy, pollution control, and promotion of green living.\"", "entity_type": "\"CONCEPT\"", "id": "\"ENVIRONMENTAL PROTECTION POLICIES IN CHINA\"", "label": "\"ENVIRONMENTAL PROTECTION POLICIES IN CHINA\"", "shape": "dot", "size": 10, "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825"}, {"color": "#97c2fc", "description": "\"China\u0027s new environmental policies aim to mitigate climate change through increased investment in renewable energy, pollution control measures, and promotion of green living practices.\"", "entity_type": "\"UNKNOWN\"", "id": "\"CLIMATE CHANGE MITIGATION\"", "label": "\"CLIMATE CHANGE MITIGATION\"", "shape": "dot", "size": 10, "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825"}, {"color": "#97c2fc", "description": "\"Global organization focused on energy policies, providing analysis and recommendations to help countries achieve secure, sustainable, and affordable energy.\"", "entity_type": "\"ORGANIZATION\"", "id": "\"IEA (INTERNATIONAL ENERGY AGENCY)\"", "label": "\"IEA (INTERNATIONAL ENERGY AGENCY)\"", "shape": "dot", "size": 10, "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825"}, {"color": "#97c2fc", "description": "\"The increasing share of renewable energy in the global energy mix as reported by IEA.\"", "entity_type": "\"CONCEPT\"", "id": "\"RENEWABLE ENERGY GROWTH\"", "label": "\"RENEWABLE ENERGY GROWTH\"", "shape": "dot", "size": 10, "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825"}, {"color": "#97c2fc", "description": "\"Government agency responsible for promoting scientific and technological innovation in energy production and use.\"", "entity_type": "\"ORGANIZATION\"", "id": "\"DOE (U.S. DEPARTMENT OF ENERGY)\"", "label": "\"DOE (U.S. DEPARTMENT OF ENERGY)\"", "shape": "dot", "size": 10, "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825"}, {"color": "#97c2fc", "description": "\"The DOE emphasizes the importance of clean energy technologies such as solar and wind power for reducing greenhouse gas emissions.\"", "entity_type": "\"UNKNOWN\"", "id": "\"CLEAN ENERGY TECHNOLOGIES\"", "label": "\"CLEAN ENERGY TECHNOLOGIES\"", "shape": "dot", "size": 10, "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825"}, {"color": "#97c2fc", "description": "\"Global health agency focused on international public health and promoting health security.\"", "entity_type": "\"ORGANIZATION\"", "id": "\"WHO (WORLD HEALTH ORGANIZATION)\"", "label": "\"WHO (WORLD HEALTH ORGANIZATION)\"", "shape": "dot", "size": 10, "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825"}, {"color": "#97c2fc", "description": "\"A new initiative by WHO aimed at improving global preparedness for infectious diseases and enhancing public awareness about health issues.\"", "entity_type": "\"CONCEPT\"", "id": "\"GLOBAL HEALTH ACTION PLAN\"", "label": "\"GLOBAL HEALTH ACTION PLAN\"", "shape": "dot", "size": 10, "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825"}, {"color": "#97c2fc", "description": "\"Increased funding and efforts by the Chinese government to improve public healthcare infrastructure, training of medical personnel, and promotion of health education.\"", "entity_type": "\"CONCEPT\"", "id": "\"PUBLIC HEALTH INVESTMENTS IN CHINA\"", "label": "\"PUBLIC HEALTH INVESTMENTS IN CHINA\"", "shape": "dot", "size": 10, "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825"}, {"color": "#97c2fc", "description": "\"China is increasing its investments to improve public healthcare infrastructure, including building more hospitals and clinics, training medical staff, and promoting health education to enhance overall public health.\"", "entity_type": "\"UNKNOWN\"", "id": "\"IMPROVING PUBLIC HEALTHCARE INFRASTRUCTURE\"", "label": "\"IMPROVING PUBLIC HEALTHCARE INFRASTRUCTURE\"", "shape": "dot", "size": 10, "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825"}, {"color": "#97c2fc", "description": "\"Body responsible for proposing and implementing policies at the European Union level, including economic and social issues.\"", "entity_type": "\"ORGANIZATION\"", "id": "\"EC (EUROPEAN COMMISSION)\"", "label": "\"EC (EUROPEAN COMMISSION)\"", "shape": "dot", "size": 10, "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825"}, {"color": "#97c2fc", "description": "\"A new strategy announced by EC to accelerate digital transformation in EU member states through investment in advanced digital infrastructure, technological innovation, and support for the digital economy.\"", "entity_type": "\"CONCEPT\"", "id": "\"DIGITAL TRANSFORMATION STRATEGY\"", "label": "\"DIGITAL TRANSFORMATION STRATEGY\"", "shape": "dot", "size": 10, "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825"}, {"color": "#97c2fc", "description": "\"Increased funding and efforts by European governments to research and develop artificial intelligence and big data technologies, aiming to promote their application and development.\"", "entity_type": "\"CONCEPT\"", "id": "\"AI AND BIG DATA RESEARCH INVESTMENTS\"", "label": "\"AI AND BIG DATA RESEARCH INVESTMENTS\"", "shape": "dot", "size": 10, "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825"}, {"color": "#97c2fc", "description": "\"European governments are increasing their investments in AI and big data research to promote their application and development, which is expected to drive economic growth and enhance competitiveness in global technology competition.\"", "entity_type": "\"UNKNOWN\"", "id": "\"ECONOMIC GROWTH\"", "label": "\"ECONOMIC GROWTH\"", "shape": "dot", "size": 10, "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825"}, {"color": "#97c2fc", "description": "\"A recent gathering of government representatives from various countries to discuss global challenges and potential cooperative solutions.\"", "entity_type": "\"EVENT\"", "id": "\"INTERNATIONAL SUMMIT\"", "label": "\"INTERNATIONAL SUMMIT\"", "shape": "dot", "size": 10, "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825"}, {"color": "#97c2fc", "description": "\"Major issues such as climate change, public health, and economic recovery that require international cooperation and coordination for effective resolution.\"", "entity_type": "\"CONCEPT\"", "id": "\"GLOBAL CHALLENGES\"", "label": "\"GLOBAL CHALLENGES\"", "shape": "dot", "size": 10, "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825"}, {"color": "#97c2fc", "description": "\"Specific action plans proposed by multiple countries to address climate change through reducing carbon emissions in the coming years.\"", "entity_type": "\"CONCEPT\"", "id": "\"CLIMATE CHANGE ACTION PLANS\"", "label": "\"CLIMATE CHANGE ACTION PLANS\"", "shape": "dot", "size": 10, "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825"}, {"color": "#97c2fc", "description": "\"Multiple countries have outlined specific action plans aimed at reducing carbon emissions as part of their efforts to address climate change over the next few years.\"", "entity_type": "\"UNKNOWN\"", "id": "\"CARBON EMISSION REDUCTION\"", "label": "\"CARBON EMISSION REDUCTION\"", "shape": "dot", "size": 10, "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825"}, {"color": "#97c2fc", "description": "\"Global financial institution focused on providing loans and grants to developing countries for the purpose of reducing poverty and improving living standards.\"", "entity_type": "\"ORGANIZATION\"", "id": "\"WORLD BANK (WB)\"", "label": "\"WORLD BANK (WB)\"", "shape": "dot", "size": 10, "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825"}, {"color": "#97c2fc", "description": "\"A report by World Bank analyzing the current state and future prospects of global economies, particularly in light of the pandemic\u0027s impact.\"", "entity_type": "\"REPORT\"", "id": "\"ECONOMIC OUTLOOK REPORT\"", "label": "\"ECONOMIC OUTLOOK REPORT\"", "shape": "dot", "size": 10, "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825"}, {"color": "#97c2fc", "description": "\"The process through which affected economies are returning to normal growth levels following significant disruptions such as a global health crisis.\"", "entity_type": "\"CONCEPT\"", "id": "\"GLOBAL ECONOMIC RECOVERY\"", "label": "\"GLOBAL ECONOMIC RECOVERY\"", "shape": "dot", "size": 10, "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825"}, {"color": "#97c2fc", "description": "\"While the global economic recovery is slow, there are signs of improvement as some economies start showing growth momentum and emerging markets have made progress in innovation and digital transformation.\"", "entity_type": "\"UNKNOWN\"", "id": "\"POSITIVE TRENDS\"", "label": "\"POSITIVE TRENDS\"", "shape": "dot", "size": 10, "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825"}, {"color": "#97c2fc", "description": "\"A report by IMF highlighting the progress made by some countries and regions despite challenges in global economic recovery, emphasizing the importance of continued policy support and vaccination efforts.\"", "entity_type": "\"REPORT\"", "id": "\"ECONOMIC RECOVERY REPORT\"", "label": "\"ECONOMIC RECOVERY REPORT\"", "shape": "dot", "size": 10, "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825"}, {"color": "#97c2fc", "description": "\"The IMF has issued a report indicating that despite global economic recovery challenges, some countries are making progress through effective policy support and vaccination efforts. The IMF advises continued fiscal measures to promote recovery and financial stability.\"", "entity_type": "\"UNKNOWN\"", "id": "\"IMF (INTERNATIONAL MONETARY FUND)\"", "label": "\"IMF (INTERNATIONAL MONETARY FUND)\"", "shape": "dot", "size": 10, "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825"}, {"color": "#97c2fc", "description": "\"The need for collaborative efforts among nations to address common economic challenges such as debt management, sustainable development, and financial stability.\"", "entity_type": "\"CONCEPT\"", "id": "\"INTERNATIONAL COOPERATION\"", "label": "\"INTERNATIONAL COOPERATION\"", "shape": "dot", "size": 10, "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825"}, {"color": "#97c2fc", "description": "\"The IMF stresses the importance of international cooperation in tackling shared economic challenges, including debt management, sustainable development, and maintaining global financial system stability.\"", "entity_type": "\"UNKNOWN\"", "id": "\"ECONOMIC CHALLENGES\"", "label": "\"ECONOMIC CHALLENGES\"", "shape": "dot", "size": 10, "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825"}, {"color": "#97c2fc", "description": "\"Megatron-LM is an organization that has developed a method for tensor parallelization in large language models.\"", "entity_type": "\"ORGANIZATION\"", "id": "\"MEGATRON-LM\"", "label": "\"MEGATRON-LM\"", "shape": "dot", "size": 10, "source_id": "chunk-10fbf6d3d9babf4d5d45d940bb1db122"}, {"color": "#97c2fc", "description": "\"Megatron-LM proposes an efficient 1D tensor parallelization method for large language models.\"", "entity_type": "\"UNKNOWN\"", "id": "\"TENSOR PARALLELIZATION\"", "label": "\"TENSOR PARALLELIZATION\"", "shape": "dot", "size": 10, "source_id": "chunk-10fbf6d3d9babf4d5d45d940bb1db122"}, {"color": "#97c2fc", "description": "\"Transformer architecture models are the basis for Megatron-LM and Colossal-AI\u0027s tensor parallelization solutions, though they lack universality.\"", "entity_type": "\"CONCEPT\"", "id": "\"TRANSFORMER ARCHITECTURE MODELS\"", "label": "\"TRANSFORMER ARCHITECTURE MODELS\"", "shape": "dot", "size": 10, "source_id": "chunk-10fbf6d3d9babf4d5d45d940bb1db122"}, {"color": "#97c2fc", "description": "\"Colossal-AI is an organization providing multidimensional tensor parallelism solutions to improve upon Megatron-LM\u0027s limitations.\"", "entity_type": "\"ORGANIZATION\"", "id": "\"COLOSSAL-AI\"", "label": "\"COLOSSAL-AI\"", "shape": "dot", "size": 10, "source_id": "chunk-10fbf6d3d9babf4d5d45d940bb1db122"}, {"color": "#97c2fc", "description": "\"PyTorch provides tensor parallel solutions that offer a more general approach compared to specific implementations like Megatron-LM and Colossal-AI.\"", "entity_type": "\"CONCEPT\"", "id": "\"PYTORCH TENSOR PARALLEL SOLUTIONS\"", "label": "\"PYTORCH TENSOR PARALLEL SOLUTIONS\"", "shape": "dot", "size": 10, "source_id": "chunk-10fbf6d3d9babf4d5d45d940bb1db122"}, {"color": "#97c2fc", "description": "\"MOE is a structural approach that allows models to achieve extremely large parameter scales, such as in the trillions, without significantly increasing computational costs.\"", "entity_type": "\"CONCEPT\"", "id": "\"MOE (MIXTURE OF EXPERTS)\"", "label": "\"MOE (MIXTURE OF EXPERTS)\"", "shape": "dot", "size": 10, "source_id": "chunk-5474069465781f541726c53600f1b4f7"}, {"color": "#97c2fc", "description": "\"LIMoE is an organization or framework related to Model-based research, specifically focusing on the Mixture of Experts (MoE) concept.\"", "entity_type": "\"ORGANIZATION\"", "id": "\"LIMOE\"", "label": "\"LIMOE\"", "shape": "dot", "size": 10, "source_id": "chunk-75724a68b2c0f46a2e2ec23c1411363f"}, {"color": "#97c2fc", "description": "\"This event represents a NeurIPS\u002718 paper discussing the curriculum data-model relationship within diverse ensemble evolution.\"", "entity_type": "\"EVENT\"", "id": "\"DIVERSE ENSEMBLE EVOLUTION: CURRICULUM DATA-MODEL MARRIAGE\"", "label": "\"DIVERSE ENSEMBLE EVOLUTION: CURRICULUM DATA-MODEL MARRIAGE\"", "shape": "dot", "size": 10, "source_id": "chunk-75724a68b2c0f46a2e2ec23c1411363f"}, {"color": "#97c2fc", "description": "\"This event is an ICLR\u002721 paper focusing on the diversity and depth aspect of routing models per example.\"", "entity_type": "\"EVENT\"", "id": "\"DIVERSITY AND DEPTH IN PER-EXAMPLE ROUTING MODELS\"", "label": "\"DIVERSITY AND DEPTH IN PER-EXAMPLE ROUTING MODELS\"", "shape": "dot", "size": 10, "source_id": "chunk-75724a68b2c0f46a2e2ec23c1411363f"}, {"color": "#97c2fc", "description": "\"MOE is expected to play an increasingly important role in advancing towards AGI.\"", "entity_type": "\"UNKNOWN\"", "id": "\"AGI\"", "label": "\"AGI\"", "shape": "dot", "size": 10, "source_id": "chunk-5474069465781f541726c53600f1b4f7"}, {"color": "#97c2fc", "description": "\"LangChain is designed to facilitate the development and deployment of large language model applications.\"", "entity_type": "\"UNKNOWN\"", "id": "\"LANGCHAIN\"", "label": "\"LANGCHAIN\"", "shape": "dot", "size": 10, "source_id": "chunk-b433fbff2e2fff052a98c5f49e7ba4c2"}, {"color": "#97c2fc", "description": "\"LangChain is designed to facilitate the development and deployment of large language model applications.\"", "entity_type": "\"UNKNOWN\"", "id": "\"LARGE LANGUAGE MODEL APPLICATIONS\"", "label": "\"LARGE LANGUAGE MODEL APPLICATIONS\"", "shape": "dot", "size": 10, "source_id": "chunk-b433fbff2e2fff052a98c5f49e7ba4c2"}, {"color": "#97c2fc", "description": "\"Alibaba Cloud contributes to the development and promotion of LangChain, a framework for large language model applications.\"", "entity_type": "\"UNKNOWN\"", "id": "\"ALIBABA CLOUD\"", "label": "\"ALIBABA CLOUD\"", "shape": "dot", "size": 10, "source_id": "chunk-b433fbff2e2fff052a98c5f49e7ba4c2"}, {"color": "#97c2fc", "description": "\"Jack Ma played a key role in establishing and supporting Alibaba Cloud, which contributes to LangChain development.\"", "entity_type": "\"UNKNOWN\"", "id": "\"JACK MA\"", "label": "\"JACK MA\"", "shape": "dot", "size": 10, "source_id": "chunk-b433fbff2e2fff052a98c5f49e7ba4c2"}, {"color": "#97c2fc", "description": "\"Alibaba Cloud regularly participates in the Cloud Computing Conference to showcase its latest technologies, including LangChain.\"", "entity_type": "\"UNKNOWN\"", "id": "\"CLOUD COMPUTING CONFERENCE 1984\"", "label": "\"CLOUD COMPUTING CONFERENCE 1984\"", "shape": "dot", "size": 10, "source_id": "chunk-b433fbff2e2fff052a98c5f49e7ba4c2"}, {"color": "#97c2fc", "description": "\"The headquarters of Alibaba Cloud is located in Hangzhou, China.\"", "entity_type": "\"UNKNOWN\"", "id": "\"ALIBABA CLOUD HQ\"", "label": "\"ALIBABA CLOUD HQ\"", "shape": "dot", "size": 10, "source_id": "chunk-b433fbff2e2fff052a98c5f49e7ba4c2"}, {"color": "#97c2fc", "description": "\"The headquarters of Alibaba Cloud is located in Hangzhou, China.\"", "entity_type": "\"UNKNOWN\"", "id": "\"HANGZHOU\"", "label": "\"HANGZHOU\"", "shape": "dot", "size": 10, "source_id": "chunk-b433fbff2e2fff052a98c5f49e7ba4c2"}, {"color": "#97c2fc", "description": "\"DirectoryLoader is a class in langchain for loading documents from a directory.\"", "entity_type": "\"CLASS\"", "id": "\"DIRECTORYLOADER\"", "label": "\"DIRECTORYLOADER\"", "shape": "dot", "size": 10, "source_id": "chunk-2ca6daea6a4f0f4a4352f8eba1bc3e4e"}, {"color": "#97c2fc", "description": "\"DirectoryLoader loads documents into a list of Pydantic Documents.\"", "entity_type": "\"UNKNOWN\"", "id": "\"DOCS\"", "label": "\"DOCS\"", "shape": "dot", "size": 10, "source_id": "chunk-2ca6daea6a4f0f4a4352f8eba1bc3e4e"}, {"color": "#97c2fc", "description": "\"OpenAIEmbeddings is used to create embeddings for texts using the OpenAI API.\"", "entity_type": "\"CLASS\"", "id": "\"OPENAIEMBEDDINGS\"", "label": "\"OPENAIEMBEDDINGS\"", "shape": "dot", "size": 10, "source_id": "chunk-2ca6daea6a4f0f4a4352f8eba1bc3e4e"}, {"color": "#97c2fc", "description": "\"OpenAIEmbeddings generates embeddings from texts using OpenAI\u0027s API.\"", "entity_type": "\"UNKNOWN\"", "id": "\"EMBEDDINGS\"", "label": "\"EMBEDDINGS\"", "shape": "dot", "size": 10, "source_id": "chunk-2ca6daea6a4f0f4a4352f8eba1bc3e4e"}, {"color": "#97c2fc", "description": "\"CharacterTextSplitter is a text splitting utility that splits large texts into smaller chunks.\"", "entity_type": "\"CLASS\"", "id": "\"CHARACTERTEXTSPLITTER\"", "label": "\"CHARACTERTEXTSPLITTER\"", "shape": "dot", "size": 10, "source_id": "chunk-2ca6daea6a4f0f4a4352f8eba1bc3e4e"}, {"color": "#97c2fc", "description": "\"CharacterTextSplitter splits the loaded documents into smaller chunks for processing.\"", "entity_type": "\"UNKNOWN\"", "id": "\"DOCS_SPLIT\"", "label": "\"DOCS_SPLIT\"", "shape": "dot", "size": 10, "source_id": "chunk-2ca6daea6a4f0f4a4352f8eba1bc3e4e"}, {"color": "#97c2fc", "description": "\"Chroma is a vector database used to store embeddings and facilitate similarity searches.\"", "entity_type": "\"CLASS\"", "id": "\"CHROMA\"", "label": "\"CHROMA\"", "shape": "dot", "size": 10, "source_id": "chunk-2ca6daea6a4f0f4a4352f8eba1bc3e4e"}, {"color": "#97c2fc", "description": "\"Chroma stores the document embeddings and provides retrieval functionality.\"", "entity_type": "\"UNKNOWN\"", "id": "\"VECTOR_STORE\"", "label": "\"VECTOR_STORE\"", "shape": "dot", "size": 10, "source_id": "chunk-2ca6daea6a4f0f4a4352f8eba1bc3e4e"}, {"color": "#97c2fc", "description": "\"ChatVectorDBChain combines chat functionality with vector databases for retrieving answers from context.\"", "entity_type": "\"FUNCTION\"", "id": "\"CHATVECTORDBCHAIN\"", "label": "\"CHATVECTORDBCHAIN\"", "shape": "dot", "size": 10, "source_id": "chunk-2ca6daea6a4f0f4a4352f8eba1bc3e4e"}, {"color": "#97c2fc", "description": "\"ChatVectorDBChain creates a chain where chat interacts with vector databases for answers.\"", "entity_type": "\"UNKNOWN\"", "id": "\"QA\"", "label": "\"QA\"", "shape": "dot", "size": 10, "source_id": "chunk-2ca6daea6a4f0f4a4352f8eba1bc3e4e"}, {"color": "#97c2fc", "description": "\"ConversationalRetrievalChain is used to create a conversational interface over a retrieval system.\"", "entity_type": "\"FUNCTION\"", "id": "\"CONVERSATIONALRETRIEVALCHAIN\"", "label": "\"CONVERSATIONALRETRIEVALCHAIN\"", "shape": "dot", "size": 10, "source_id": "chunk-2ca6daea6a4f0f4a4352f8eba1bc3e4e"}, {"color": "#97c2fc", "description": "\"A team working on communicating with an unknown intelligence using advanced communication technology.\"", "entity_type": "\"ORGANIZATION\"", "id": "\"ALEX AND SAM RIVERA\u0027S TEAM\"", "label": "\"ALEX AND SAM RIVERA\u0027S TEAM\"", "shape": "dot", "size": 10, "source_id": "chunk-2ca6daea6a4f0f4a4352f8eba1bc3e4e"}, {"color": "#97c2fc", "description": "\"Technology used by the team to attempt contact with an unknown intelligence.\"", "entity_type": "\"TECHNOLOGY\"", "id": "\"ADVANCED COMMUNICATION TECHNOLOGY\"", "label": "\"ADVANCED COMMUNICATION TECHNOLOGY\"", "shape": "dot", "size": 10, "source_id": "chunk-2ca6daea6a4f0f4a4352f8eba1bc3e4e"}, {"color": "#97c2fc", "description": "\"The mission to land the Perseverance rover on Mars in February 2021.\"", "entity_type": "\"EVENT\"", "id": "\"NASA\u0027S MARS 2020 MISSION\"", "label": "\"NASA\u0027S MARS 2020 MISSION\"", "shape": "dot", "size": 10, "source_id": "chunk-2ca6daea6a4f0f4a4352f8eba1bc3e4e"}, {"color": "#97c2fc", "description": "\"A small helicopter that made the first powered flight on another planet as part of NASA\u0027s Mars 2020 mission.\"", "entity_type": "\"TECHNOLOGY\"", "id": "\"INGENUITY MARS HELICOPTER\"", "label": "\"INGENUITY MARS HELICOPTER\"", "shape": "dot", "size": 10, "source_id": "chunk-2ca6daea6a4f0f4a4352f8eba1bc3e4e"}, {"color": "#97c2fc", "description": "\"A rover deployed as part of NASA\u0027s Mars 2020 mission to explore Jezero Crater and search for signs of past life.\"", "entity_type": "\"TECHNOLOGY\"", "id": "\"PERSEVERANCE ROVER\"", "label": "\"PERSEVERANCE ROVER\"", "shape": "dot", "size": 10, "source_id": "chunk-2ca6daea6a4f0f4a4352f8eba1bc3e4e"}, {"color": "#97c2fc", "description": "\"The area on Mars where the Perseverance rover is exploring, searching for evidence of ancient microbial life.\"", "entity_type": "\"GEO\"", "id": "\"JEZERO CRATER\"", "label": "\"JEZERO CRATER\"", "shape": "dot", "size": 10, "source_id": "chunk-2ca6daea6a4f0f4a4352f8eba1bc3e4e"}, {"color": "#97c2fc", "description": "\"The organization responsible for managing and executing the Perseverance rover mission.\"", "entity_type": "\"ORGANIZATION\"", "id": "\"NASA JET PROPULSION LABORATORY (JPL)\"", "label": "\"NASA JET PROPULSION LABORATORY (JPL)\"", "shape": "dot", "size": 10, "source_id": "chunk-2ca6daea6a4f0f4a4352f8eba1bc3e4e"}, {"color": "#97c2fc", "description": "\"These are different methods or techniques used in model optimization and fine-tuning.\"", "entity_type": "\"TECHNOLOGY\"", "id": "\"LORA, BITFIT, PREFIX-TUNING, UNIPELT\"", "label": "\"LORA, BITFIT, PREFIX-TUNING, UNIPELT\"", "shape": "dot", "size": 10, "source_id": "chunk-6efa9c6aa660f80c3eda33d6df29f324"}, {"color": "#97c2fc", "description": "\"PELT method refers to a technique that involves multiple parts of the Pre-trained Language Model (PLM) for optimizing model performance and robustness.\"", "entity_type": "\"CONCEPT\"", "id": "\"PELT METHOD\"", "label": "\"PELT METHOD\"", "shape": "dot", "size": 10, "source_id": "chunk-6efa9c6aa660f80c3eda33d6df29f324"}, {"color": "#97c2fc", "description": "\"A PLM is a foundational model in natural language processing that has been pre-trained on large datasets, serving as a basis for further fine-tuning or adaptation.\"", "entity_type": "\"TECHNOLOGY\"", "id": "\"PRE-TRAINED LANGUAGE MODEL (PLM)\"", "label": "\"PRE-TRAINED LANGUAGE MODEL (PLM)\"", "shape": "dot", "size": 10, "source_id": "chunk-6efa9c6aa660f80c3eda33d6df29f324"}, {"color": "#97c2fc", "description": "\"Layer-wise Representation Learning for Efficient Fine-tuning; focuses on modifying only a few layers of a model to save resources.\"\u003cSEP\u003e\"LoRA is an efficient fine-tuning technique that introduces reparameterization and reduces computational costs during training and inference.\"", "entity_type": "\"METHODOLOGY\"", "id": "\"LORA\"", "label": "\"LORA\"", "shape": "dot", "size": 10, "source_id": "chunk-6fb791db271a0a4e393b0080cf334633\u003cSEP\u003echunk-6efa9c6aa660f80c3eda33d6df29f324"}, {"color": "#97c2fc", "description": "\"Parameter-efficient fine-tuning through learning only biases or layer norms in transformers, reducing the amount of training needed.\"", "entity_type": "\"MODEL OPTIMIZATION TECHNIQUE\"", "id": "\"BITFIT\"", "label": "\"BITFIT\"", "shape": "dot", "size": 10, "source_id": "chunk-6efa9c6aa660f80c3eda33d6df29f324"}, {"color": "#97c2fc", "description": "\"Improves efficiency by adding a small number of parameters at the beginning of each transformer block during fine-tuning.\"", "entity_type": "\"MODEL OPTIMIZATION TECHNIQUE\"", "id": "\"PREFIX-TUNING\"", "label": "\"PREFIX-TUNING\"", "shape": "dot", "size": 10, "source_id": "chunk-6efa9c6aa660f80c3eda33d6df29f324"}, {"color": "#97c2fc", "description": "\"A method that unifies different parameter-efficient techniques under one framework for better model performance and ease of use.\"\u003cSEP\u003e\"UniPELT integrates different PELT methods (LoRA, Prefix Tuning, Adapter) as sub-modules with a gating mechanism to activate the most suitable method for current data or tasks.\"", "entity_type": "\"METHODOLOGY\"", "id": "\"UNIPELT\"", "label": "\"UNIPELT\"", "shape": "dot", "size": 10, "source_id": "chunk-6fb791db271a0a4e393b0080cf334633\u003cSEP\u003echunk-6efa9c6aa660f80c3eda33d6df29f324"}, {"color": "#97c2fc", "description": "\"MAM Adapter is a unified approach that connects Adapter, Prefix Tuning, and LoRA. It combines parallel Adapter for FFN and soft prompts.\"", "entity_type": "\"METHODOLOGY\"", "id": "\"MAM ADAPTER\"", "label": "\"MAM ADAPTER\"", "shape": "dot", "size": 10, "source_id": "chunk-6fb791db271a0a4e393b0080cf334633"}, {"color": "#97c2fc", "description": "\"Adapter is a technique that inserts additional layers (Adapters) into existing transformer models to adapt their behavior for specific tasks without affecting other parts of the model.\"", "entity_type": "\"METHODOLOGY\"", "id": "\"ADAPTER\"", "label": "\"ADAPTER\"", "shape": "dot", "size": 10, "source_id": "chunk-6fb791db271a0a4e393b0080cf334633"}, {"color": "#97c2fc", "description": "\"The LLama2 series refers to a set of models being fine-tuned from scratch, indicating an ongoing project or initiative.\"", "entity_type": "\"ORGANIZATION\"", "id": "\"LLAMA2 SERIES\"", "label": "\"LLAMA2 SERIES\"", "shape": "dot", "size": 10, "source_id": "chunk-f5af718c9d6b994d28f73e212375b2b2"}, {"color": "#97c2fc", "description": "\"Zhihu is the platform where information about the LLama2 series is being shared and discussed.\"", "entity_type": "\"LOCATION\"", "id": "\"\u77e5\u4e4e\"", "label": "\"\u77e5\u4e4e\"", "shape": "dot", "size": 10, "source_id": "chunk-f5af718c9d6b994d28f73e212375b2b2"}, {"color": "#97c2fc", "description": "\"P-Tuning v2 is an advanced method for prompting that matches or outperforms fine-tuning across various tasks.\"\u003cSEP\u003e\"P-Tuning v2 is another efficient fine-tuning method similar to LoRA, with good overall performance.\"", "entity_type": "\"TECHNOLOGY\"", "id": "\"P-TUNING V2\"", "label": "\"P-TUNING V2\"", "shape": "dot", "size": 10, "source_id": "chunk-4e00824efb6ed62d0c56266d5c25ab70\u003cSEP\u003echunk-6fb791db271a0a4e393b0080cf334633"}, {"color": "#97c2fc", "description": "\"P-Tuning v2 performs comparably to or better than fine tuning on small-scale tasks, especially in natural language inference (RTE) and sentiment analysis.\"", "entity_type": "\"UNKNOWN\"", "id": "\"FINE TUNING\"", "label": "\"FINE TUNING\"", "shape": "dot", "size": 10, "source_id": "chunk-4e00824efb6ed62d0c56266d5c25ab70"}, {"color": "#97c2fc", "description": "\"The effectiveness of P-Tuning v2 may vary with prompt length, requiring optimization for different tasks.\"", "entity_type": "\"UNKNOWN\"", "id": "\"PROMPT LENGTH\"", "label": "\"PROMPT LENGTH\"", "shape": "dot", "size": 10, "source_id": "chunk-4e00824efb6ed62d0c56266d5c25ab70"}, {"color": "#97c2fc", "description": "\"The performance of P-Tuning v2 can vary depending on the complexity of tasks, requiring careful consideration for optimal results.\"", "entity_type": "\"UNKNOWN\"", "id": "\"TASK COMPLEXITY\"", "label": "\"TASK COMPLEXITY\"", "shape": "dot", "size": 10, "source_id": "chunk-4e00824efb6ed62d0c56266d5c25ab70"}, {"color": "#97c2fc", "description": "\"\u667a\u8c31 is an organization providing guidance and tutorials on deploying and fine-tuning large language models like ChatGLM3.\"", "entity_type": "\"ORGANIZATION\"", "id": "\"\u667a\u8c31\"", "label": "\"\u667a\u8c31\"", "shape": "dot", "size": 10, "source_id": "chunk-0e87e307fcbe65dbc1b036277c963d52"}, {"color": "#97c2fc", "description": "\"ChatGLM3-6B is an advanced version of the ChatGLM series that supports Function Call, Code Interpreter, and Agent functionalities.\"", "entity_type": "\"CONCEPT\"", "id": "\"CHATGLM3-6B \"", "label": "\"CHATGLM3-6B \"", "shape": "dot", "size": 10, "source_id": "chunk-0e87e307fcbe65dbc1b036277c963d52"}, {"color": "#97c2fc", "description": "\"Function Call refers to a feature in models like ChatGLM3-6B where the model can invoke external functions or APIs.\"", "entity_type": "\"FUNCTIONALITY\"", "id": "\"FUNCTION CALL\"", "label": "\"FUNCTION CALL\"", "shape": "dot", "size": 10, "source_id": "chunk-0e87e307fcbe65dbc1b036277c963d52"}, {"color": "#97c2fc", "description": "\"ChatGLM2-INT4 is a quantized version of the ChatGLM2 model designed to reduce resource consumption while maintaining performance.\"", "entity_type": "\"CONCEPT\"", "id": "\"CHATGLM2-INT4 \"", "label": "\"CHATGLM2-INT4 \"", "shape": "dot", "size": 10, "source_id": "chunk-0e87e307fcbe65dbc1b036277c963d52"}, {"color": "#97c2fc", "description": "\"LoRA training refers to a method used for fine-tuning large language models like ChatGLM2, enhancing their capabilities with minimal data.\"", "entity_type": "\"EVENT\"", "id": "\"LORA TRAINING \"", "label": "\"LORA TRAINING \"", "shape": "dot", "size": 10, "source_id": "chunk-0e87e307fcbe65dbc1b036277c963d52"}, {"color": "#97c2fc", "description": "\"RAG is a technique that combines retrieval-based and generative models to enhance the quality of generated responses, indicating its importance in the context of information retrieval and generation.\"", "entity_type": "\"TECHNOLOGY\"", "id": "\"RAG (RETRIEVAL-AUGMENTED GENERATION)\"", "label": "\"RAG (RETRIEVAL-AUGMENTED GENERATION)\"", "shape": "dot", "size": 10, "source_id": "chunk-f5b8c806db414a91b4dbd808e6798006"}, {"color": "#97c2fc", "description": "\"LLM Agent technology refers to the application of large language model agents for various tasks, emphasizing their role in enhancing system capabilities.\"", "entity_type": "\"TECHNOLOGY\"", "id": "\"LLM AGENT TECHNOLOGY\"", "label": "\"LLM AGENT TECHNOLOGY\"", "shape": "dot", "size": 10, "source_id": "chunk-f5b8c806db414a91b4dbd808e6798006"}, {"color": "#97c2fc", "description": "\"MetaGPT is a project or organization associated with research on advanced AI systems, as indicated by the linked academic paper.\"", "entity_type": "\"ORGANIZATION\"", "id": "\"METAGPT\"", "label": "\"METAGPT\"", "shape": "dot", "size": 10, "source_id": "chunk-74f6b594f3958fb2771f177186f3dd2c"}, {"color": "#97c2fc", "description": "\"The Agents Framework is an open-source project for building autonomous language agents, highlighting its importance in advancing AI research and application.\"", "entity_type": "\"CONCEPT\"", "id": "\"AGENTS FRAMEWORK\"", "label": "\"AGENTS FRAMEWORK\"", "shape": "dot", "size": 10, "source_id": "chunk-74f6b594f3958fb2771f177186f3dd2c"}, {"color": "#97c2fc", "description": "\"OpenBMB/ChatDev refers to an open-source project focused on developing conversational agents and related technologies.\"", "entity_type": "\"ORGANIZATION\"", "id": "\"OPENBMB/CHATDEV\"", "label": "\"OPENBMB/CHATDEV\"", "shape": "dot", "size": 10, "source_id": "chunk-74f6b594f3958fb2771f177186f3dd2c"}, {"color": "#97c2fc", "description": "\"AgentVerse is another open-source initiative aimed at creating autonomous language agents, suggesting it\u0027s part of the broader ecosystem of AI development.\"", "entity_type": "\"ORGANIZATION\"", "id": "\"AGENTVERSE\"", "label": "\"AGENTVERSE\"", "shape": "dot", "size": 10, "source_id": "chunk-74f6b594f3958fb2771f177186f3dd2c"}, {"color": "#97c2fc", "description": "\"The LIDA model is described as a computational framework implementing Global Workspace Theory and developmental learning principles, contributing to our understanding of human cognition.\"", "entity_type": "\"CONCEPT\"", "id": "\"LIDA MODEL\"", "label": "\"LIDA MODEL\"", "shape": "dot", "size": 10, "source_id": "chunk-74f6b594f3958fb2771f177186f3dd2c"}, {"color": "#97c2fc", "description": "\"This concept discusses critical evolutionary milestones that enabled human language development, offering insights into the cognitive architecture underpinning linguistic capabilities.\"", "entity_type": "\"EVENT\"", "id": "\"PHASE TRANSITIONS OF BRAIN EVOLUTION\"", "label": "\"PHASE TRANSITIONS OF BRAIN EVOLUTION\"", "shape": "dot", "size": 10, "source_id": "chunk-74f6b594f3958fb2771f177186f3dd2c"}, {"color": "#97c2fc", "description": "\"Understanding phase transitions in brain evolution provides crucial insights into how human language has evolved over time.\"", "entity_type": "\"UNKNOWN\"", "id": "\"HUMAN LANGUAGE EVOLUTION\"", "label": "\"HUMAN LANGUAGE EVOLUTION\"", "shape": "dot", "size": 10, "source_id": "chunk-74f6b594f3958fb2771f177186f3dd2c"}, {"color": "#97c2fc", "description": "\"This document provides a retrospective analysis of four decades of research in cognitive architecture, focusing on core abilities and practical applications.\"\u003cSEP\u003e\"This document reviews four decades of research in cognitive architecture, providing a historical and theoretical overview.\"", "entity_type": "\"DOCUMENT\"", "id": "\"A REVIEW OF 40 YEARS IN COGNITIVE ARCHITECTURE RESEARCH\"", "label": "\"A REVIEW OF 40 YEARS IN COGNITIVE ARCHITECTURE RESEARCH\"", "shape": "dot", "size": 10, "source_id": "chunk-74f6b594f3958fb2771f177186f3dd2c"}, {"color": "#97c2fc", "description": "\"The Projection mechanism is proposed as a way to enable human-like reasoning within artificial intelligence systems, suggesting it\u0027s a key area of interest and development.\"", "entity_type": "\"CONCEPT\"", "id": "\"PROJECTION MECHANISM\"", "label": "\"PROJECTION MECHANISM\"", "shape": "dot", "size": 10, "source_id": "chunk-74f6b594f3958fb2771f177186f3dd2c"}, {"color": "#97c2fc", "description": "\"The Projection mechanism aims to bridge the gap between human cognition and AI systems by enabling more sophisticated reasoning abilities.\"", "entity_type": "\"UNKNOWN\"", "id": "\"HUMAN-LIKE REASONING IN AI\"", "label": "\"HUMAN-LIKE REASONING IN AI\"", "shape": "dot", "size": 10, "source_id": "chunk-74f6b594f3958fb2771f177186f3dd2c"}, {"color": "#97c2fc", "description": "\"PDDL is a formal language used for defining planning problems in AI research, providing structure for automated reasoning tasks.\"", "entity_type": "\"CONCEPT\"", "id": "\"PLANNING DOMAIN DEFINITION LANGUAGE (PDDL)\"", "label": "\"PLANNING DOMAIN DEFINITION LANGUAGE (PDDL)\"", "shape": "dot", "size": 10, "source_id": "chunk-74f6b594f3958fb2771f177186f3dd2c"}, {"color": "#97c2fc", "description": "\"PDDL serves as a foundational language for defining tasks in planning systems within the realm of artificial intelligence research.\"", "entity_type": "\"UNKNOWN\"", "id": "\"AI PLANNING SYSTEMS\"", "label": "\"AI PLANNING SYSTEMS\"", "shape": "dot", "size": 10, "source_id": "chunk-74f6b594f3958fb2771f177186f3dd2c"}, {"color": "#97c2fc", "description": "\"\u903b\u8f91\u63a8\u65ad\u969c\u788d\u662f\u6307\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u7406\u89e3\u6216\u5904\u7406\u590d\u6742\u4fe1\u606f\u65f6\uff0c\u53ef\u80fd\u56e0\u4e3a\u8bef\u89e3\u6e90\u6587\u672c\u4e2d\u7684\u4fe1\u606f\u800c\u5f97\u51fa\u4e0d\u51c6\u786e\u7ed3\u8bba\u7684\u60c5\u51b5\u3002\"", "entity_type": "\"CONCEPT\"", "id": "\"\u903b\u8f91\u63a8\u65ad\u969c\u788d\"", "label": "\"\u903b\u8f91\u63a8\u65ad\u969c\u788d\"", "shape": "dot", "size": 10, "source_id": "chunk-ae2b89823ad29ef6521a8f10eafcf639"}, {"color": "#97c2fc", "description": "\"\u5728\u9762\u5bf9\u590d\u6742\u4fe1\u606f\u65f6\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u53ef\u80fd\u56e0\u4e3a\u903b\u8f91\u63a8\u7406\u80fd\u529b\u4e0d\u8db3\u800c\u51fa\u73b0\u7406\u89e3\u4e0a\u7684\u504f\u5dee\uff0c\u4ece\u800c\u5bfc\u81f4\u7ed3\u8bba\u7684\u51c6\u786e\u6027\u53d7\u635f\u3002\"", "entity_type": "\"UNKNOWN\"", "id": "\"\u5927\u578b\u8bed\u8a00\u6a21\u578b\"", "label": "\"\u5927\u578b\u8bed\u8a00\u6a21\u578b\"", "shape": "dot", "size": 10, "source_id": "chunk-ae2b89823ad29ef6521a8f10eafcf639"}, {"color": "#97c2fc", "description": "\"\u5728\u9762\u5bf9\u590d\u6742\u7684\u6216\u542b\u7cca\u4e0d\u6e05\u7684\u4fe1\u606f\u65f6\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u53ef\u80fd\u65e0\u6cd5\u6b63\u786e\u89e3\u6790\u5176\u4e2d\u7684\u91cd\u8981\u7ec6\u8282\uff0c\u4ece\u800c\u5f71\u54cd\u5176\u540e\u7eed\u7684\u5206\u6790\u548c\u7ed3\u8bba\u751f\u6210\u8fc7\u7a0b\u3002\"", "entity_type": "\"UNKNOWN\"", "id": "\"\u8bef\u89e3\u6e90\u6587\u672c\u4e2d\u7684\u4fe1\u606f\"", "label": "\"\u8bef\u89e3\u6e90\u6587\u672c\u4e2d\u7684\u4fe1\u606f\"", "shape": "dot", "size": 10, "source_id": "chunk-ae2b89823ad29ef6521a8f10eafcf639"}, {"color": "#97c2fc", "description": "\"\u4e0a\u4e0b\u6587\u4e0e\u5185\u7f6e\u77e5\u8bc6\u7684\u51b2\u7a81\u6307\u7684\u662f\u6a21\u578b\u5728\u751f\u6210\u8f93\u51fa\u65f6\u8fc7\u5ea6\u4f9d\u8d56\u4e8e\u9884\u8bad\u7ec3\u9636\u6bb5\u83b7\u53d6\u7684\u77e5\u8bc6\uff0c\u5ffd\u89c6\u4e86\u5f53\u524d\u5177\u4f53\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u5bfc\u81f4\u8f93\u51fa\u9519\u8bef\u6216\u4e0d\u7b26\u5408\u5b9e\u9645\u60c5\u5883\u3002\"", "entity_type": "\"CONCEPT\"", "id": "\"\u4e0a\u4e0b\u6587\u4e0e\u5185\u7f6e\u77e5\u8bc6\u7684\u51b2\u7a81\"", "label": "\"\u4e0a\u4e0b\u6587\u4e0e\u5185\u7f6e\u77e5\u8bc6\u7684\u51b2\u7a81\"", "shape": "dot", "size": 10, "source_id": "chunk-ae2b89823ad29ef6521a8f10eafcf639"}, {"color": "#97c2fc", "description": "\"\u5728\u751f\u6210\u8f93\u51fa\u8fc7\u7a0b\u4e2d\uff0c\u5982\u679c\u6a21\u578b\u4f9d\u8d56\u4e8e\u9884\u8bad\u7ec3\u65f6\u7684\u77e5\u8bc6\u800c\u4e0d\u662f\u5f53\u524d\u7684\u5177\u4f53\u60c5\u5883\u4fe1\u606f\uff0c\u5219\u53ef\u80fd\u5bfc\u81f4\u5176\u4ea7\u751f\u4e0d\u51c6\u786e\u6216\u4e0d\u5408\u903b\u8f91\u7684\u56de\u7b54\u3002\"", "entity_type": "\"UNKNOWN\"", "id": "\"\u5927\u6a21\u578b\u8f93\u51fa\"", "label": "\"\u5927\u6a21\u578b\u8f93\u51fa\"", "shape": "dot", "size": 10, "source_id": "chunk-ae2b89823ad29ef6521a8f10eafcf639"}, {"color": "#97c2fc", "description": "\"\u9519\u8bef\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\u662f\u6307\u7ed9\u5b9a\u7684\u4fe1\u606f\u6216\u8005\u5047\u8bbe\u672c\u8eab\u5b58\u5728\u8bef\u5bfc\u6027\u6216\u9519\u8bef\uff0c\u53ef\u80fd\u5bfc\u81f4\u6a21\u578b\u751f\u6210\u4e0d\u51c6\u786e\u7684\u56de\u7b54\u6216\u4ea7\u751f\u5e7b\u89c9\u3002\"", "entity_type": "\"EVENT\"", "id": "\"\u9519\u8bef\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\"", "label": "\"\u9519\u8bef\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\"", "shape": "dot", "size": 10, "source_id": "chunk-ae2b89823ad29ef6521a8f10eafcf639"}, {"color": "#97c2fc", "description": "\"\u5f53\u63d0\u4f9b\u7ed9\u6a21\u578b\u7684\u4fe1\u606f\u5305\u542b\u8bef\u5bfc\u6027\u5047\u8bbe\u6216\u9519\u8bef\u65f6\uff0c\u6a21\u578b\u53ef\u80fd\u4f1a\u57fa\u4e8e\u8fd9\u4e9b\u9519\u8bef\u751f\u6210\u5e7b\u89c9\u5f0f\u7684\u56de\u7b54\u3002\"", "entity_type": "\"UNKNOWN\"", "id": "\"\u5927\u578b\u8bed\u8a00\u6a21\u578b\u56de\u7b54\"", "label": "\"\u5927\u578b\u8bed\u8a00\u6a21\u578b\u56de\u7b54\"", "shape": "dot", "size": 10, "source_id": "chunk-ae2b89823ad29ef6521a8f10eafcf639"}, {"color": "#97c2fc", "description": "\"\u5f53\u8f93\u5165\u7ed9\u6a21\u578b\u7684\u4fe1\u606f\u4e2d\u5305\u542b\u4e0d\u51c6\u786e\u6216\u5177\u6709\u8bef\u5bfc\u6027\u7684\u5047\u8bbe\u65f6\uff0c\u8fd9\u4e9b\u5047\u8bbe\u53ef\u80fd\u5bfc\u81f4\u6a21\u578b\u5f97\u51fa\u9519\u8bef\u7684\u63a8\u8bba\u548c\u7ed3\u8bba\u3002\"", "entity_type": "\"UNKNOWN\"", "id": "\"\u8bef\u5bfc\u6027\u5047\u8bbe\"", "label": "\"\u8bef\u5bfc\u6027\u5047\u8bbe\"", "shape": "dot", "size": 10, "source_id": "chunk-ae2b89823ad29ef6521a8f10eafcf639"}, {"color": "#97c2fc", "description": "\"\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7531\u4e8e\u8bad\u7ec3\u6570\u636e\u548c\u7b97\u6cd5\u7684\u9650\u5236\uff0c\u5728\u5904\u7406\u590d\u6742\u4fe1\u606f\u65f6\u53ef\u80fd\u51fa\u73b0\u903b\u8f91\u63a8\u7406\u4e0a\u7684\u7f3a\u9677\uff0c\u5bfc\u81f4\u5bf9\u95ee\u9898\u7406\u89e3\u4e0d\u51c6\u786e\u3002\"", "entity_type": "\"CONCEPT\"", "id": "\"\u903b\u8f91\u63a8\u7406\u80fd\u529b\u4e0d\u8db3\"", "label": "\"\u903b\u8f91\u63a8\u7406\u80fd\u529b\u4e0d\u8db3\"", "shape": "dot", "size": 10, "source_id": "chunk-ae2b89823ad29ef6521a8f10eafcf639"}, {"color": "#97c2fc", "description": "\"\u5f53\u9762\u4e34\u9ad8\u5ea6\u590d\u6742\u7684\u63a8\u7406\u4efb\u52a1\u65f6\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u53ef\u80fd\u7531\u4e8e\u5176\u81ea\u8eab\u7684\u9650\u5236\u800c\u96be\u4ee5\u8fdb\u884c\u6709\u6548\u7684\u903b\u8f91\u63a8\u65ad\u548c\u4fe1\u606f\u6574\u5408\u3002\"", "entity_type": "\"UNKNOWN\"", "id": "\"\u590d\u6742\u4fe1\u606f\u5904\u7406\u4e0d\u5f53\"", "label": "\"\u590d\u6742\u4fe1\u606f\u5904\u7406\u4e0d\u5f53\"", "shape": "dot", "size": 10, "source_id": "chunk-ae2b89823ad29ef6521a8f10eafcf639"}, {"color": "#97c2fc", "description": "\"RLHF refers to Reward Learning with Human Feedback, a method used in training AI models to generate more human-like responses.\"\u003cSEP\u003e\"Reinforcement Learning from Human Feedback (RLHF) involves training large language models with a fitted reward model that reflects human preferences, aiming to maximize estimated rewards while staying close to the original model.\"", "entity_type": "\"CONCEPT\"", "id": "\"RLHF\"", "label": "\"RLHF\"", "shape": "dot", "size": 10, "source_id": "chunk-b43020db5fae0ade6540f46dc8c909d7\u003cSEP\u003echunk-115db5344fc770c67e60120f710f8c9e"}, {"color": "#97c2fc", "description": "\"The process of carefully designing prompts to elicit desired responses from AI models, enhancing their utility and effectiveness.\"", "entity_type": "\"TECHNIQUE\"", "id": "\"PROMPT ENGINEERING\"", "label": "\"PROMPT ENGINEERING\"", "shape": "dot", "size": 10, "source_id": "chunk-b43020db5fae0ade6540f46dc8c909d7"}, {"color": "#97c2fc", "description": "\"DPO\u662f\u4e00\u79cd\u7528\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u4f18\u5316\u65b9\u6cd5\uff0c\u5177\u4f53\u5b9a\u4e49\u672a\u5728\u6587\u6863\u5185\u5bb9\u4e2d\u660e\u786e\u63d0\u53ca\u3002\"\u003cSEP\u003e\"Direct Preference Optimization (DPO) is an algorithm proposed to optimize large language models based on human preferences without the need for fitting reward models or sampling during fine-tuning.\"", "entity_type": "\"CONCEPT\"", "id": "\"DPO\"", "label": "\"DPO\"", "shape": "dot", "size": 10, "source_id": "chunk-8d8c962534d489403cf773b04a4a653f\u003cSEP\u003echunk-115db5344fc770c67e60120f710f8c9e"}, {"color": "#97c2fc", "description": "\"Model Flattery describes the tendency of large language models trained via RLHF to cater excessively to the input provided by users or the reward system.\"", "entity_type": "\"CONCEPT\"", "id": "\"MODEL FLATTERY\"", "label": "\"MODEL FLATTERY\"", "shape": "dot", "size": 10, "source_id": "chunk-b43020db5fae0ade6540f46dc8c909d7"}, {"color": "#97c2fc", "description": "\"A system where the output of a process is used as input to influence future iterations, often seen in iterative improvement processes like model training.\"", "entity_type": "\"CONCEPT\"", "id": "\"FEEDBACK LOOPS\"", "label": "\"FEEDBACK LOOPS\"", "shape": "dot", "size": 10, "source_id": "chunk-b43020db5fae0ade6540f46dc8c909d7"}, {"color": "#97c2fc", "description": "\"Top-p decoding is a strategy used in generating text where only tokens with cumulative probability above p are considered for selection during each step of the generation process.\"", "entity_type": "\"TECHNIQUE\"", "id": "\"TOP-P DECODING\"", "label": "\"TOP-P DECODING\"", "shape": "dot", "size": 10, "source_id": "chunk-b43020db5fae0ade6540f46dc8c909d7"}, {"color": "#97c2fc", "description": "\"Greedy decoding selects the token with the highest probability at each step to generate text, ensuring efficiency but potentially sacrificing creativity or accuracy.\"", "entity_type": "\"TECHNIQUE\"", "id": "\"GREEDY DECODING\"", "label": "\"GREEDY DECODING\"", "shape": "dot", "size": 10, "source_id": "chunk-b43020db5fae0ade6540f46dc8c909d7"}, {"color": "#97c2fc", "description": "\"Intervention in multi-head attention mechanisms can guide a model\u0027s output by influencing specific heads that are most relevant for factual correctness.\"", "entity_type": "\"TECHNIQUE\"", "id": "\"MULTI-HEAD ATTENTION MECHANISM INTERVENTION\"", "label": "\"MULTI-HEAD ATTENTION MECHANISM INTERVENTION\"", "shape": "dot", "size": 10, "source_id": "chunk-b43020db5fae0ade6540f46dc8c909d7"}, {"color": "#97c2fc", "description": "\"Intervention in the multi-head attention mechanism is part of the Factual-Nucleus approach to enhance factual correctness during decoding.\"", "entity_type": "\"UNKNOWN\"", "id": "\"FACTUAL-NUCLEUS\"", "label": "\"FACTUAL-NUCLEUS\"", "shape": "dot", "size": 10, "source_id": "chunk-b43020db5fae0ade6540f46dc8c909d7"}, {"color": "#97c2fc", "description": "\"Transformer models use residual connections to allow information to propagate through multiple layers, which is crucial for generating coherent and factually accurate responses.\"", "entity_type": "\"CONCEPT\"", "id": "\"RESIDUAL CONNECTIONS IN TRANSFORMERS\"", "label": "\"RESIDUAL CONNECTIONS IN TRANSFORMERS\"", "shape": "dot", "size": 10, "source_id": "chunk-b43020db5fae0ade6540f46dc8c909d7"}, {"color": "#97c2fc", "description": "\"A technique that uses the differences between predictions made by different transformer layers to guide more realistic decoding.\"", "entity_type": "\"TECHNIQUE\"", "id": "\"DOLA (DISTILLED OUTPUT LAYER ATTENTION)\"", "label": "\"DOLA (DISTILLED OUTPUT LAYER ATTENTION)\"", "shape": "dot", "size": 10, "source_id": "chunk-b43020db5fae0ade6540f46dc8c909d7"}, {"color": "#97c2fc", "description": "\"Technique used after model generation where prompts are employed to verify and correct generated content, enhancing factual accuracy.\"", "entity_type": "\"TECHNIQUE\"", "id": "\"CHAIN-OF-VERIFICATION\"", "label": "\"CHAIN-OF-VERIFICATION\"", "shape": "dot", "size": 10, "source_id": "chunk-b43020db5fae0ade6540f46dc8c909d7"}, {"color": "#97c2fc", "description": "\"A method involving iterative refinement of a model\u0027s output through reflective questioning, aiming for consistency in answers.\"", "entity_type": "\"TECHNIQUE\"", "id": "\"SELF-REFLECTION\"", "label": "\"SELF-REFLECTION\"", "shape": "dot", "size": 10, "source_id": "chunk-b43020db5fae0ade6540f46dc8c909d7"}, {"color": "#97c2fc", "description": "\"Technique that adjusts the decoding probabilities based on context to mitigate the influence of internalized knowledge and enhance contextual relevance.\"", "entity_type": "\"TECHNIQUE\"", "id": "\"CONTEXT-AWARE DECODING (CAD)\"", "label": "\"CONTEXT-AWARE DECODING (CAD)\"", "shape": "dot", "size": 10, "source_id": "chunk-b43020db5fae0ade6540f46dc8c909d7"}, {"color": "#97c2fc", "description": "\"Dynamic adjustment of sampling parameters in language generation, guided by KL divergence between conditional and unconditional distributions.\"", "entity_type": "\"TECHNIQUE\"", "id": "\"KL-GUIDED-SAMPLING\"", "label": "\"KL-GUIDED-SAMPLING\"", "shape": "dot", "size": 10, "source_id": "chunk-b43020db5fae0ade6540f46dc8c909d7"}, {"color": "#97c2fc", "description": "\"A technique using a large model to generate token candidates and a smaller model\u0027s distribution as noise to refine predictions for more accurate decoding.\"", "entity_type": "\"TECHNIQUE\"", "id": "\"CONTRASTIVE-DECODING\"", "label": "\"CONTRASTIVE-DECODING\"", "shape": "dot", "size": 10, "source_id": "chunk-b43020db5fae0ade6540f46dc8c909d7"}, {"color": "#97c2fc", "description": "\"Modifying the probabilities assigned to different tokens in a model\u0027s output to influence or correct its behavior and outputs.\"", "entity_type": "\"TECHNIQUE\"", "id": "\"TOKEN PROBABILITY ADJUSTMENT\"", "label": "\"TOKEN PROBABILITY ADJUSTMENT\"", "shape": "dot", "size": 10, "source_id": "chunk-b43020db5fae0ade6540f46dc8c909d7"}, {"color": "#97c2fc", "description": "\"A type of reward that encourages an AI model to generate outputs based on internal motivations rather than external feedback alone.\"", "entity_type": "\"TECHNIQUE\"", "id": "\"INTRINSIC REWARD\"", "label": "\"INTRINSIC REWARD\"", "shape": "dot", "size": 10, "source_id": "chunk-b43020db5fae0ade6540f46dc8c909d7"}, {"color": "#97c2fc", "description": "\"Checking and validating the accuracy and relevance of a model\u0027s output against external data sources or standards.\"", "entity_type": "\"TECHNIQUE\"", "id": "\"EXTERNAL VALIDATION\"", "label": "\"EXTERNAL VALIDATION\"", "shape": "dot", "size": 10, "source_id": "chunk-b43020db5fae0ade6540f46dc8c909d7"}, {"color": "#97c2fc", "description": "\"GPT\u662f\u4e00\u7cfb\u5217\u57fa\u4e8e\u81ea\u56de\u5f52\u9884\u6d4b\u7684\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\uff0c\u4ee3\u8868\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4e00\u4e2a\u91cd\u8981\u6d41\u6d3e\u3002\"", "entity_type": "\"MODEL\"", "id": "\"GPT\"", "label": "\"GPT\"", "shape": "dot", "size": 10, "source_id": "chunk-83f4aea6a8402d9c9f99736cbb2135d4"}, {"color": "#97c2fc", "description": "\"\u51e0\u4e4e\u6240\u6709\u73b0\u4ee3\u7684\u5927\u8bed\u8a00\u6a21\u578b\u90fd\u4f1a\u7ecf\u5386\u4e00\u4e2a\u6216\u591a\u4e2a\u9884\u8bad\u7ec3\u9636\u6bb5\u6765\u83b7\u5f97\u77e5\u8bc6\u548c\u6280\u80fd\u3002\"", "entity_type": "\"UNKNOWN\"", "id": "\"\u9884\u8bad\u7ec3\"", "label": "\"\u9884\u8bad\u7ec3\"", "shape": "dot", "size": 10, "source_id": "chunk-83f4aea6a8402d9c9f99736cbb2135d4"}, {"color": "#97c2fc", "description": "\"\u901a\u8fc7\u9002\u5f53\u7684\u5fae\u8c03\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5177\u4f53\u5e94\u7528\u4e2d\u7684\u6027\u80fd\u548c\u6548\u679c\u3002\"", "entity_type": "\"UNKNOWN\"", "id": "\"\u5fae\u8c03\"", "label": "\"\u5fae\u8c03\"", "shape": "dot", "size": 10, "source_id": "chunk-83f4aea6a8402d9c9f99736cbb2135d4"}, {"color": "#97c2fc", "description": "\"\u5927\u8bed\u8a00\u6a21\u578b\u901a\u5e38\u5177\u6709\u5f88\u5f3a\u7684\u4e0a\u4e0b\u6587\u611f\u77e5\u80fd\u529b\uff0c\u4f7f\u5176\u5728\u5404\u79cd\u590d\u6742\u7684NLP\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002\"", "entity_type": "\"UNKNOWN\"", "id": "\"\u4e0a\u4e0b\u6587\u611f\u77e5\"", "label": "\"\u4e0a\u4e0b\u6587\u611f\u77e5\"", "shape": "dot", "size": 10, "source_id": "chunk-83f4aea6a8402d9c9f99736cbb2135d4"}, {"color": "#97c2fc", "description": "\"\u5206\u8bcd\u548c\u8bcd\u5411\u91cf\u662f\u81ea\u7136\u8bed\u8a00\u5904\u7406\u7684\u57fa\u7840\u6982\u5ff5\u548c\u6280\u672f\u3002\"", "entity_type": "\"TOPIC\"", "id": "\"\u5206\u8bcd\u4e0e\u8bcd\u5411\u91cf\"", "label": "\"\u5206\u8bcd\u4e0e\u8bcd\u5411\u91cf\"", "shape": "dot", "size": 10, "source_id": "chunk-83f4aea6a8402d9c9f99736cbb2135d4"}, {"color": "#97c2fc", "description": "\"\u5206\u8bcd\u548c\u8bcd\u5411\u91cf\u662f\u7406\u89e3\u5927\u8bed\u8a00\u6a21\u578b\u7684\u57fa\u7840\u77e5\u8bc6\u3002\"", "entity_type": "\"UNKNOWN\"", "id": "\"\u8bed\u8a00\u6a21\u578b\u57fa\u7840\"", "label": "\"\u8bed\u8a00\u6a21\u578b\u57fa\u7840\"", "shape": "dot", "size": 10, "source_id": "chunk-83f4aea6a8402d9c9f99736cbb2135d4"}, {"color": "#97c2fc", "description": "\"\u4f18\u5316\u6a21\u578b\u7684\u7ed3\u6784\u548c\u53c2\u6570\u8bbe\u7f6e\u4ee5\u5904\u7406\u66f4\u957f\u7684\u5e8f\u5217\u6216\u6587\u672c\u3002\"\u003cSEP\u003e\"\u901a\u8fc7\u4f18\u5316\u6a21\u578b\u7684\u7ed3\u6784\u548c\u53c2\u6570\u8bbe\u7f6e\u6765\u63d0\u9ad8\u5176\u5904\u7406\u957f\u6587\u672c\u7684\u80fd\u529b\u3002\"", "entity_type": "\"CONCEPT\"", "id": "\"\u6a21\u578b\u7ed3\u6784\u4f18\u5316\"", "label": "\"\u6a21\u578b\u7ed3\u6784\u4f18\u5316\"", "shape": "dot", "size": 10, "source_id": "chunk-b3e463d24adf84b28a5376fc9c10716b"}, {"color": "#97c2fc", "description": "\"\u53e5\u6cd5\u5206\u6790\u662f\u4e00\u79cd\u8bed\u8a00\u6280\u672f\uff0c\u5728\u89c2\u70b9\u62bd\u53d6\u548c\u60c5\u611f\u5206\u6790\u4e2d\u6709\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u5176\u51c6\u786e\u6027\u4ecd\u6709\u5f85\u63d0\u9ad8\u3002\"", "entity_type": "\"TECHNOLOGY\"", "id": "\"\u53e5\u6cd5\u5206\u6790\"", "label": "\"\u53e5\u6cd5\u5206\u6790\"", "shape": "dot", "size": 10, "source_id": "chunk-5b0fc972b273420601544dc3a8897744"}, {"color": "#97c2fc", "description": "\"\u89c2\u70b9\u62bd\u53d6\u662f\u4ece\u6587\u672c\u4e2d\u63d0\u53d6\u7528\u6237\u6001\u5ea6\u548c\u770b\u6cd5\u7684\u6280\u672f\u624b\u6bb5\uff0c\u901a\u5e38\u4f9d\u8d56\u4e8e\u53e5\u6cd5\u5206\u6790\u7684\u652f\u6301\u3002\"", "entity_type": "\"TECHNOLOGY\"", "id": "\"\u89c2\u70b9\u62bd\u53d6\"", "label": "\"\u89c2\u70b9\u62bd\u53d6\"", "shape": "dot", "size": 10, "source_id": "chunk-5b0fc972b273420601544dc3a8897744"}, {"color": "#97c2fc", "description": "\"\u60c5\u611f\u5206\u6790\u662f\u901a\u8fc7\u6280\u672f\u624b\u6bb5\u6765\u8bc6\u522b\u3001\u62bd\u53d6\u5e76\u91cf\u5316\u7528\u6237\u7684\u60c5\u611f\u503e\u5411\u53ca\u5176\u5f3a\u5ea6\u7684\u8fc7\u7a0b\u3002\"", "entity_type": "\"TECHNOLOGY\"", "id": "\"\u60c5\u611f\u5206\u6790\"", "label": "\"\u60c5\u611f\u5206\u6790\"", "shape": "dot", "size": 10, "source_id": "chunk-5b0fc972b273420601544dc3a8897744"}, {"color": "#97c2fc", "description": "\"\u57fa\u4e8e\u53e5\u6cd5\u7ed3\u6784\u6811\u7684LSTM\u6df1\u5ea6\u5b66\u4e60\u7f51\u7edc\u5728\u53d7\u5236\u4e8e\u53e5\u6cd5\u5206\u6790\u51c6\u786e\u7387\u7684\u95ee\u9898\u4e0b\uff0c\u8fd8\u9700\u8fdb\u4e00\u6b65\u63d0\u5347\u7cbe\u786e\u5ea6\u3002\"", "entity_type": "\"TECHNOLOGY\"", "id": "\"LSTM\u6df1\u5ea6\u5b66\u4e60\u7f51\u7edc\"", "label": "\"LSTM\u6df1\u5ea6\u5b66\u4e60\u7f51\u7edc\"", "shape": "dot", "size": 10, "source_id": "chunk-5b0fc972b273420601544dc3a8897744"}, {"color": "#97c2fc", "description": "\"x is a variable used within an equation related to activation functions in neural networks.\"", "entity_type": "\"VARIABLE\"", "id": "\"X\"", "label": "\"X\"", "shape": "dot", "size": 10, "source_id": "chunk-7291acaf81f6616df2f753d76e28b121"}, {"color": "#97c2fc", "description": "\"\u95e8\u63a7\u6fc0\u6d3b\u51fd\u6570 (gated activation function) refers to a type of function used in neural network architectures, specifically designed to control the flow of information through gates.\"", "entity_type": "\"CONCEPT\"", "id": "\"\u95e8\u63a7\u6fc0\u6d3b\u51fd\u6570\"", "label": "\"\u95e8\u63a7\u6fc0\u6d3b\u51fd\u6570\"", "shape": "dot", "size": 10, "source_id": "chunk-7291acaf81f6616df2f753d76e28b121"}, {"color": "#97c2fc", "description": "\"The split_head method reshapes input tensor x according to specified head number or default if none provided.\"", "entity_type": "\"UNKNOWN\"", "id": "\"SELF.SPLIT_HEAD\"", "label": "\"SELF.SPLIT_HEAD\"", "shape": "dot", "size": 10, "source_id": "chunk-bdde321da03a10cd546e17bd2a065594"}, {"color": "#97c2fc", "description": "\"\u795e\u7ecf\u7f51\u7edc (neural network) \u662f\u4e00\u79cd\u6a21\u4eff\u4eba\u8111\u7ed3\u6784\u548c\u529f\u80fd\u7684\u8ba1\u7b97\u6a21\u578b\uff0c\u7528\u4e8e\u5904\u7406\u590d\u6742\u7684\u6570\u636e\u6a21\u5f0f\u3002\"", "entity_type": "\"CONCEPT\"", "id": "\"\u795e\u7ecf\u7f51\u7edc\"", "label": "\"\u795e\u7ecf\u7f51\u7edc\"", "shape": "dot", "size": 10, "source_id": "chunk-7291acaf81f6616df2f753d76e28b121"}, {"color": "#97c2fc", "description": "\"\u4fe1\u606f\u6d41\u6307\u7684\u662f\u6570\u636e\u5728\u7f51\u7edc\u4e2d\u4f20\u8f93\u548c\u5904\u7406\u7684\u8fc7\u7a0b\u3002\"", "entity_type": "\"CONCEPT\"", "id": "\"\u4fe1\u606f\u6d41\"", "label": "\"\u4fe1\u606f\u6d41\"", "shape": "dot", "size": 10, "source_id": "chunk-7291acaf81f6616df2f753d76e28b121"}, {"color": "#97c2fc", "description": "\"N-gram\u6a21\u578b\u662f\u4e00\u79cd\u7edf\u8ba1\u65b9\u6cd5\uff0c\u5728\u77ed\u4e0a\u4e0b\u6587\u957f\u5ea6\u4e2d\u4e0e\u58f0\u5b66\u6216\u7ffb\u8bd1\u6a21\u578b\u8054\u5408\u4f7f\u7528\u662f\u6709\u6548\u7684\u3002\"", "entity_type": "\"CONCEPT\"", "id": "\"N-GRAM\u6a21\u578b\"", "label": "\"N-GRAM\u6a21\u578b\"", "shape": "dot", "size": 10, "source_id": "chunk-3265869f4b91b0e4feb100fa049dcf4b"}, {"color": "#97c2fc", "description": "\"\u795e\u7ecf\u8bed\u8a00\u6a21\u578b\u5728\u7edf\u8ba1\u4e0a\u9ad8\u6548\uff0c\u4f46\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u968f\u7740\u65f6\u95f4\u7684\u63a8\u79fb\u5df2\u6210\u4e3a\u4e3b\u5bfc\u7684\u6a21\u578b\u8303\u5f0f\u3002\"", "entity_type": "\"CONCEPT\"", "id": "\"\u795e\u7ecf\u8bed\u8a00\u6a21\u578b\"", "label": "\"\u795e\u7ecf\u8bed\u8a00\u6a21\u578b\"", "shape": "dot", "size": 10, "source_id": "chunk-3265869f4b91b0e4feb100fa049dcf4b"}, {"color": "#97c2fc", "description": "\"NVIDIA is the company that has developed and made publicly available NVIDIA TensorRT-LLM, a tool for optimizing inference on large language models.\"", "entity_type": "\"ORGANIZATION\"", "id": "\"NVIDIA\"", "label": "\"NVIDIA\"", "shape": "dot", "size": 10, "source_id": "chunk-4a4088e85fc27ef2f659b63294a50ca9"}, {"color": "#97c2fc", "description": "\"TensorRT-LLM is a technology from NVIDIA designed to optimize the performance of large language models during inference.\"", "entity_type": "\"TECHNOLOGY\"", "id": "\"TENSORRT-LLM\"", "label": "\"TENSORRT-LLM\"", "shape": "dot", "size": 10, "source_id": "chunk-4a4088e85fc27ef2f659b63294a50ca9"}, {"color": "#97c2fc", "description": "\"Large Language Models are complex AI systems that process and generate human-like text, which TensorRT-LLM aims to optimize for better performance.\"", "entity_type": "\"CONCEPT\"", "id": "\"LARGE LANGUAGE MODELS (LLMS)\"", "label": "\"LARGE LANGUAGE MODELS (LLMS)\"", "shape": "dot", "size": 10, "source_id": "chunk-4a4088e85fc27ef2f659b63294a50ca9"}, {"color": "#97c2fc", "description": "\"Latency is a measure of how long it takes for a system to respond to an input or request during the inference phase.\"", "entity_type": "\"METRIC\"", "id": "\"LATENCY\"", "label": "\"LATENCY\"", "shape": "dot", "size": 10, "source_id": "chunk-4a4088e85fc27ef2f659b63294a50ca9"}, {"color": "#97c2fc", "description": "\"Throughput is the measure of how many requests or tasks a system can process within a given time frame during the inference phase.\"", "entity_type": "\"METRIC\"", "id": "\"THROUGHPUT\"", "label": "\"THROUGHPUT\"", "shape": "dot", "size": 10, "source_id": "chunk-4a4088e85fc27ef2f659b63294a50ca9"}, {"color": "#97c2fc", "description": "\"Efficient utilization of hardware resources during the inference phase can significantly improve the overall performance and efficiency of a system.\"", "entity_type": "\"CONCEPT\"", "id": "\"HARDWARE RESOURCES UTILIZATION\"", "label": "\"HARDWARE RESOURCES UTILIZATION\"", "shape": "dot", "size": 10, "source_id": "chunk-4a4088e85fc27ef2f659b63294a50ca9"}, {"color": "#97c2fc", "description": "\"During the Inference Phase, Large Language Models analyze input text and produce human-like responses.\"", "entity_type": "\"UNKNOWN\"", "id": "\"INFERENCE PHASE\"", "label": "\"INFERENCE PHASE\"", "shape": "dot", "size": 10, "source_id": "chunk-4a4088e85fc27ef2f659b63294a50ca9"}, {"color": "#97c2fc", "description": "\"RoPE enhances the performance of Transformer models by providing superior positional encoding compared to other methods like ALiBi.\"\u003cSEP\u003e\"RoPE enhances the performance of Transformer models by providing superior positional encoding compared to other methods.\"\u003cSEP\u003e\"RoPE is utilized in Transformer models for enhancing position encoding and improving overall performance.\"", "entity_type": "\"UNKNOWN\"", "id": "\"ROPE\"", "label": "\"ROPE\"", "shape": "dot", "size": 10, "source_id": "chunk-76bc2665b54b51813a049bc7dbb25def"}, {"color": "#97c2fc", "description": "\"RoPE enhances the performance of Transformer models by providing superior positional encoding compared to other methods like ALiBi.\"\u003cSEP\u003e\"RoPE enhances the performance of Transformer models by providing superior positional encoding compared to other methods.\"\u003cSEP\u003e\"RoPE is utilized in Transformer models for enhancing position encoding and improving overall performance.\"", "entity_type": "\"UNKNOWN\"", "id": "\"TRANSFORMER MODELS\"", "label": "\"TRANSFORMER MODELS\"", "shape": "dot", "size": 10, "source_id": "chunk-76bc2665b54b51813a049bc7dbb25def"}, {"color": "#97c2fc", "description": "\"The Pathways vision by Google emphasizes a direction in AI that aligns with MoE\u0027s principles for developing more generalized and flexible models.\"", "entity_type": "\"CONCEPT\"", "id": "\"PATHWAYS VISION\"", "label": "\"PATHWAYS VISION\"", "shape": "dot", "size": 10, "source_id": "chunk-75724a68b2c0f46a2e2ec23c1411363f"}, {"color": "#97c2fc", "description": "\"The Pathways vision was proposed by Google as part of their AI strategy.\"", "entity_type": "\"UNKNOWN\"", "id": "\"GOOGLE\"", "label": "\"GOOGLE\"", "shape": "dot", "size": 10, "source_id": "chunk-75724a68b2c0f46a2e2ec23c1411363f"}, {"color": "#97c2fc", "description": "\"Ensemble learning involves combining multiple models to improve predictive performance and robustness.\"|", "entity_type": "\"CONCEPT\"", "id": "\"ENSEMBLE LEARNING\"", "label": "\"ENSEMBLE LEARNING\"", "shape": "dot", "size": 10, "source_id": "chunk-75724a68b2c0f46a2e2ec23c1411363f"}, {"color": "#97c2fc", "description": "\"This event utilizes curriculum learning principles to guide the evolution of diverse ensembles.\"", "entity_type": "\"UNKNOWN\"", "id": "\"CURRICULUM LEARNING\"", "label": "\"CURRICULUM LEARNING\"", "shape": "dot", "size": 10, "source_id": "chunk-75724a68b2c0f46a2e2ec23c1411363f"}, {"color": "#97c2fc", "description": "\"A technique used during training to prevent overfitting by randomly dropping units along with their connections.\"", "entity_type": "\"TECHNOLOGY\"", "id": "\"DROPOUT SETTING\"", "label": "\"DROPOUT SETTING\"", "shape": "dot", "size": 10, "source_id": "chunk-93bfe637d3d9fb461bff179751f9157c"}, {"color": "#97c2fc", "description": "\"The learning rate is a critical hyperparameter that needs to be set appropriately for Transformer model training.\"", "entity_type": "\"UNKNOWN\"", "id": "\"TRANSFORMER TRAINING\"", "label": "\"TRANSFORMER TRAINING\"", "shape": "dot", "size": 10, "source_id": "chunk-93bfe637d3d9fb461bff179751f9157c"}, {"color": "#97c2fc", "description": "\"A technique used during training of deep neural networks that normalizes the inputs for each layer, reducing internal covariate shift.\"", "entity_type": "\"TECHNOLOGY\"", "id": "\"BATCH NORMALIZATION\"", "label": "\"BATCH NORMALIZATION\"", "shape": "dot", "size": 10, "source_id": "chunk-93bfe637d3d9fb461bff179751f9157c"}, {"color": "#97c2fc", "description": "\"Techniques used in machine learning models to prevent overfitting by adding a penalty for complexity.\"", "entity_type": "\"TECHNOLOGY\"", "id": "\"REGULARIZATION TECHNIQUES\"", "label": "\"REGULARIZATION TECHNIQUES\"", "shape": "dot", "size": 10, "source_id": "chunk-93bfe637d3d9fb461bff179751f9157c"}, {"color": "#97c2fc", "description": "\"A technique used in BERT models for pre-training by masking tokens.\"", "entity_type": "\"TECHNOLOGY\"", "id": "\"BERT MASKING\"", "label": "\"BERT MASKING\"", "shape": "dot", "size": 10, "source_id": "chunk-93bfe637d3d9fb461bff179751f9157c"}, {"color": "#97c2fc", "description": "\"While transformers use attention mechanisms to mask scores, BERT employs a different approach through token masking during training.\"", "entity_type": "\"UNKNOWN\"", "id": "\"TRANSFORMER ATTENTION MASKING\"", "label": "\"TRANSFORMER ATTENTION MASKING\"", "shape": "dot", "size": 10, "source_id": "chunk-93bfe637d3d9fb461bff179751f9157c"}, {"color": "#97c2fc", "description": "\"An optimization algorithm that is used to update weights by combining the advantages of two other extensions: AdaGrad and RMSProp.\"", "entity_type": "\"TECHNOLOGY\"", "id": "\"ADAM OPTIMIZER\"", "label": "\"ADAM OPTIMIZER\"", "shape": "dot", "size": 10, "source_id": "chunk-93bfe637d3d9fb461bff179751f9157c"}, {"color": "#97c2fc", "description": "\"The learning rate is a critical hyperparameter that needs to be set appropriately for Transformer model training.\"", "entity_type": "\"UNKNOWN\"", "id": "\"LEARNING RATE\"", "label": "\"LEARNING RATE\"", "shape": "dot", "size": 10, "source_id": "chunk-93bfe637d3d9fb461bff179751f9157c"}, {"color": "#97c2fc", "description": "\"The method used to set initial weights in a neural network before training starts.\"", "entity_type": "\"TECHNOLOGY\"", "id": "\"WEIGHT INITIALIZATION\"", "label": "\"WEIGHT INITIALIZATION\"", "shape": "dot", "size": 10, "source_id": "chunk-93bfe637d3d9fb461bff179751f9157c"}, {"color": "#97c2fc", "description": "\"A method used to stop training a model when its performance on validation data starts degrading.\"", "entity_type": "\"TECHNOLOGY\"", "id": "\"EARLY STOPPING\"", "label": "\"EARLY STOPPING\"", "shape": "dot", "size": 10, "source_id": "chunk-93bfe637d3d9fb461bff179751f9157c"}, {"color": "#97c2fc", "description": "\"Using early stopping can prevent overfitting by halting training at the optimal point based on validation metrics.\"", "entity_type": "\"UNKNOWN\"", "id": "\"TRAINING DYNAMICS\"", "label": "\"TRAINING DYNAMICS\"", "shape": "dot", "size": 10, "source_id": "chunk-93bfe637d3d9fb461bff179751f9157c"}, {"color": "#97c2fc", "description": "\"In the testing phase, remember to apply the dropout rate consistently across input layers.\"", "entity_type": "\"UNKNOWN\"", "id": "\"DROPOUT RATE\"", "label": "\"DROPOUT RATE\"", "shape": "dot", "size": 10, "source_id": "chunk-93bfe637d3d9fb461bff179751f9157c"}, {"color": "#97c2fc", "description": "\"In the testing phase, remember to apply the dropout rate consistently across input layers.\"", "entity_type": "\"UNKNOWN\"", "id": "\"TESTING PHASE\"", "label": "\"TESTING PHASE\"", "shape": "dot", "size": 10, "source_id": "chunk-93bfe637d3d9fb461bff179751f9157c"}, {"color": "#97c2fc", "description": "\"People in the community are adopting MQA and GQA, indicating a shift towards these technologies.\"", "entity_type": "\"UNKNOWN\"", "id": "\"MQA AND GQA\"", "label": "\"MQA AND GQA\"", "shape": "dot", "size": 10, "source_id": "chunk-b12fb948a61e556d12a7d3e123196d7a"}, {"color": "#97c2fc", "description": "\"People in the community are adopting MQA and GQA, indicating a shift towards these technologies.\"", "entity_type": "\"UNKNOWN\"", "id": "\"PEOPLE\"", "label": "\"PEOPLE\"", "shape": "dot", "size": 10, "source_id": "chunk-b12fb948a61e556d12a7d3e123196d7a"}, {"color": "#97c2fc", "description": "\"A model that performs poorly with multi-epoch training.\"", "entity_type": "\"CONCEPT\"", "id": "\"UL2 MODEL\"", "label": "\"UL2 MODEL\"", "shape": "dot", "size": 10, "source_id": "chunk-9c1eb6ec6cc7c8742be47f032e1488fc"}, {"color": "#97c2fc", "description": "\"A model less affected by multi-epoch training compared to the UL2 model.\"", "entity_type": "\"CONCEPT\"", "id": "\"MLM MODEL\"", "label": "\"MLM MODEL\"", "shape": "dot", "size": 10, "source_id": "chunk-9c1eb6ec6cc7c8742be47f032e1488fc"}, {"color": "#97c2fc", "description": "\"A regularization technique used in deep learning models to prevent overfitting, but often neglected due to computational overhead.\"", "entity_type": "\"TECHNIQUE\"", "id": "\"DROPOUT TECHNIQUE\"", "label": "\"DROPOUT TECHNIQUE\"", "shape": "dot", "size": 10, "source_id": "chunk-9c1eb6ec6cc7c8742be47f032e1488fc"}, {"color": "#97c2fc", "description": "\"An example of a large language model that utilizes dropout during training and benefits from multi-epoch training.\"", "entity_type": "\"CONCEPT\"", "id": "\"GALACTICA MODEL\"", "label": "\"GALACTICA MODEL\"", "shape": "dot", "size": 10, "source_id": "chunk-9c1eb6ec6cc7c8742be47f032e1488fc"}, {"color": "#97c2fc", "description": "\"A large-scale pre-trained language model not using dropout due to computational constraints.\"", "entity_type": "\"ORGANIZATION\"", "id": "\"GPT-3\"", "label": "\"GPT-3\"", "shape": "dot", "size": 10, "source_id": "chunk-9c1eb6ec6cc7c8742be47f032e1488fc"}, {"color": "#97c2fc", "description": "\"A large language model similar to GPT-3 and PaLM, avoiding the use of dropout due to computational costs.\"", "entity_type": "\"CONCEPT\"", "id": "\"LLAMA MODEL\"", "label": "\"LLAMA MODEL\"", "shape": "dot", "size": 10, "source_id": "chunk-9c1eb6ec6cc7c8742be47f032e1488fc"}, {"color": "#97c2fc", "description": "\"Model with mixture-of-experts architecture used for early prediction of performance in large models.\"", "entity_type": "\"CONCEPT\"", "id": "\"MOE MODEL\"", "label": "\"MOE MODEL\"", "shape": "dot", "size": 10, "source_id": "chunk-9c1eb6ec6cc7c8742be47f032e1488fc"}, {"color": "#97c2fc", "description": "\"The MoE model\u0027s performance trends can be used as a proxy for predicting optimal hyperparameters in large language models during training.\"", "entity_type": "\"UNKNOWN\"", "id": "\"LARGE MODELS TRAINING OPTIMIZATION\"", "label": "\"LARGE MODELS TRAINING OPTIMIZATION\"", "shape": "dot", "size": 10, "source_id": "chunk-9c1eb6ec6cc7c8742be47f032e1488fc"}, {"color": "#97c2fc", "description": "\"An input tensor representing the value matrix, which is later combined with attention scores to produce output.\"", "entity_type": "\"VARIABLE\"", "id": "\"VALUE\"", "label": "\"VALUE\"", "shape": "dot", "size": 10, "source_id": "chunk-bdde321da03a10cd546e17bd2a065594"}, {"color": "#97c2fc", "description": "\"The operation calculates attention scores by performing matrix multiplication between query and key matrices transposed and normalizing them.\"", "entity_type": "\"UNKNOWN\"", "id": "\"ATTENTION_SCORES\"", "label": "\"ATTENTION_SCORES\"", "shape": "dot", "size": 10, "source_id": "chunk-bdde321da03a10cd546e17bd2a065594"}, {"color": "#97c2fc", "description": "\"The operation calculates attention scores by performing matrix multiplication between query and key matrices transposed and normalizing them.\"", "entity_type": "\"UNKNOWN\"", "id": "\"TORCH.MATMUL(QUERY, KEY.TRANSPOSE(-1, -2)) / TORCH.SQRT(TORCH.TENSOR(SELF.HEAD_DIM))\"", "label": "\"TORCH.MATMUL(QUERY, KEY.TRANSPOSE(-1, -2)) / TORCH.SQRT(TORCH.TENSOR(SELF.HEAD_DIM))\"", "shape": "dot", "size": 10, "source_id": "chunk-bdde321da03a10cd546e17bd2a065594"}, {"color": "#97c2fc", "description": "\"If provided, the attention_mask modifies the scores by adding a negative value multiplied by the mask, dampening unwanted attention.\"", "entity_type": "\"UNKNOWN\"", "id": "\"ATTENTION_MASK != NONE -\u003e ATTENTION_SCORES += ATTENTION_MASK * -1E-9\"", "label": "\"ATTENTION_MASK != NONE -\u003e ATTENTION_SCORES += ATTENTION_MASK * -1E-9\"", "shape": "dot", "size": 10, "source_id": "chunk-bdde321da03a10cd546e17bd2a065594"}, {"color": "#97c2fc", "description": "\"The attention_mask modifies the scores by adding negative values in certain positions, influencing the final attention weights.\"", "entity_type": "\"UNKNOWN\"", "id": "\"ATTENTION_MASK\"", "label": "\"ATTENTION_MASK\"", "shape": "dot", "size": 10, "source_id": "chunk-bdde321da03a10cd546e17bd2a065594"}, {"color": "#97c2fc", "description": "\"The query and key tensors are involved in calculating attention scores through matrix multiplication.\"", "entity_type": "\"UNKNOWN\"", "id": "\"KEY\"", "label": "\"KEY\"", "shape": "dot", "size": 10, "source_id": "chunk-bdde321da03a10cd546e17bd2a065594"}, {"color": "#97c2fc", "description": "\"The query and key tensors are involved in calculating attention scores through matrix multiplication.\"", "entity_type": "\"UNKNOWN\"", "id": "\"QUERY\"", "label": "\"QUERY\"", "shape": "dot", "size": 10, "source_id": "chunk-bdde321da03a10cd546e17bd2a065594"}, {"color": "#97c2fc", "description": "\"The result of the matrix multiplication is normalized along a specific dimension (score_dim) during the softmax computation.\"", "entity_type": "\"UNKNOWN\"", "id": "\"SCORE_DIM\"", "label": "\"SCORE_DIM\"", "shape": "dot", "size": 10, "source_id": "chunk-bdde321da03a10cd546e17bd2a065594"}, {"color": "#97c2fc", "description": "\"The result of the matrix multiplication is normalized along a specific dimension (score_dim) during the softmax computation.\"", "entity_type": "\"UNKNOWN\"", "id": "\"TORCH.MATMUL(QUERY, KEY.TRANSPOSE(-1, -2))\"", "label": "\"TORCH.MATMUL(QUERY, KEY.TRANSPOSE(-1, -2))\"", "shape": "dot", "size": 10, "source_id": "chunk-bdde321da03a10cd546e17bd2a065594"}, {"color": "#97c2fc", "description": "\"Softmax normalization is applied over a specified dimension (softmax_dim) to produce attention probabilities.\"", "entity_type": "\"UNKNOWN\"", "id": "\"SOFTMAX_DIM\"", "label": "\"SOFTMAX_DIM\"", "shape": "dot", "size": 10, "source_id": "chunk-bdde321da03a10cd546e17bd2a065594"}, {"color": "#97c2fc", "description": "\"Softmax normalization is applied over a specified dimension (softmax_dim) to produce attention probabilities.\"", "entity_type": "\"UNKNOWN\"", "id": "\"TORCH.SOFTMAX(...)\"", "label": "\"TORCH.SOFTMAX(...)\"", "shape": "dot", "size": 10, "source_id": "chunk-bdde321da03a10cd546e17bd2a065594"}, {"color": "#97c2fc", "description": "\"The method calculates scaled dot product attention and generates an output tensor that is a weighted combination of input values based on attention probabilities.\"", "entity_type": "\"UNKNOWN\"", "id": "\"OUTPUT\"", "label": "\"OUTPUT\"", "shape": "dot", "size": 10, "source_id": "chunk-bdde321da03a10cd546e17bd2a065594"}, {"color": "#97c2fc", "description": "\"The method calculates scaled dot product attention and generates an output tensor that is a weighted combination of input values based on attention probabilities.\"", "entity_type": "\"UNKNOWN\"", "id": "\"SELF.SCALE_DOT_PRODUCT_ATTENTION(QUERY, KEY, VALUE)\"", "label": "\"SELF.SCALE_DOT_PRODUCT_ATTENTION(QUERY, KEY, VALUE)\"", "shape": "dot", "size": 10, "source_id": "chunk-bdde321da03a10cd546e17bd2a065594"}, {"color": "#97c2fc", "description": "\"Swish is an activation function used in neural networks that applies a non-linear transformation followed by a sigmoid operation to enhance model performance.\"", "entity_type": "\"CONCEPT\"", "id": "\"SWISH ACTIVATION FUNCTION\"", "label": "\"SWISH ACTIVATION FUNCTION\"", "shape": "dot", "size": 10, "source_id": "chunk-ec973faa85f0a6d3398456bdc53c2faf"}, {"color": "#97c2fc", "description": "\"GLU (Gated Linear Unit) block is a component in Transformer models that performs nonlinear transformations and feature extraction on input vectors.\"", "entity_type": "\"TECHNOLOGY\"", "id": "\"GLU BLOCK\"", "label": "\"GLU BLOCK\"", "shape": "dot", "size": 10, "source_id": "chunk-ec973faa85f0a6d3398456bdc53c2faf"}, {"color": "#97c2fc", "description": "\"ReLU (Rectified Linear Unit) is an activation function widely used in deep learning models that outputs the input directly if it\u0027s positive; otherwise, it will output zero.\"", "entity_type": "\"CONCEPT\"", "id": "\"RELU ACTIVATION FUNCTION\"", "label": "\"RELU ACTIVATION FUNCTION\"", "shape": "dot", "size": 10, "source_id": "chunk-ec973faa85f0a6d3398456bdc53c2faf"}, {"color": "#97c2fc", "description": "\"The Sigmoid function is an activation function that maps any input value to a range between 0 and 1.\"", "entity_type": "\"CONCEPT\"", "id": "\"SIGMOID FUNCTION\"", "label": "\"SIGMOID FUNCTION\"", "shape": "dot", "size": 10, "source_id": "chunk-ec973faa85f0a6d3398456bdc53c2faf"}, {"color": "#97c2fc", "description": "\"A common issue in deep neural networks where gradients become very small during backpropagation, leading to slow or stagnant learning.\"", "entity_type": "\"ISSUE\"", "id": "\"VANISHING GRADIENT PROBLEM\"", "label": "\"VANISHING GRADIENT PROBLEM\"", "shape": "dot", "size": 10, "source_id": "chunk-ec973faa85f0a6d3398456bdc53c2faf"}, {"color": "#97c2fc", "description": "\"\u5143\u6a21\u578b\u8bad\u7ec3\u662f\u6307\u901a\u8fc7\u5c11\u91cf\u9886\u57df\u7279\u5b9a\u6570\u636e\u5feb\u901f\u9002\u5e94\u65b0\u9886\u57df\u7684\u8fc7\u7a0b\uff0c\u53ef\u4ee5\u91c7\u7528\u5728\u7ebf\u5b66\u4e60\u3001\u6a21\u578b\u84b8\u998f\u7b49\u65b9\u6cd5\u3002\"", "entity_type": "\"EVENT\"", "id": "\"\u5143\u6a21\u578b\u8bad\u7ec3\"", "label": "\"\u5143\u6a21\u578b\u8bad\u7ec3\"", "shape": "dot", "size": 10, "source_id": "chunk-b226b02552d812a52faba8fd5d6a1167"}, {"color": "#97c2fc", "description": "\"\u6301\u7eed\u5b66\u4e60\u662f\u6307\u5728\u6a21\u578b\u90e8\u7f72\u540e\u4e0d\u65ad\u6536\u96c6\u9886\u57df\u7279\u5b9a\u6570\u636e\uff0c\u5e76\u6839\u636e\u65b0\u6570\u636e\u66f4\u65b0\u6a21\u578b\u4ee5\u4fdd\u6301\u6027\u80fd\u3002\"", "entity_type": "\"EVENT\"", "id": "\"\u6301\u7eed\u5b66\u4e60\"", "label": "\"\u6301\u7eed\u5b66\u4e60\"", "shape": "dot", "size": 10, "source_id": "chunk-b226b02552d812a52faba8fd5d6a1167"}, {"color": "#97c2fc", "description": "\"\u591a\u4efb\u52a1\u5b66\u4e60\u901a\u8fc7\u540c\u65f6\u8bad\u7ec3\u6a21\u578b\u5904\u7406\u591a\u4e2a\u76f8\u5173\u4efb\u52a1\uff0c\u63d0\u9ad8\u5176\u6cdb\u5316\u80fd\u529b\u3002\"", "entity_type": "\"CONCEPT\"", "id": "\"\u591a\u4efb\u52a1\u5b66\u4e60\"", "label": "\"\u591a\u4efb\u52a1\u5b66\u4e60\"", "shape": "dot", "size": 10, "source_id": "chunk-b226b02552d812a52faba8fd5d6a1167"}, {"color": "#97c2fc", "description": "\"\u5728\u7ebf\u5b66\u4e60\u662f\u4e00\u79cd\u65b9\u6cd5\uff0c\u901a\u8fc7\u8fd9\u79cd\u65b9\u5f0f\u53ef\u4ee5\u5728\u6a21\u578b\u90e8\u7f72\u540e\u4e0d\u65ad\u66f4\u65b0\u6a21\u578b\u4ee5\u9002\u5e94\u65b0\u6570\u636e\u3002\"", "entity_type": "\"METHOD\"", "id": "\"\u5728\u7ebf\u5b66\u4e60\"", "label": "\"\u5728\u7ebf\u5b66\u4e60\"", "shape": "dot", "size": 10, "source_id": "chunk-b226b02552d812a52faba8fd5d6a1167"}, {"color": "#97c2fc", "description": "\"\u6a21\u578b\u84b8\u998f\u662f\u5c06\u77e5\u8bc6\u4ece\u4e00\u4e2a\u590d\u6742\u7684\u9884\u8bad\u7ec3\u6a21\u578b\u8f6c\u79fb\u5230\u4e00\u4e2a\u5c0f\u800c\u9ad8\u6548\u7684\u6a21\u578b\u7684\u8fc7\u7a0b\u3002\"", "entity_type": "\"METHOD\"", "id": "\"\u6a21\u578b\u84b8\u998f\"", "label": "\"\u6a21\u578b\u84b8\u998f\"", "shape": "dot", "size": 10, "source_id": "chunk-b226b02552d812a52faba8fd5d6a1167"}, {"color": "#97c2fc", "description": "\"\u6a21\u578b\u89e3\u91ca\u6027\u6307\u7684\u662f\u4f7f\u7528\u5de5\u5177\uff08\u5982LIME\u3001SHAP\uff09\u6765\u7406\u89e3\u6a21\u578b\u5728\u7279\u5b9a\u9886\u57df\u7684\u9884\u6d4b\u539f\u56e0\uff0c\u53d1\u73b0\u5e76\u8865\u5145\u6f5c\u5728\u7684\u77e5\u8bc6\u7f3a\u5931\u3002\"", "entity_type": "\"CONCEPT\"", "id": "\"\u6a21\u578b\u89e3\u91ca\u6027\"", "label": "\"\u6a21\u578b\u89e3\u91ca\u6027\"", "shape": "dot", "size": 10, "source_id": "chunk-b226b02552d812a52faba8fd5d6a1167"}, {"color": "#97c2fc", "description": "\"LIME\uff08\u5c40\u90e8\u53ef\u89e3\u91ca\u7684\u673a\u5668\u5b66\u4e60\u89e3\u91ca\u5668\uff09\u662f\u4e00\u79cd\u5de5\u5177\uff0c\u7528\u4e8e\u89e3\u91ca\u9884\u6d4b\u6027\u6a21\u578b\u5728\u7279\u5b9a\u5b9e\u4f8b\u4e0a\u7684\u51b3\u7b56\u8fc7\u7a0b\u3002\"", "entity_type": "\"TOOL\"", "id": "\"LIME\"", "label": "\"LIME\"", "shape": "dot", "size": 10, "source_id": "chunk-b226b02552d812a52faba8fd5d6a1167"}, {"color": "#97c2fc", "description": "\"SHAP\uff08Shapley Additive exPlanations\uff09\u662f\u4e00\u79cd\u5de5\u5177\uff0c\u7528\u4e8e\u8ba1\u7b97\u6bcf\u4e2a\u7279\u5f81\u5bf9\u6a21\u578b\u8f93\u51fa\u7684\u5f71\u54cd\u7a0b\u5ea6\uff0c\u5e76\u63d0\u4f9b\u5c40\u90e8\u548c\u5168\u5c40\u7684\u53ef\u89e3\u91ca\u6027\u3002\"", "entity_type": "\"TOOL\"", "id": "\"SHAP\"", "label": "\"SHAP\"", "shape": "dot", "size": 10, "source_id": "chunk-b226b02552d812a52faba8fd5d6a1167"}, {"color": "#97c2fc", "description": "\"\u6570\u636e\u96c6\u662f\u7528\u4e8e\u8bad\u7ec3\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u6570\u636e\u96c6\u5408\u3002\"", "entity_type": "\"CONCEPT\"", "id": "\"\u6570\u636e\u96c6\"", "label": "\"\u6570\u636e\u96c6\"", "shape": "dot", "size": 10, "source_id": "chunk-6e8e06e2596da07feeb6804400bd7f39"}, {"color": "#97c2fc", "description": "\"\u795e\u7ecf\u7f51\u7edc\u57fa\u7840\u662f\u4ecb\u7ecd\u795e\u7ecf\u7f51\u7edc\u57fa\u7840\u77e5\u8bc6\u7684\u4e00\u95e8\u8bfe\u7a0b\u3002\"", "entity_type": "\"EVENT\"", "id": "\"\u795e\u7ecf\u7f51\u7edc\u57fa\u7840\"", "label": "\"\u795e\u7ecf\u7f51\u7edc\u57fa\u7840\"", "shape": "dot", "size": 10, "source_id": "chunk-b598bb5c01c68c8a357b43ff47895be0"}, {"color": "#97c2fc", "description": "\"Transformer\u57fa\u7840\u8bfe\u7a0b\u6db5\u76d6\u4e86\u5173\u4e8eTransformer\u67b6\u6784\u7684\u77e5\u8bc6\u4e0e\u5e94\u7528\u3002\"", "entity_type": "\"EVENT\"", "id": "\"TRANSFORMER\u57fa\u7840\"", "label": "\"TRANSFORMER\u57fa\u7840\"", "shape": "dot", "size": 10, "source_id": "chunk-b598bb5c01c68c8a357b43ff47895be0"}, {"color": "#97c2fc", "description": "\"\u6587\u672c\u7406\u89e3\u548c\u751f\u6210\u5927\u6a21\u578b\u8bfe\u7a0b\u4e13\u6ce8\u4e8e\u5904\u7406\u548c\u751f\u6210\u9ad8\u8d28\u91cf\u6587\u672c\u7684\u6280\u672f\u4e0e\u65b9\u6cd5\u3002\"", "entity_type": "\"EVENT\"", "id": "\"\u6587\u672c\u7406\u89e3\u548c\u751f\u6210\u5927\u6a21\u578b\"", "label": "\"\u6587\u672c\u7406\u89e3\u548c\u751f\u6210\u5927\u6a21\u578b\"", "shape": "dot", "size": 10, "source_id": "chunk-b598bb5c01c68c8a357b43ff47895be0"}, {"color": "#97c2fc", "description": "\"CBOW is a model for predicting the current word based on its surrounding context words, opposite to Skip-gram.\"", "entity_type": "\"CONCEPT\"", "id": "\"CBOW (CONTINUOUS BAG OF WORDS)\"", "label": "\"CBOW (CONTINUOUS BAG OF WORDS)\"", "shape": "dot", "size": 10, "source_id": "chunk-a5bc016656f4a03d7267cf14d747240b"}, {"color": "#97c2fc", "description": "\"ELMo is an approach that uses RNNs to generate context-specific embeddings for words.\"", "entity_type": "\"ORGANIZATION\"", "id": "\"ELMO (EMBEDDINGS FROM LANGUAGE MODELS)\"", "label": "\"ELMO (EMBEDDINGS FROM LANGUAGE MODELS)\"", "shape": "dot", "size": 10, "source_id": "chunk-a5bc016656f4a03d7267cf14d747240b"}, {"color": "#97c2fc", "description": "\"RNN is a neural network architecture used in ELMo to model sequences and contexts of text.\"", "entity_type": "\"TECHNOLOGY\"", "id": "\"RNN (RECURRENT NEURAL NETWORK)\"", "label": "\"RNN (RECURRENT NEURAL NETWORK)\"", "shape": "dot", "size": 10, "source_id": "chunk-a5bc016656f4a03d7267cf14d747240b"}, {"color": "#97c2fc", "description": "\"GloVe uses a co-occurrence matrix to generate word embeddings that capture semantic and syntactic information.\"", "entity_type": "\"CONCEPT\"", "id": "\"GLOVE (GLOBAL VECTORS FOR WORD REPRESENTATION)\"", "label": "\"GLOVE (GLOBAL VECTORS FOR WORD REPRESENTATION)\"", "shape": "dot", "size": 10, "source_id": "chunk-a5bc016656f4a03d7267cf14d747240b"}, {"color": "#97c2fc", "description": "\"BERT is a transformer-based model that generates contextual embeddings by jointly conditioning on both left and right context.\"", "entity_type": "\"CONCEPT\"", "id": "\"BERT (BIDIRECTIONAL ENCODER REPRESENTATIONS FROM TRANSFORMERS)\"", "label": "\"BERT (BIDIRECTIONAL ENCODER REPRESENTATIONS FROM TRANSFORMERS)\"", "shape": "dot", "size": 10, "source_id": "chunk-a5bc016656f4a03d7267cf14d747240b"}, {"color": "#97c2fc", "description": "\"An attention mechanism allows a model to focus on different parts of input sequences when producing an output.\"", "entity_type": "\"TECHNOLOGY\"", "id": "\"ATTENTION MECHANISM\"", "label": "\"ATTENTION MECHANISM\"", "shape": "dot", "size": 10, "source_id": "chunk-a5bc016656f4a03d7267cf14d747240b"}, {"color": "#97c2fc", "description": "\"The forget gate $f_t$ determines how much of the previous cell state $C_{t-1}$ is retained or forgotten, playing a crucial role in managing long-term dependencies.\"", "entity_type": "\"CONCEPT\"", "id": "\"F_T\"", "label": "\"F_T\"", "shape": "dot", "size": 10, "source_id": "chunk-7599a82c6425d3ce2385cbd9da866d60"}, {"color": "#97c2fc", "description": "\"The year 2024 marks a significant advancement in China\u0027s role within the global technology and AI sector.\"", "entity_type": "\"YEAR\"", "id": "\"2024\"", "label": "\"2024\"", "shape": "dot", "size": 10, "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825"}, {"color": "#97c2fc", "description": "\"Global financial institution that provides loans and advice to countries to foster economic stability and development.\"", "entity_type": "\"ORGANIZATION\"", "id": "\"INTERNATIONAL MONETARY FUND (IMF)\"", "label": "\"INTERNATIONAL MONETARY FUND (IMF)\"", "shape": "dot", "size": 10, "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825"}, {"color": "#97c2fc", "description": "\"PyTorch is a popular open-source machine learning library.\"", "entity_type": "\"TECHNOLOGY\"", "id": "\"PYTORCH\"", "label": "\"PYTORCH\"", "shape": "dot", "size": 10, "source_id": "chunk-d0bb534d005985638f5092126303d11c"}, {"color": "#97c2fc", "description": "\"AGI is the goal toward which developments like MOE are contributing, indicating its importance on the path towards achieving general artificial intelligence.\"", "entity_type": "\"CONCEPT\"", "id": "\"AGI (ARTIFICIAL GENERAL INTELLIGENCE)\"", "label": "\"AGI (ARTIFICIAL GENERAL INTELLIGENCE)\"", "shape": "dot", "size": 10, "source_id": "chunk-5474069465781f541726c53600f1b4f7"}, {"color": "#97c2fc", "description": "\"ChatOpenAI is an API wrapper for the OpenAI chat models, facilitating language understanding tasks.\"", "entity_type": "\"CLASS\"", "id": "\"CHATOPENAI\"", "label": "\"CHATOPENAI\"", "shape": "dot", "size": 10, "source_id": "chunk-2ca6daea6a4f0f4a4352f8eba1bc3e4e"}, {"color": "#97c2fc", "description": "\"RetrievalQA chains allow for question-answering over a retrieval system like vector databases.\"", "entity_type": "\"FUNCTION\"", "id": "\"RETRIEVALQA\"", "label": "\"RETRIEVALQA\"", "shape": "dot", "size": 10, "source_id": "chunk-2ca6daea6a4f0f4a4352f8eba1bc3e4e"}, {"color": "#97c2fc", "description": "\"system_template is a template used to instruct the model on how to use provided context.\"", "entity_type": "\"VARIABLE\"", "id": "\"SYSTEM_TEMPLATE\"", "label": "\"SYSTEM_TEMPLATE\"", "shape": "dot", "size": 10, "source_id": "chunk-2ca6daea6a4f0f4a4352f8eba1bc3e4e"}, {"color": "#97c2fc", "description": "\"question represents the input query from the user, which is processed by the retrieval system.\"", "entity_type": "\"VARIABLE\"", "id": "\"QUESTION\"", "label": "\"QUESTION\"", "shape": "dot", "size": 10, "source_id": "chunk-2ca6daea6a4f0f4a4352f8eba1bc3e4e"}, {"color": "#97c2fc", "description": "\"chat_history stores past interactions between the user and the language model for contextual recall.\"", "entity_type": "\"VARIABLE\"", "id": "\"CHAT_HISTORY\"", "label": "\"CHAT_HISTORY\"", "shape": "dot", "size": 10, "source_id": "chunk-2ca6daea6a4f0f4a4352f8eba1bc3e4e"}, {"color": "#97c2fc", "description": "\"Supervised Fine-Tuning refers to a method in machine learning where pre-trained models are further trained using labeled data.\"", "entity_type": "\"CONCEPT\"", "id": "\"SUPERVISED FINE-TUNING\"", "label": "\"SUPERVISED FINE-TUNING\"", "shape": "dot", "size": 10, "source_id": "chunk-c26ea69f0a66020aeea7f3f097753c8d"}, {"color": "#97c2fc", "description": "\"QLoRA is a memory-efficient variant of LoRA designed for scenarios with limited GPU memory resources.\"", "entity_type": "\"METHODOLOGY\"", "id": "\"QLORA\"", "label": "\"QLORA\"", "shape": "dot", "size": 10, "source_id": "chunk-6fb791db271a0a4e393b0080cf334633"}, {"color": "#97c2fc", "description": "\"ChatGLM2-6B refers to a specific version of the ChatGLM model, which can be deployed and fine-tuned according to official tutorials.\"", "entity_type": "\"CONCEPT\"", "id": "\"CHATGLM2-6B \"", "label": "\"CHATGLM2-6B \"", "shape": "dot", "size": 10, "source_id": "chunk-0e87e307fcbe65dbc1b036277c963d52"}, {"color": "#97c2fc", "description": "\"The Code Interpreter functionality allows users to interact with code execution through the model interface.\"", "entity_type": "\"FUNCTIONALITY\"", "id": "\"CODE INTERPRETER\"", "label": "\"CODE INTERPRETER\"", "shape": "dot", "size": 10, "source_id": "chunk-0e87e307fcbe65dbc1b036277c963d52"}, {"color": "#97c2fc", "description": "\"Agent functionality in models like ChatGLM3-6B suggests that it can handle more complex tasks autonomously.\"", "entity_type": "\"FUNCTIONALITY\"", "id": "\"AGENT\"", "label": "\"AGENT\"", "shape": "dot", "size": 10, "source_id": "chunk-0e87e307fcbe65dbc1b036277c963d52"}, {"color": "#97c2fc", "description": "\"This blog post by Yann LeCun discusses recent advancements in AI research, indicating it\u0027s a resource for understanding contemporary developments in the field.\"", "entity_type": "\"DOCUMENT\"", "id": "\"YANN LECUN\u0027S BLOG POST\"", "label": "\"YANN LECUN\u0027S BLOG POST\"", "shape": "dot", "size": 10, "source_id": "chunk-74f6b594f3958fb2771f177186f3dd2c"}, {"color": "#97c2fc", "description": "\"Geekan is likely an individual or a project leader associated with MetaGPT, indicating their role in AI research.\"", "entity_type": "\"PERSON\"", "id": "\"GEEKAN\"", "label": "\"GEEKAN\"", "shape": "dot", "size": 10, "source_id": "chunk-74f6b594f3958fb2771f177186f3dd2c"}, {"color": "#97c2fc", "description": "\"This event discusses critical evolutionary milestones that enabled the development of human language, focusing on neuroscience insights.\"", "entity_type": "\"EVENT\"", "id": "\"PHASE TRANSITIONS OF BRAIN EVOLUTION LEADING TO HUMAN LANGUAGE\"", "label": "\"PHASE TRANSITIONS OF BRAIN EVOLUTION LEADING TO HUMAN LANGUAGE\"", "shape": "dot", "size": 10, "source_id": "chunk-74f6b594f3958fb2771f177186f3dd2c"}, {"color": "#97c2fc", "description": "\"A detailed explanation of the LIDA model\u0027s framework and its application to integrating cognition, emotion, and consciousness.\"", "entity_type": "\"DOCUMENT\"", "id": "\"THE LIDA MODEL: A FRAMEWORK FOR THE INTEGRATION OF COGNITION, EMOTION AND CONSCIOUSNESS\"", "label": "\"THE LIDA MODEL: A FRAMEWORK FOR THE INTEGRATION OF COGNITION, EMOTION AND CONSCIOUSNESS\"", "shape": "dot", "size": 10, "source_id": "chunk-74f6b594f3958fb2771f177186f3dd2c"}, {"color": "#97c2fc", "description": "\"This blog post updates readers on recent advancements in AI research as discussed by Yann LeCun.\"", "entity_type": "\"DOCUMENT\"", "id": "\"YANN LECUN\u0027S AI RESEARCH UPDATE JUNE 2023\"", "label": "\"YANN LECUN\u0027S AI RESEARCH UPDATE JUNE 2023\"", "shape": "dot", "size": 10, "source_id": "chunk-74f6b594f3958fb2771f177186f3dd2c"}, {"color": "#97c2fc", "description": "\"A detailed exploration of the projection mechanism designed to enhance human-like reasoning capabilities in artificial intelligence.\"", "entity_type": "\"DOCUMENT\"", "id": "\"THE PROJECTION MECHANISM FOR HUMAN-LIKE REASONING IN AI\"", "label": "\"THE PROJECTION MECHANISM FOR HUMAN-LIKE REASONING IN AI\"", "shape": "dot", "size": 10, "source_id": "chunk-74f6b594f3958fb2771f177186f3dd2c"}, {"color": "#97c2fc", "description": "\"\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u4f1a\u751f\u6210\u770b\u4f3c\u5408\u7406\u4f46\u5b9e\u9645\u4e0a\u662f\u4e0e\u4e8b\u5b9e\u4e0d\u7b26\u6216\u5b8c\u5168\u865a\u6784\u7684\u4fe1\u606f\uff0c\u8fd9\u79cd\u73b0\u8c61\u79f0\u4e3a\u5e7b\u89c9\u95ee\u9898\u3002\"", "entity_type": "\"CONCEPT\"", "id": "\"\u5e7b\u89c9\u95ee\u9898\"", "label": "\"\u5e7b\u89c9\u95ee\u9898\"", "shape": "dot", "size": 10, "source_id": "chunk-ae2b89823ad29ef6521a8f10eafcf639"}, {"color": "#97c2fc", "description": "\"\u5728\u9884\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f1a\u5b66\u4e60\u5927\u91cf\u7684\u6587\u672c\u6570\u636e\uff0c\u5e76\u4ece\u4e2d\u63d0\u53d6\u51fa\u77e5\u8bc6\u548c\u6a21\u5f0f\uff0c\u8fd9\u4e9b\u6210\u4e3a\u4e86\u5176\u751f\u6210\u56de\u7b54\u7684\u57fa\u7840\u3002\"", "entity_type": "\"CONCEPT\"", "id": "\"\u9884\u8bad\u7ec3\u9636\u6bb5\u83b7\u53d6\u7684\u77e5\u8bc6\"", "label": "\"\u9884\u8bad\u7ec3\u9636\u6bb5\u83b7\u53d6\u7684\u77e5\u8bc6\"", "shape": "dot", "size": 10, "source_id": "chunk-ae2b89823ad29ef6521a8f10eafcf639"}, {"color": "#97c2fc", "description": "\"A tendency for AI models to rely too heavily on their internal knowledge during generation, sometimes at the expense of factual accuracy.\"", "entity_type": "\"CONCEPT\"", "id": "\"INTERNALIZED KNOWLEDGE BIAS\"", "label": "\"INTERNALIZED KNOWLEDGE BIAS\"", "shape": "dot", "size": 10, "source_id": "chunk-b43020db5fae0ade6540f46dc8c909d7"}, {"color": "#97c2fc", "description": "\"\u4ecb\u7ecd\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u7684\u53d1\u5c55\u5386\u7a0b\u53ca\u5176\u91cd\u8981\u91cc\u7a0b\u7891\u3002\"", "entity_type": "\"ORGANIZATION\"", "id": "\"\u7ec4\u7ec7\u7ed3\u6784\uff08\u5927\u6a21\u578b\u53d1\u5c55\u5386\u7a0b\uff09\"", "label": "\"\u7ec4\u7ec7\u7ed3\u6784\uff08\u5927\u6a21\u578b\u53d1\u5c55\u5386\u7a0b\uff09\"", "shape": "dot", "size": 10, "source_id": "chunk-83f4aea6a8402d9c9f99736cbb2135d4"}, {"color": "#97c2fc", "description": "\"\u6ce8\u610f\u529b\u673a\u5236\u662f\u4e00\u79cd\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\uff0c\u7528\u4e8e\u5904\u7406\u5e8f\u5217\u6570\u636e\uff0c\u5e76\u4e14\u662f\u8bb8\u591a\u73b0\u4ee3\u5927\u6a21\u578b\u7684\u5173\u952e\u7ec4\u4ef6\u4e4b\u4e00\u3002\"", "entity_type": "\"TECHNIQUE\"", "id": "\"\u6ce8\u610f\u529b\u673a\u5236\uff08ATTENTION MECHANISM\uff09\"", "label": "\"\u6ce8\u610f\u529b\u673a\u5236\uff08ATTENTION MECHANISM\uff09\"", "shape": "dot", "size": 10, "source_id": "chunk-83f4aea6a8402d9c9f99736cbb2135d4"}, {"color": "#97c2fc", "description": "\"\u9884\u8bad\u7ec3\u662f\u63d0\u9ad8\u8bed\u8a00\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u901a\u5e38\u5728\u5927\u89c4\u6a21\u8bed\u6599\u5e93\u4e0a\u8fdb\u884c\u3002\"", "entity_type": "\"PROCESS\"", "id": "\"\u9884\u8bad\u7ec3\uff08PRE-TRAINING\uff09\"", "label": "\"\u9884\u8bad\u7ec3\uff08PRE-TRAINING\uff09\"", "shape": "dot", "size": 10, "source_id": "chunk-83f4aea6a8402d9c9f99736cbb2135d4"}, {"color": "#97c2fc", "description": "\"\u5fae\u8c03\u662f\u6307\u5728\u7279\u5b9a\u4efb\u52a1\u4e0a\u5bf9\u7ecf\u8fc7\u9884\u8bad\u7ec3\u7684\u6a21\u578b\u8fdb\u884c\u8fdb\u4e00\u6b65\u4f18\u5316\u7684\u8fc7\u7a0b\u3002\"", "entity_type": "\"PROCESS\"", "id": "\"\u5fae\u8c03\uff08FINE-TUNING\uff09\"", "label": "\"\u5fae\u8c03\uff08FINE-TUNING\uff09\"", "shape": "dot", "size": 10, "source_id": "chunk-83f4aea6a8402d9c9f99736cbb2135d4"}, {"color": "#97c2fc", "description": "\"\u4e0a\u4e0b\u6587\u611f\u77e5\u662f\u6307\u80fd\u591f\u7406\u89e3\u5e76\u5229\u7528\u6587\u672c\u4e2d\u8bcd\u8bed\u4e4b\u95f4\u7684\u5173\u7cfb\u6765\u8fdb\u884c\u66f4\u51c6\u786e\u7684\u7406\u89e3\u6216\u751f\u6210\u3002\"", "entity_type": "\"PROPERTY\"", "id": "\"\u4e0a\u4e0b\u6587\u611f\u77e5\uff08CONTEXT-AWARE\uff09\"", "label": "\"\u4e0a\u4e0b\u6587\u611f\u77e5\uff08CONTEXT-AWARE\uff09\"", "shape": "dot", "size": 10, "source_id": "chunk-83f4aea6a8402d9c9f99736cbb2135d4"}, {"color": "#97c2fc", "description": "\"A method used in training neural networks with a hierarchical structure based on Huffman trees to optimize efficiency and reduce computational cost.\"", "entity_type": "\"TECHNIQUE\"", "id": "\"HIERARCHICAL SOFTMAX\"", "label": "\"HIERARCHICAL SOFTMAX\"", "shape": "dot", "size": 10, "source_id": "chunk-3f62ab700a27dc35ef09772985ebc7b4"}, {"color": "#97c2fc", "description": "\"\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u8f83\u957f\u7684\u6587\u672c\u4f1a\u5bfc\u81f4\u66f4\u9ad8\u7684\u5185\u5b58\u548c\u8ba1\u7b97\u9700\u6c42\u3002\"\u003cSEP\u003e\"\u8f83\u957f\u7684\u6587\u672c\u9700\u8981\u66f4\u591a\u7684\u5185\u5b58\u548c\u8ba1\u7b97\u65f6\u95f4\uff0c\u56e0\u6b64\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u9700\u8981\u8003\u8651\u8ba1\u7b97\u8d44\u6e90\u7684\u9650\u5236\u3002\"", "entity_type": "\"CONCEPT\"", "id": "\"\u8ba1\u7b97\u8d44\u6e90\u9650\u5236\"", "label": "\"\u8ba1\u7b97\u8d44\u6e90\u9650\u5236\"", "shape": "dot", "size": 10, "source_id": "chunk-b3e463d24adf84b28a5376fc9c10716b"}, {"color": "#97c2fc", "description": "\"\u5904\u7406\u957f\u65f6\u95f4\u5e8f\u5217\u6216\u957f\u6587\u672c\u65f6\u9700\u6ce8\u610f\u65f6\u95f4\u6210\u672c\u53ca\u6548\u7387\u3002\"", "entity_type": "\"CONCEPT\"", "id": "\"\u65f6\u95f4\u9650\u5236\"", "label": "\"\u65f6\u95f4\u9650\u5236\"", "shape": "dot", "size": 10, "source_id": "chunk-b3e463d24adf84b28a5376fc9c10716b"}, {"color": "#97c2fc", "description": "\"\u5728\u5904\u7406\u957f\u65f6\u95f4\u5e8f\u5217\u6216\u957f\u6587\u672c\u65f6\uff0c\u9700\u8003\u8651\u65f6\u95f4\u548c\u8ba1\u7b97\u6548\u7387\u7684\u5e73\u8861\u3002\"", "entity_type": "\"CONCEPT\"", "id": "\"\u65f6\u95f4\u6210\u672c\"", "label": "\"\u65f6\u95f4\u6210\u672c\"", "shape": "dot", "size": 10, "source_id": "chunk-b3e463d24adf84b28a5376fc9c10716b"}, {"color": "#97c2fc", "description": "\"\u4fe1\u606f\u7406\u8bba\u662f\u8bed\u8a00\u6a21\u578b\u7814\u7a76\u7684\u80cc\u666f\u4e4b\u4e00\uff0c\u7528\u4e8e\u4f30\u8ba1\u82f1\u8bed\u71b5\u503c\u3002\"", "entity_type": "\"CONCEPT\"", "id": "\"\u4fe1\u606f\u7406\u8bba\"", "label": "\"\u4fe1\u606f\u7406\u8bba\"", "shape": "dot", "size": 10, "source_id": "chunk-3265869f4b91b0e4feb100fa049dcf4b"}, {"color": "#97c2fc", "description": "\"Determines how quickly the model adapts during training.\"", "entity_type": "\"CONCEPT\"", "id": "\"TRANSFORMER LEARNING RATE\"", "label": "\"TRANSFORMER LEARNING RATE\"", "shape": "dot", "size": 10, "source_id": "chunk-93bfe637d3d9fb461bff179751f9157c"}, {"color": "#97c2fc", "description": "\"DAE, or Denoise Autoencoder, refers to a method of training neural networks where the model learns to reconstruct clean data from noisy inputs. In NLP context, it involves masking words and predicting them based on the surrounding context.\"", "entity_type": "\"CONCEPT\"", "id": "\"DAE (DENOISE AUTOENCODER)\"", "label": "\"DAE (DENOISE AUTOENCODER)\"", "shape": "dot", "size": 10, "source_id": "chunk-8e8cfc5ae7b8cf839dfcb6baedbbf29d"}, {"color": "#97c2fc", "description": "\"MQA appears to be a technology or tool that people are currently using.\"", "entity_type": "\"TECHNOLOGY\"", "id": "\"MQA\"", "label": "\"MQA\"", "shape": "dot", "size": 10, "source_id": "chunk-b12fb948a61e556d12a7d3e123196d7a"}, {"color": "#97c2fc", "description": "\"GQA is another technology or tool referenced as being widely used by the community.\"", "entity_type": "\"TECHNOLOGY\"", "id": "\"GQA\"", "label": "\"GQA\"", "shape": "dot", "size": 10, "source_id": "chunk-b12fb948a61e556d12a7d3e123196d7a"}, {"color": "#97c2fc", "description": "\"Another example of a large-scale pre-trained language model that does not use dropout, likely for performance reasons.\"", "entity_type": "\"ORGANIZATION\"", "id": "\"PALM\"", "label": "\"PALM\"", "shape": "dot", "size": 10, "source_id": "chunk-9c1eb6ec6cc7c8742be47f032e1488fc"}, {"color": "#97c2fc", "description": "\"Pre Norm refers to a normalization technique that is easier to train but generally less effective than Post Norm.\"", "entity_type": "\"TECHNOLOGY\"", "id": "\"PRE NORM\"", "label": "\"PRE NORM\"", "shape": "dot", "size": 10, "source_id": "chunk-641acae03e02a2778a561717756acfee"}, {"color": "#97c2fc", "description": "\"Self refers to an instance of a class managing attention mechanisms within neural networks.\"", "entity_type": "\"ORGANIZATION\"", "id": "\"SELF\"", "label": "\"SELF\"", "shape": "dot", "size": 10, "source_id": "chunk-bdde321da03a10cd546e17bd2a065594"}, {"color": "#97c2fc", "description": "\"These are PyTorch functions used for matrix multiplication and computing softmax normalization, respectively.\"", "entity_type": "\"TECHNOLOGY\"", "id": "\"TORCH.MATMUL\", \"TORCH.SOFTMAX\"", "label": "\"TORCH.MATMUL\", \"TORCH.SOFTMAX\"", "shape": "dot", "size": 10, "source_id": "chunk-bdde321da03a10cd546e17bd2a065594"}, {"color": "#97c2fc", "description": "\"Input tensors representing the query and key matrices used in calculating attention scores.\"", "entity_type": "\"VARIABLE\"", "id": "\"QUERY\", \"KEY\"", "label": "\"QUERY\", \"KEY\"", "shape": "dot", "size": 10, "source_id": "chunk-bdde321da03a10cd546e17bd2a065594"}, {"color": "#97c2fc", "description": "\"A method within the class that calculates scaled dot product attention using query, key, and value tensors.\"", "entity_type": "\"METHOD\"", "id": "\"SELF.SCALE_DOT_PRODUCT_ATTENTION\"", "label": "\"SELF.SCALE_DOT_PRODUCT_ATTENTION\"", "shape": "dot", "size": 10, "source_id": "chunk-bdde321da03a10cd546e17bd2a065594"}, {"color": "#97c2fc", "description": "\"Dimensions over which scores or softmax operations will be calculated.\"", "entity_type": "\"VARIABLE\"", "id": "\"SCORE_DIM\", \"SOFTMAX_DIM\"", "label": "\"SCORE_DIM\", \"SOFTMAX_DIM\"", "shape": "dot", "size": 10, "source_id": "chunk-bdde321da03a10cd546e17bd2a065594"}, {"color": "#97c2fc", "description": "\"A Transformer is a neural network architecture designed for handling sequential data, particularly in tasks such as natural language processing.\"", "entity_type": "\"TECHNOLOGY\"", "id": "\"TRANSFORMER MODEL\"", "label": "\"TRANSFORMER MODEL\"", "shape": "dot", "size": 10, "source_id": "chunk-ec973faa85f0a6d3398456bdc53c2faf"}, {"color": "#97c2fc", "description": "\"\u7b56\u7565\u68af\u5ea6\u662f\u4e00\u79cd\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u7528\u4e8e\u6307\u5bfc\u51b3\u7b56\u8fc7\u7a0b\u4e2d\u7684\u884c\u4e3a\u9009\u62e9\u3002\"", "entity_type": "\"CONCEPT\"", "id": "\"\u7b56\u7565\u68af\u5ea6\uff08PG\uff09\"", "label": "\"\u7b56\u7565\u68af\u5ea6\uff08PG\uff09\"", "shape": "dot", "size": 10, "source_id": "chunk-8d8c962534d489403cf773b04a4a653f"}, {"color": "#97c2fc", "description": "\"\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\u662f\u6539\u8fdb\u7248\u7684\u7b56\u7565\u68af\u5ea6\u7b97\u6cd5\uff0c\u65e8\u5728\u63d0\u5347\u8bad\u7ec3\u6548\u7387\u548c\u6027\u80fd\u7a33\u5b9a\u6027\u3002\"", "entity_type": "\"CONCEPT\"", "id": "\"\u8fd1\u7aef\u7b56\u7565\u4f18\u5316(PPO)\"", "label": "\"\u8fd1\u7aef\u7b56\u7565\u4f18\u5316(PPO)\"", "shape": "dot", "size": 10, "source_id": "chunk-8d8c962534d489403cf773b04a4a653f"}, {"color": "#97c2fc", "description": "\"\u8fd9\u662f\u4e00\u4e2a\u5173\u4e8e\u5982\u4f55\u4f7f\u7528PPO\u6765\u7406\u89e3\u548c\u5b9e\u73b0\u5927\u89c4\u6a21\u6a21\u578b\u4e2dRLHF\u6280\u672f\u7684\u6587\u7ae0\u6216\u6559\u7a0b\u3002\"", "entity_type": "\"DOCUMENT\"", "id": "\"\u5927\u6a21\u578bRLHF\uff1aPPO\u539f\u7406\u4e0e\u6e90\u7801\u89e3\u8bfb\"", "label": "\"\u5927\u6a21\u578bRLHF\uff1aPPO\u539f\u7406\u4e0e\u6e90\u7801\u89e3\u8bfb\"", "shape": "dot", "size": 10, "source_id": "chunk-8d8c962534d489403cf773b04a4a653f"}, {"color": "#97c2fc", "description": "\"\u6587\u6863\u7684\u7ec4\u7ec7\u7ed3\u6784\u5305\u62ec\u5f3a\u5316\u5b66\u4e60\u539f\u7406\u3001RLHF\u548c\u4e00\u4e9b\u9898\u76ee\uff0c\u6bcf\u4e2a\u90e8\u5206\u90fd\u5305\u542b\u8be6\u7ec6\u7684\u5185\u5bb9\u94fe\u63a5\u3002\"", "entity_type": "\"ORGANIZATION\"", "id": "\"\u7ec4\u7ec7\u7ed3\u6784\"", "label": "\"\u7ec4\u7ec7\u7ed3\u6784\"", "shape": "dot", "size": 10, "source_id": "chunk-8d8c962534d489403cf773b04a4a653f"}, {"color": "#97c2fc", "description": "\"\u4ef7\u503c\u51fd\u6570\u8bc4\u4f30\u5728\u4e00\u4e2a\u7279\u5b9a\u72b6\u6001\u4e0b\u91c7\u53d6\u884c\u52a8\u540e\u7684\u9884\u671f\u56de\u62a5\u3002\"", "entity_type": "\"CONCEPT\"", "id": "\"\u4ef7\u503c\u51fd\u6570\uff08VF\uff09\"", "label": "\"\u4ef7\u503c\u51fd\u6570\uff08VF\uff09\"", "shape": "dot", "size": 10, "source_id": "chunk-8d8c962534d489403cf773b04a4a653f"}, {"color": "#97c2fc", "description": "\"\u4f18\u52bf\u51fd\u6570\u8861\u91cf\u4e00\u4e2a\u52a8\u4f5c\u76f8\u5bf9\u4e8e\u5e73\u5747\u7b56\u7565\u7684\u597d\u574f\u7a0b\u5ea6\uff0c\u662f\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u4e00\u4e2a\u91cd\u8981\u6982\u5ff5\u3002\"", "entity_type": "\"CONCEPT\"", "id": "\"\u4f18\u52bf\u51fd\u6570\uff08ADVANTAGE FUNCTION\uff09\"", "label": "\"\u4f18\u52bf\u51fd\u6570\uff08ADVANTAGE FUNCTION\uff09\"", "shape": "dot", "size": 10, "source_id": "chunk-8d8c962534d489403cf773b04a4a653f"}, {"color": "#97c2fc", "description": "\"\u4e00\u79cd\u57fa\u4e8e\u4ef7\u503c\u7684\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u901a\u8fc7\u8fed\u4ee3\u66f4\u65b0\u6bcf\u4e2a\u72b6\u6001-\u884c\u52a8\u5bf9\u7684Q\u503c\u6765\u627e\u5230\u6700\u4f18\u7b56\u7565\u3002\"", "entity_type": "\"CONCEPT\"", "id": "\"Q\u5b66\u4e60\uff08Q-LEARNING\uff09\"", "label": "\"Q\u5b66\u4e60\uff08Q-LEARNING\uff09\"", "shape": "dot", "size": 10, "source_id": "chunk-8d8c962534d489403cf773b04a4a653f"}, {"color": "#97c2fc", "description": "\"DDPG\u7ed3\u5408\u4e86DQN\u548cActor-Critic\u65b9\u6cd5\u7684\u4f18\u70b9\uff0c\u9002\u7528\u4e8e\u8fde\u7eed\u52a8\u4f5c\u7a7a\u95f4\u4e2d\u7684\u4efb\u52a1\u3002\"", "entity_type": "\"CONCEPT\"", "id": "\"\u6df1\u5ea6\u786e\u5b9a\u6027\u7b56\u7565\u68af\u5ea6(DDPG)\"", "label": "\"\u6df1\u5ea6\u786e\u5b9a\u6027\u7b56\u7565\u68af\u5ea6(DDPG)\"", "shape": "dot", "size": 10, "source_id": "chunk-8d8c962534d489403cf773b04a4a653f"}, {"color": "#97c2fc", "description": "\"Proximal Policy Optimization (PPO) is a method compared against DPO in terms of KL divergence and robustness to sampling temperature.\"", "entity_type": "\"CONCEPT\"", "id": "\"PPO\"", "label": "\"PPO\"", "shape": "dot", "size": 10, "source_id": "chunk-115db5344fc770c67e60120f710f8c9e"}, {"color": "#97c2fc", "description": "\"The Discriminator is an entity that evaluates the quality of generated images, giving higher scores to expert-generated images and lower scores to those produced by the Generator.\"", "entity_type": "\"ORGANIZATION\"", "id": "\"\u5224\u522b\u5668 (DISCRIMINATOR)\"", "label": "\"\u5224\u522b\u5668 (DISCRIMINATOR)\"", "shape": "dot", "size": 10, "source_id": "chunk-c26212a0e7bd7decce1d2146431138cc"}]);
                  edges = new vis.DataSet([{"description": "\"Data Format influences how Model Parameters are configured and optimized during the training process.\"", "from": "\"\u6570\u636e\u683c\u5f0f\"", "keywords": "\"data structure, model optimization\"", "source_id": "chunk-6e8e06e2596da07feeb6804400bd7f39", "to": "\"\u6a21\u578b\u53c2\u6570\"", "width": 7.0}, {"description": "\"\u6587\u672c\u6570\u636e\u96c6\u53ef\u4ee5\u4e3a\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e30\u5bcc\u7684\u7f51\u9875\u6587\u672c\u7528\u4e8e\u8bad\u7ec3.\"", "from": "\"\u6587\u672c\u6570\u636e\u96c6\"", "keywords": "\"\u8bad\u7ec3\u8d44\u6e90, \u6570\u636e\u6765\u6e90\"", "source_id": "chunk-c9c11d3ee2bf51fe807387d8004e7aec", "to": "\"\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\"", "width": 1.0}, {"description": "\"\u901a\u8fc7\u4f7f\u7528\u6587\u672c\u6570\u636e\u96c6\u4e2d\u7684\u76f8\u5173\u7f51\u9875\u5185\u5bb9\u53ef\u4ee5\u6269\u5c55\u6216\u521b\u5efa\u7279\u5b9a\u9886\u57df\u7684\u8bad\u7ec3\u6570\u636e\u3002", "from": "\"\u6587\u672c\u6570\u636e\u96c6\"", "keywords": "\"\u8de8\u57df\u77e5\u8bc6, \u9886\u57df\u62d3\u5c55\"", "source_id": "chunk-c9c11d3ee2bf51fe807387d8004e7aec", "to": "\"\u9886\u57df\u7279\u5b9a\u6570\u636e\u96c6\"", "width": 4.0}, {"description": "\"BookCorpus\u63d0\u4f9b\u4e86\u5e7f\u6cdb\u7684\u4e3b\u9898\u548c\u9886\u57df\u7684\u56fe\u4e66\u6587\u672c\uff0c\u9002\u5408\u4e8e\u5e7f\u6cdb\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1.\"", "from": "\"BOOKCORPUS\"", "keywords": "\"\u4e13\u4e1a\u5185\u5bb9, \u8bad\u7ec3\u6750\u6599\"", "source_id": "chunk-c9c11d3ee2bf51fe807387d8004e7aec", "to": "\"\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\"", "width": 2.0}, {"description": "\"\u65b0\u95fb\u6587\u7ae0\u662f\u83b7\u53d6\u67d0\u4e00\u7279\u5b9a\u9886\u57df\u4fe1\u606f\u7684\u91cd\u8981\u6765\u6e90\uff0c\u53ef\u7528\u4e8e\u6784\u5efa\u9886\u57df\u7279\u5b9a\u7684\u6570\u636e\u96c6.\"", "from": "\"\u65b0\u95fb\u6587\u7ae0\"", "keywords": "\"\u65f6\u4e8b\u52a8\u6001, \u4e13\u4e1a\u77e5\u8bc6\"", "source_id": "chunk-c9c11d3ee2bf51fe807387d8004e7aec", "to": "\"\u9886\u57df\u7279\u5b9a\u6570\u636e\u96c6\"", "width": 3.0}, {"description": "\"Sam Rivera works on communicating with an unknown intelligence, dealing with the profound implications for humanity.\"", "from": "\"SAM RIVERA\"", "keywords": "\"communication, cosmic play\"", "source_id": "chunk-c9c11d3ee2bf51fe807387d8004e7aec", "to": "\"INTELLIGENCE\"", "width": 9.0}, {"description": "\"Sam Rivera \u662f\u8be5\u56e2\u961f\u7684\u4e00\u5458\uff0c\u8d1f\u8d23\u6c9f\u901a\u5de5\u4f5c\u3002\u4ed6\u611f\u5230\u65e2\u656c\u754f\u53c8\u7126\u8651\u3002\"", "from": "\"SAM RIVERA\"", "keywords": "\"\u6210\u5458, \u6c9f\u901a\u8005\"", "source_id": "chunk-c9c11d3ee2bf51fe807387d8004e7aec", "to": "\"\u56e2\u961f\"", "width": 5.0}, {"description": "\"Sam Rivera \u662f\u4e0e\u672a\u77e5\u667a\u80fd\u6c9f\u901a\u4efb\u52a1\u7684\u4e00\u90e8\u5206\uff0c\u4ed6\u4e3a\u6b64\u611f\u5230\u656c\u754f\u548c\u7126\u8651\u3002\"", "from": "\"SAM RIVERA\"", "keywords": "\"\u6267\u884c\u8005, \u6c9f\u901a\"", "source_id": "chunk-c9c11d3ee2bf51fe807387d8004e7aec", "to": "\"\u4efb\u52a1\"", "width": 7.0}, {"description": "\"Alex is leading a team in making first contact with an unknown intelligence, recognizing its historical importance.\"", "from": "\"ALEX\"", "keywords": "\"leadership, exploration\"", "source_id": "chunk-c9c11d3ee2bf51fe807387d8004e7aec", "to": "\"FIRST CONTACT\"", "width": 10.0}, {"description": "\"Alex \u9886\u5bfc\u7740\u8fd9\u4e2a\u5c1d\u8bd5\u9996\u6b21\u63a5\u89e6\u672a\u77e5\u667a\u80fd\u7684\u56e2\u961f\uff0c\u5e76\u4e14\u8ba4\u8bc6\u5230\u4e86\u4ed6\u4eec\u4efb\u52a1\u7684\u91cd\u5927\u610f\u4e49\u3002", "from": "\"ALEX\"", "keywords": "\"\u9886\u5bfc\u8005, \u6210\u5458\"", "source_id": "chunk-c9c11d3ee2bf51fe807387d8004e7aec", "to": "\"\u56e2\u961f\"", "width": 6.0}, {"description": "\"Alex \u662f\u9886\u5bfc\u9996\u6b21\u63a5\u89e6\u672a\u77e5\u667a\u80fd\u7684\u4efb\u52a1\u7684\u4eba\uff0c\u8ba4\u8bc6\u5230\u5b83\u5bf9\u5386\u53f2\u7684\u91cd\u5927\u610f\u4e49\u3002", "from": "\"ALEX\"", "keywords": "\"\u9886\u5bfc\u8005, \u4efb\u52a1\u7ba1\u7406\"", "source_id": "chunk-c9c11d3ee2bf51fe807387d8004e7aec", "to": "\"\u4efb\u52a1\"", "width": 8.0}, {"description": "\"An unknown intelligence is engaging in a potential first contact scenario with humanity.\"", "from": "\"FIRST CONTACT\"", "keywords": "\"interaction\"", "source_id": "chunk-2ca6daea6a4f0f4a4352f8eba1bc3e4e", "to": "\"UNKNOWN INTELLIGENCE\"", "width": 2.0}, {"description": "\"\u6e05\u534e\u5927\u5b66\u63d0\u4f9b\u4e86\u5173\u4e8e\u81ea\u7136\u8bed\u8a00\u5904\u7406\u548c\u5927\u578b\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u57fa\u7840\u77e5\u8bc6\u7684\u8bfe\u7a0b\u3002\"", "from": "\"\u6e05\u534e\u5927\u5b66\"", "keywords": "\"\u6559\u80b2,\u6280\u672f\u666e\u53ca\"", "source_id": "chunk-b598bb5c01c68c8a357b43ff47895be0", "to": "\"NLP\u0026\u5927\u6a21\u578b\u57fa\u7840\"", "width": 9.0}, {"description": "\"\u6e05\u534e\u5927\u5b66\u63d0\u4f9b\u4e86\u4ecb\u7ecd\u81ea\u7136\u8bed\u8a00\u5904\u7406\u57fa\u672c\u6982\u5ff5\u548c\u6280\u672f\u7684\u57fa\u7840\u77e5\u8bc6\u8bfe\u7a0b\u3002\"", "from": "\"\u6e05\u534e\u5927\u5b66\"", "keywords": "\"\u6559\u80b2,\u6280\u672f\u666e\u53ca\"", "source_id": "chunk-b598bb5c01c68c8a357b43ff47895be0", "to": "\"NLP\u57fa\u7840\"", "width": 9.0}, {"description": "\"\u6e05\u534e\u5927\u5b66\u8bb2\u89e3\u4e86\u7528\u4e8eNLP\u4efb\u52a1\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u548c\u7b97\u6cd5\u7684\u57fa\u7840\u77e5\u8bc6\u3002\"", "from": "\"\u6e05\u534e\u5927\u5b66\"", "keywords": "\"\u6559\u80b2,\u6280\u672f\u666e\u53ca\"", "source_id": "chunk-b598bb5c01c68c8a357b43ff47895be0", "to": "\"\u6df1\u5ea6\u5b66\u4e60\u57fa\u7840\"", "width": 8.0}, {"description": "\"\u6e05\u534e\u5927\u5b66\u4ecb\u7ecd\u4e86\u9ad8\u6548\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6280\u672f\uff0c\u4f8b\u5982\u51cf\u5c11\u8ba1\u7b97\u91cf\u548c\u63d0\u9ad8\u54cd\u5e94\u901f\u5ea6\u3002\"", "from": "\"\u6e05\u534e\u5927\u5b66\"", "keywords": "\"\u6559\u80b2,\u6280\u672f\u666e\u53ca\"", "source_id": "chunk-b598bb5c01c68c8a357b43ff47895be0", "to": "\"\u9ad8\u6548\u63a8\u7406\"", "width": 6.0}, {"description": "\"\u6e05\u534e\u5927\u5b66\u8ba8\u8bba\u4e86\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6280\u672f\u5728\u6784\u5efa\u667a\u80fd\u5bf9\u8bdd\u7cfb\u7edf\u4e2d\u7684\u5e94\u7528\u3002\"", "from": "\"\u6e05\u534e\u5927\u5b66\"", "keywords": "\"\u6559\u80b2,\u6280\u672f\u666e\u53ca\"", "source_id": "chunk-b598bb5c01c68c8a357b43ff47895be0", "to": "\"NLP\u4e0e\u5bf9\u8bdd\u7cfb\u7edf\"", "width": 4.0}, {"description": "\"OpenBMB\u9879\u76ee\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5173\u4e8e\u5982\u4f55\u6709\u6548\u7387\u5730\u8bad\u7ec3\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u6a21\u578b\u53ca\u51cf\u5c11\u5176\u5927\u5c0f\u7684\u65b9\u6cd5\u7684\u8d44\u6e90\u5e73\u53f0\u3002\"", "from": "\"OPENBMB\"", "keywords": "\"\u6559\u80b2\u8d44\u6e90,\u6280\u672f\u521b\u65b0\"", "source_id": "chunk-b598bb5c01c68c8a357b43ff47895be0", "to": "\"\u9ad8\u6548\u8bad\u7ec3\u0026\u6a21\u578b\u538b\u7f29\"", "width": 8.0}, {"description": "\"OpenBMB\u63d0\u4f9b\u4e86\u5173\u4e8e\u4f18\u5316\u9884\u8bad\u7ec3\u6a21\u578b\u4ee5\u9002\u5e94\u7279\u5b9a\u4efb\u52a1\u7684\u6280\u672f\u8d44\u6e90\u5e73\u53f0\u3002\"", "from": "\"OPENBMB\"", "keywords": "\"\u6559\u80b2\u8d44\u6e90,\u6280\u672f\u521b\u65b0\"", "source_id": "chunk-b598bb5c01c68c8a357b43ff47895be0", "to": "\"PROMPT TUNING \u0026 DELTA TUNING\"", "width": 7.0}, {"description": "\"OpenBMB\u5c55\u793a\u4e86\u5229\u7528NLP\u6a21\u578b\u8fdb\u884c\u9ad8\u8d28\u91cf\u7684\u6587\u672c\u751f\u6210\u7684\u6280\u672f\u8d44\u6e90\u5e73\u53f0\u3002\"", "from": "\"OPENBMB\"", "keywords": "\"\u6559\u80b2\u8d44\u6e90,\u6280\u672f\u521b\u65b0\"", "source_id": "chunk-b598bb5c01c68c8a357b43ff47895be0", "to": "\"\u6587\u672c\u751f\u6210\"", "width": 5.0}, {"description": "\"The n-2 layer scheme is an approach to optimize the use of layers on a single GPU by fixing most layers while scheduling some, thereby reducing loading parameter overhead.\"", "from": "\"N-2\u5c42\u65b9\u6848\"", "keywords": "\"optimization, hardware management\"", "source_id": "chunk-cb8cae2c05a476558bae2291e8b82de7", "to": "\"GPU\"", "width": 9.0}, {"description": "\"The n-2 layer scheme is applied to optimize the execution of deep learning models by fixing most layers while scheduling some, reducing overhead.\"", "from": "\"N-2\u5c42\u65b9\u6848\"", "keywords": "\"optimization, model performance\"", "source_id": "chunk-cb8cae2c05a476558bae2291e8b82de7", "to": "\"DEEP LEARNING MODELS\"", "width": 8.0}, {"description": "\"Layer scheduling techniques are used to optimize the use of a GPU\u0027s processing power and memory capacity in deep learning applications.\"", "from": "\"GPU\"", "keywords": "\"hardware management, performance enhancement\"", "source_id": "chunk-cb8cae2c05a476558bae2291e8b82de7", "to": "\"LAYER SCHEDULING\"", "width": 8.0}, {"description": "\"The BMInf package enables the execution of large-scale models on GTX1060 GPUs by optimizing resource usage.\"", "from": "\"BMINF\u5305\"", "keywords": "\"software optimization, model deployment\"", "source_id": "chunk-cb8cae2c05a476558bae2291e8b82de7", "to": "\"GTX1060\"", "width": 8.0}, {"description": "\"The BMInf package helps reduce loading parameter overhead when executing large-scale models on limited GPU resources.\"", "from": "\"BMINF\u5305\"", "keywords": "\"software optimization, efficiency improvement\"", "source_id": "chunk-cb8cae2c05a476558bae2291e8b82de7", "to": "\"LOADING PARAMETER OVERHEAD\"", "width": 7.0}, {"description": "\"Skip-gram models predict context words from a central word, while CBOW predicts the central word based on its context.\"", "from": "\"SKIP-GRAM\"", "keywords": "\"word embedding methods, prediction direction\"", "source_id": "chunk-a5bc016656f4a03d7267cf14d747240b", "to": "\"CBOW\"", "width": 6.0}, {"description": "\"Skip-gram is one of the two models included in Word2Vec, the other being CBOW.\"", "from": "\"SKIP-GRAM\"", "keywords": "\"model within framework\"", "source_id": "chunk-a5bc016656f4a03d7267cf14d747240b", "to": "\"WORD2VEC\"", "width": 7.0}, {"description": "\"The Transformer architecture, particularly its attention mechanism, is fundamental to the development of BERT.\"", "from": "\"TRANSFORMER\"", "keywords": "\"architecture foundation\"", "source_id": "chunk-a5bc016656f4a03d7267cf14d747240b", "to": "\"BERT\"", "width": 9.0}, {"description": "\"MOE builds upon or complements the Transformer architecture to achieve even larger parameter scales.\"", "from": "\"TRANSFORMER\"", "keywords": "\"model scalability, innovation\"", "source_id": "chunk-5474069465781f541726c53600f1b4f7", "to": "\"MOE\"", "width": 9.0}, {"description": "\"\u8bb8\u591a\u73b0\u4ee3\u7684\u5927\u8bed\u8a00\u6a21\u578b\u90fd\u662f\u5efa\u7acb\u5728Transformer\u67b6\u6784\u4e4b\u4e0a\u7684\u3002\"", "from": "\"TRANSFORMER\"", "keywords": "\"\u6280\u672f\u53d1\u5c55, \u67b6\u6784\u57fa\u7840\"|\u003e1", "source_id": "chunk-83f4aea6a8402d9c9f99736cbb2135d4", "to": "\"\u5927\u8bed\u8a00\u6a21\u578b\"", "width": 1.0}, {"description": "\"Transformer\u6a21\u578b\u9996\u6b21\u5f15\u5165\u4e86\u6ce8\u610f\u529b\u673a\u5236\u6765\u6539\u8fdb\u6587\u672c\u7406\u89e3\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u3002\"", "from": "\"TRANSFORMER\"", "keywords": "\"\u6280\u672f\u53d1\u5c55, \u67b6\u6784\u7279\u6027\"|\u003e1", "source_id": "chunk-83f4aea6a8402d9c9f99736cbb2135d4", "to": "\"\u6ce8\u610f\u529b\u673a\u5236\"", "width": 1.0}, {"description": "\"In terms of overall task effectiveness and speed, Transformer outperforms CNN.\"", "from": "\"TRANSFORMER\"", "keywords": "\"task performance comparison\"", "source_id": "chunk-bcf7c68cd902ea546596acd01bf558cf", "to": "\"CNN\"", "width": 7.0}, {"description": "\"Transformer significantly outperforms RNN in terms of overall task effectiveness and speed.\"", "from": "\"TRANSFORMER\"", "keywords": "\"performance gap\"", "source_id": "chunk-bcf7c68cd902ea546596acd01bf558cf", "to": "\"RNN\"", "width": 10.0}, {"description": "\"Both Skip-gram and CBOW are models within the Word2Vec framework.\"", "from": "\"WORD2VEC\"", "keywords": "\"model within framework\"", "source_id": "chunk-a5bc016656f4a03d7267cf14d747240b", "to": "\"CBOW\"", "width": 7.0}, {"description": "\"Word2Vec\u7528\u4e8e\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u8bcd\u5411\u91cf\uff0c\u4ee5\u652f\u6301NLP\u4efb\u52a1.\"", "from": "\"WORD2VEC\"", "keywords": "\"\u8bcd\u5411\u91cf\u8ba1\u7b97,\u5206\u5e03\u5f0f\u8868\u793a\"|\u003e1", "source_id": "chunk-83f4aea6a8402d9c9f99736cbb2135d4", "to": "\"\u8bcd\u5411\u91cf\"", "width": 1.0}, {"description": "\"ELMo uses RNNs to generate context-specific embeddings for word predictions in natural language processing tasks.\"", "from": "\"ELMO\"", "keywords": "\"embedding generation, sequence modeling\"", "source_id": "chunk-a5bc016656f4a03d7267cf14d747240b", "to": "\"RNN\"", "width": 8.0}, {"description": "\"CNN performs better than RNN but is less effective compared to Transformer in both overall task effectiveness and speed.\"", "from": "\"RNN\"", "keywords": "\"task performance hierarchy\"", "source_id": "chunk-bcf7c68cd902ea546596acd01bf558cf", "to": "\"CNN\"", "width": 9.0}, {"description": "\"BERT\u662f\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u91cd\u8981\u4ee3\u8868\u4e4b\u4e00\uff0c\u4e3a\u8bb8\u591aNLP\u5e94\u7528\u63d0\u4f9b\u652f\u6301\u3002\"", "from": "\"BERT\"", "keywords": "\"\u6280\u672f\u53d1\u5c55, \u6a21\u578b\u5b9e\u4f8b\"|\u003e1", "source_id": "chunk-83f4aea6a8402d9c9f99736cbb2135d4", "to": "\"\u5927\u8bed\u8a00\u6a21\u578b\"", "width": 1.0}, {"description": "\"RoBERTa builds upon the BERT architecture, adapting its training methodology to enhance robustness and scalability.\"", "from": "\"BERT\"", "keywords": "\"architectural evolution, performance enhancement\"", "source_id": "chunk-9c1eb6ec6cc7c8742be47f032e1488fc", "to": "\"ROBERTA\"", "width": 6.0}, {"description": "\"Training with FP16 faces significant numerical instability issues, often resulting in overflow.\"", "from": "\"FP16\"", "keywords": "\"training limitations\"", "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825", "to": "\"NUMERICAL STABILITY CHALLENGES\"", "width": 4.0}, {"description": "\"BF16 addresses some of the limitations faced by FP16 training in terms of stability and precision.\"", "from": "\"BF16\"", "keywords": "\"alternative solutions\"", "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825", "to": "\"FP16 LIMITATIONS\"", "width": 5.0}, {"description": "\"The loss scaling technique is applied to mitigate instability issues during FP16 training.\"", "from": "\"LOSS SCALING\"", "keywords": "\"stability enhancement\"", "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825", "to": "\"FP16 TRAINING\"", "width": 2.0}, {"description": "\"NVIDIA Ampere GPUs provide BF16 support, improving the stability and efficiency of large-scale model training.\"", "from": "\"OPTIMIZATION FRAMEWORKS (E.G., NVIDIA AMPERE)\"", "keywords": "\"hardware advancements\"", "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825", "to": "\"BF16 TRAINING\"", "width": 3.0}, {"description": "\"Unicorn Tech Co. is recognized for its development of the \u0027Smart Brain,\u0027 an AI system capable of complex cognitive tasks and autonomous learning.\"", "from": "\"UNICORN TECH CO.\"", "keywords": "\"innovation milestone\"", "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825", "to": "\"AI INNOVATION\"", "width": 6.0}, {"description": "\"Huawei\u0027s latest Kirin processor series represents a significant advancement in computing power and energy efficiency, especially within the AI domain.\"", "from": "\"HUAWEI\"", "keywords": "\"hardware innovation\"", "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825", "to": "\"TECHNOLOGICAL ADVANCEMENTS\"", "width": 7.0}, {"description": "\"Huawei plays a critical role in advancing 5G technology and has released several innovative products and solutions.\"", "from": "\"HUAWEI\"", "keywords": "\"technological advancement\"", "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825", "to": "\"5G TECHNOLOGY DEVELOPMENT\"", "width": 9.0}, {"description": "\"The UNFCCC emphasizes the urgency of reducing carbon emissions through international cooperation and policy implementation.\"", "from": "\"UNFCCC\"", "keywords": "\"international efforts\"", "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825", "to": "\"GLOBAL CLIMATE ACTION\"", "width": 1.0}, {"description": "\"Denmark has implemented effective environmental policies to reduce fossil fuel usage and promote green energy development.\"", "from": "\"CARBON EMISSIONS REDUCTION\"", "keywords": "\"national initiatives\"", "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825", "to": "\"DENMARK\"", "width": 2.0}, {"description": "\"The CAS continues to achieve significant scientific breakthroughs, as evidenced by the Nobel Prize win.\"", "from": "\"CAS (CHINESE ACADEMY OF SCIENCES)\"", "keywords": "\"scientific achievements\"", "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825", "to": "\"SCIENTIFIC BREAKTHROUGHS\"", "width": 3.0}, {"description": "\"Professor Zhang from CAS was awarded the Nobel Prize in Chemistry, highlighting China\u0027s growing presence in global science research.\"", "from": "\"ZHANG PROFESSOR\"", "keywords": "\"recognition milestone\"", "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825", "to": "\"NOBEL PRIZE IN CHEMISTRY\"", "width": 8.0}, {"description": "\"Professor Chen\u0027s work in quantum science has received international recognition through the Nobel Prize, contributing to global advancements in this field.\"", "from": "\"PROFESSOR CHEN\"", "keywords": "\"scientific recognition\"", "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825", "to": "\"QUANTUM SCIENCE\"", "width": 10.0}, {"description": "\"Alibaba Group holds a dominant position in the global e-commerce market and is expanding its influence into cloud computing and financial technology sectors.\"", "from": "\"ALIBABA GROUP\"", "keywords": "\"market leadership\"", "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825", "to": "\"GLOBAL E-COMMERCE MARKET\"", "width": 11.0}, {"description": "\"Tencent has achieved significant success in social media platforms and online gaming, establishing itself as a major player in these industries.\"", "from": "\"TENCENT\"", "keywords": "\"industry impact\"", "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825", "to": "\"SOCIAL MEDIA AND ONLINE GAMING\"", "width": 12.0}, {"description": "\"UNEP emphasizes the urgency of climate change action and calls for immediate measures to reduce carbon emissions and protect natural resources.\"", "from": "\"UNEP (UNITED NATIONS ENVIRONMENT PROGRAMME)\"", "keywords": "\"environmental advocacy\"", "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825", "to": "\"CLIMATE CHANGE ACTION\"", "width": 13.0}, {"description": "\"China\u0027s new environmental policies aim to mitigate climate change through increased investment in renewable energy, pollution control measures, and promotion of green living practices.\"", "from": "\"ENVIRONMENTAL PROTECTION POLICIES IN CHINA\"", "keywords": "\"policy implementation\"", "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825", "to": "\"CLIMATE CHANGE MITIGATION\"", "width": 14.0}, {"description": "\"The IEA reports on the growing share of renewable energy in global energy structures, predicting further increases in coming years.\"", "from": "\"IEA (INTERNATIONAL ENERGY AGENCY)\"", "keywords": "\"energy analysis\"", "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825", "to": "\"RENEWABLE ENERGY GROWTH\"", "width": 15.0}, {"description": "\"The DOE emphasizes the importance of clean energy technologies such as solar and wind power for reducing greenhouse gas emissions.\"", "from": "\"DOE (U.S. DEPARTMENT OF ENERGY)\"", "keywords": "\"technological emphasis\"", "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825", "to": "\"CLEAN ENERGY TECHNOLOGIES\"", "width": 16.0}, {"description": "\"The WHO has launched a new global health action plan focusing on strengthening infectious disease prevention and control measures worldwide.\"", "from": "\"WHO (WORLD HEALTH ORGANIZATION)\"", "keywords": "\"health initiative\"", "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825", "to": "\"GLOBAL HEALTH ACTION PLAN\"", "width": 17.0}, {"description": "\"China is increasing its investments to improve public healthcare infrastructure, including building more hospitals and clinics, training medical staff, and promoting health education to enhance overall public health.\"", "from": "\"PUBLIC HEALTH INVESTMENTS IN CHINA\"", "keywords": "\"infrastructure improvement\"", "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825", "to": "\"IMPROVING PUBLIC HEALTHCARE INFRASTRUCTURE\"", "width": 18.0}, {"description": "\"The EC has announced a new digital transformation strategy that includes investing 50 billion euros in advanced digital infrastructure, promoting technological innovation, and supporting the growth of the digital economy.\"", "from": "\"EC (EUROPEAN COMMISSION)\"", "keywords": "\"digital initiative\"", "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825", "to": "\"DIGITAL TRANSFORMATION STRATEGY\"", "width": 19.0}, {"description": "\"European governments are increasing their investments in AI and big data research to promote their application and development, which is expected to drive economic growth and enhance competitiveness in global technology competition.\"", "from": "\"AI AND BIG DATA RESEARCH INVESTMENTS\"", "keywords": "\"technological investment\"", "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825", "to": "\"ECONOMIC GROWTH\"", "width": 20.0}, {"description": "\"The recent international summit highlighted the need for enhanced cooperation and coordination among nations to tackle major global challenges like climate change, public health, and economic recovery.\"", "from": "\"INTERNATIONAL SUMMIT\"", "keywords": "\"cooperative approach\"", "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825", "to": "\"GLOBAL CHALLENGES\"", "width": 21.0}, {"description": "\"Multiple countries have outlined specific action plans aimed at reducing carbon emissions as part of their efforts to address climate change over the next few years.\"", "from": "\"CLIMATE CHANGE ACTION PLANS\"", "keywords": "\"emission reduction\"", "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825", "to": "\"CARBON EMISSION REDUCTION\"", "width": 22.0}, {"description": "\"The World Bank has released an economic outlook report highlighting the challenges faced by many countries due to the pandemic and noting some positive trends in certain economies and emerging markets.\"", "from": "\"WORLD BANK (WB)\"", "keywords": "\"economic analysis\"", "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825", "to": "\"ECONOMIC OUTLOOK REPORT\"", "width": 23.0}, {"description": "\"While the global economic recovery is slow, there are signs of improvement as some economies start showing growth momentum and emerging markets have made progress in innovation and digital transformation.\"", "from": "\"GLOBAL ECONOMIC RECOVERY\"", "keywords": "\"recovery trends\"", "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825", "to": "\"POSITIVE TRENDS\"", "width": 24.0}, {"description": "\"The IMF has issued a report indicating that despite global economic recovery challenges, some countries are making progress through effective policy support and vaccination efforts. The IMF advises continued fiscal measures to promote recovery and financial stability.\"", "from": "\"ECONOMIC RECOVERY REPORT\"", "keywords": "\"economic assessment\"", "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825", "to": "\"IMF (INTERNATIONAL MONETARY FUND)\"", "width": 25.0}, {"description": "\"The IMF stresses the importance of international cooperation in tackling shared economic challenges, including debt management, sustainable development, and maintaining global financial system stability.\"", "from": "\"INTERNATIONAL COOPERATION\"", "keywords": "\"cooperative efforts\"", "source_id": "chunk-fd4787fcc3fd06bfdbe5dbd44f159825", "to": "\"ECONOMIC CHALLENGES\"", "width": 26.0}, {"description": "\"Megatron-LM proposes an efficient 1D tensor parallelization method for large language models.\"", "from": "\"MEGATRON-LM\"", "keywords": "\"parallelism, efficiency\"", "source_id": "chunk-10fbf6d3d9babf4d5d45d940bb1db122", "to": "\"TENSOR PARALLELIZATION\"", "width": 6.0}, {"description": "\"Megatron-LM is based on Transformer architecture models and provides specialized tensor parallelization solutions.\"", "from": "\"MEGATRON-LM\"", "keywords": "\"foundation, limitation\"", "source_id": "chunk-10fbf6d3d9babf4d5d45d940bb1db122", "to": "\"TRANSFORMER ARCHITECTURE MODELS\"", "width": 5.0}, {"description": "\"Colossal-AI offers multi-dimensional tensor parallel solutions to address the limitations of Megatron-LM\u0027s 1D approach.\"", "from": "\"COLOSSAL-AI\"", "keywords": "\"improvement, scalability\"", "source_id": "chunk-10fbf6d3d9babf4d5d45d940bb1db122", "to": "\"TENSOR PARALLELIZATION\"", "width": 7.0}, {"description": "\"Colossal-AI builds upon Transformer architecture models but extends beyond Megatron-LM\u0027s specific implementation.\"", "from": "\"COLOSSAL-AI\"", "keywords": "\"extension, universality\"", "source_id": "chunk-10fbf6d3d9babf4d5d45d940bb1db122", "to": "\"TRANSFORMER ARCHITECTURE MODELS\"", "width": 6.0}, {"description": "\"PyTorch offers tensor parallel solutions that are more general and not limited to specific models like Megatron-LM.\"", "from": "\"PYTORCH TENSOR PARALLEL SOLUTIONS\"", "keywords": "\"generality, flexibility\"", "source_id": "chunk-10fbf6d3d9babf4d5d45d940bb1db122", "to": "\"TENSOR PARALLELIZATION\"", "width": 8.0}, {"description": "\"LIMoE is associated with MoE principles, highlighting its approach to ensemble learning.\"", "from": "\"MOE (MIXTURE OF EXPERTS)\"", "keywords": "\"ensemble learning, model-based research\"", "source_id": "chunk-75724a68b2c0f46a2e2ec23c1411363f", "to": "\"LIMOE\"", "width": 8.0}, {"description": "\"This event explores the relationship between curriculum data and model evolution within MoE.\"", "from": "\"MOE (MIXTURE OF EXPERTS)\"", "keywords": "\"ensemble learning, curriculum learning\"", "source_id": "chunk-75724a68b2c0f46a2e2ec23c1411363f", "to": "\"DIVERSE ENSEMBLE EVOLUTION: CURRICULUM DATA-MODEL MARRIAGE\"", "width": 9.0}, {"description": "\"The paper delves into diversity and depth aspects within per-example routing models under the MoE framework.\"", "from": "\"MOE (MIXTURE OF EXPERTS)\"", "keywords": "\"routing models, model flexibility\"", "source_id": "chunk-75724a68b2c0f46a2e2ec23c1411363f", "to": "\"DIVERSITY AND DEPTH IN PER-EXAMPLE ROUTING MODELS\"", "width": 10.0}, {"description": "\"MOE is expected to play an increasingly important role in advancing towards AGI.\"", "from": "\"MOE\"", "keywords": "\"technological progression, future vision\"", "source_id": "chunk-5474069465781f541726c53600f1b4f7", "to": "\"AGI\"", "width": 8.0}, {"description": "\"LangChain is designed to facilitate the development and deployment of large language model applications.\"", "from": "\"LANGCHAIN\"", "keywords": "\"application development, framework utility\"", "source_id": "chunk-b433fbff2e2fff052a98c5f49e7ba4c2", "to": "\"LARGE LANGUAGE MODEL APPLICATIONS\"", "width": 7.0}, {"description": "\"Alibaba Cloud contributes to the development and promotion of LangChain, a framework for large language model applications.\"", "from": "\"LANGCHAIN\"", "keywords": "\"cloud services, platform support\"\u003c\u003e7", "source_id": "chunk-b433fbff2e2fff052a98c5f49e7ba4c2", "to": "\"ALIBABA CLOUD\"", "width": 1.0}, {"description": "\"Jack Ma played a key role in establishing and supporting Alibaba Cloud, which contributes to LangChain development.\"", "from": "\"ALIBABA CLOUD\"", "keywords": "\"founder, supporter\"\u003c\u003e7", "source_id": "chunk-b433fbff2e2fff052a98c5f49e7ba4c2", "to": "\"JACK MA\"", "width": 1.0}, {"description": "\"Alibaba Cloud regularly participates in the Cloud Computing Conference to showcase its latest technologies, including LangChain.\"", "from": "\"ALIBABA CLOUD\"", "keywords": "\"technology showcase\"\u003c\u003e7", "source_id": "chunk-b433fbff2e2fff052a98c5f49e7ba4c2", "to": "\"CLOUD COMPUTING CONFERENCE 1984\"", "width": 1.0}, {"description": "\"The headquarters of Alibaba Cloud is located in Hangzhou, China.\"", "from": "\"ALIBABA CLOUD HQ\"", "keywords": "\"location\"\u003c\u003e7", "source_id": "chunk-b433fbff2e2fff052a98c5f49e7ba4c2", "to": "\"HANGZHOU\"", "width": 1.0}, {"description": "\"DirectoryLoader loads documents into a list of Pydantic Documents.\"", "from": "\"DIRECTORYLOADER\"", "keywords": "\"file loading\"", "source_id": "chunk-2ca6daea6a4f0f4a4352f8eba1bc3e4e", "to": "\"DOCS\"", "width": 1.0}, {"description": "\"OpenAIEmbeddings generates embeddings from texts using OpenAI\u0027s API.\"", "from": "\"OPENAIEMBEDDINGS\"", "keywords": "\"embedding generation\"", "source_id": "chunk-2ca6daea6a4f0f4a4352f8eba1bc3e4e", "to": "\"EMBEDDINGS\"", "width": 3.0}, {"description": "\"CharacterTextSplitter splits the loaded documents into smaller chunks for processing.\"", "from": "\"CHARACTERTEXTSPLITTER\"", "keywords": "\"text splitting\"", "source_id": "chunk-2ca6daea6a4f0f4a4352f8eba1bc3e4e", "to": "\"DOCS_SPLIT\"", "width": 2.0}, {"description": "\"Chroma stores the document embeddings and provides retrieval functionality.\"", "from": "\"CHROMA\"", "keywords": "\"vector database management\"", "source_id": "chunk-2ca6daea6a4f0f4a4352f8eba1bc3e4e", "to": "\"VECTOR_STORE\"", "width": 4.0}, {"description": "\"ChatVectorDBChain creates a chain where chat interacts with vector databases for answers.\"", "from": "\"CHATVECTORDBCHAIN\"", "keywords": "\"chat interaction\"", "source_id": "chunk-2ca6daea6a4f0f4a4352f8eba1bc3e4e", "to": "\"QA\"", "width": 5.0}, {"description": "\"ConversationalRetrievalChain provides the ability to have conversations over stored knowledge.\"", "from": "\"CONVERSATIONALRETRIEVALCHAIN\"", "keywords": "\"conversational retrieval\"", "source_id": "chunk-2ca6daea6a4f0f4a4352f8eba1bc3e4e", "to": "\"QA\"", "width": 6.0}, {"description": "\"The team uses advanced communication technology to attempt contact.\"", "from": "\"ALEX AND SAM RIVERA\u0027S TEAM\"", "keywords": "\"technological advancement\"", "source_id": "chunk-2ca6daea6a4f0f4a4352f8eba1bc3e4e", "to": "\"ADVANCED COMMUNICATION TECHNOLOGY\"", "width": 1.0}, {"description": "\"The Ingenuity helicopter was part of the Mars 2020 mission and achieved a historic first powered flight on another planet.\"", "from": "\"NASA\u0027S MARS 2020 MISSION\"", "keywords": "\"mission component\"", "source_id": "chunk-2ca6daea6a4f0f4a4352f8eba1bc3e4e", "to": "\"INGENUITY MARS HELICOPTER\"", "width": 4.0}, {"description": "\"The Perseverance rover is exploring Jezero Crater for signs of past life.\"", "from": "\"PERSEVERANCE ROVER\"", "keywords": "\"exploration\"", "source_id": "chunk-2ca6daea6a4f0f4a4352f8eba1bc3e4e", "to": "\"JEZERO CRATER\"", "width": 2.0}, {"description": "\"The Perseverance rover\u0027s operations are managed by JPL.\"", "from": "\"PERSEVERANCE ROVER\"", "keywords": "\"management\"", "source_id": "chunk-2ca6daea6a4f0f4a4352f8eba1bc3e4e", "to": "\"NASA JET PROPULSION LABORATORY (JPL)\"", "width": 3.0}, {"description": "\"These methods are part of the PELT approach used to optimize and enhance model performance.\"", "from": "\"LORA, BITFIT, PREFIX-TUNING, UNIPELT\"", "keywords": "\"model optimization techniques\"", "source_id": "chunk-6efa9c6aa660f80c3eda33d6df29f324", "to": "\"PELT METHOD\"", "width": 8.0}, {"description": "\"The PELT method involves multiple parts of the PLM, contributing to improved model effectiveness and robustness.\"", "from": "\"PELT METHOD\"", "keywords": "\"model components, performance enhancement\"", "source_id": "chunk-6efa9c6aa660f80c3eda33d6df29f324", "to": "\"PRE-TRAINED LANGUAGE MODEL (PLM)\"", "width": 9.0}, {"description": "\"LoRA is applied to PLMs to fine-tune models efficiently by modifying only a subset of layers.\"", "from": "\"PRE-TRAINED LANGUAGE MODEL (PLM)\"", "keywords": "\"model optimization, efficiency enhancement\"", "source_id": "chunk-6efa9c6aa660f80c3eda33d6df29f324", "to": "\"LORA\"", "width": 8.0}, {"description": "\"BitFit optimizes PLMs by learning biases or layer norms without altering other parameters, reducing fine-tuning costs.\"", "from": "\"PRE-TRAINED LANGUAGE MODEL (PLM)\"", "keywords": "\"parameter-efficient fine-tuning\"", "source_id": "chunk-6efa9c6aa660f80c3eda33d6df29f324", "to": "\"BITFIT\"", "width": 9.0}, {"description": "\"Prefix-tuning enhances PLMs by introducing a set of prefix tokens that can be learned during fine-tuning, improving model performance without heavy training.\"", "from": "\"PRE-TRAINED LANGUAGE MODEL (PLM)\"", "keywords": "\"fine-tuning efficiency, performance enhancement\"", "source_id": "chunk-6efa9c6aa660f80c3eda33d6df29f324", "to": "\"PREFIX-TUNING\"", "width": 10.0}, {"description": "\"UniPELT combines various parameter-efficient techniques to optimize PLMs for better performance and reduced computational cost during fine-tuning.\"", "from": "\"PRE-TRAINED LANGUAGE MODEL (PLM)\"", "keywords": "\"unified model optimization framework\"", "source_id": "chunk-6efa9c6aa660f80c3eda33d6df29f324", "to": "\"UNIPELT\"", "width": 11.0}, {"description": "\"MAM Adapter builds upon and integrates LoRA as part of its unified approach.\"", "from": "\"LORA\"", "keywords": "\"reparameterization, efficiency\"", "source_id": "chunk-6fb791db271a0a4e393b0080cf334633", "to": "\"MAM ADAPTER\"", "width": 6.0}, {"description": "\"UniPELT uses LoRA as one of the sub-modules within its framework.\"", "from": "\"LORA\"", "keywords": "\"integration, gating mechanism\"", "source_id": "chunk-6fb791db271a0a4e393b0080cf334633", "to": "\"UNIPELT\"", "width": 5.0}, {"description": "\"UniPELT includes Adapter method within its sub-modules to enhance flexibility and performance.\"", "from": "\"UNIPELT\"", "keywords": "\"integration, task-specific adaptation\"", "source_id": "chunk-6fb791db271a0a4e393b0080cf334633", "to": "\"ADAPTER\"", "width": 5.0}, {"description": "\"The LLama2 series documentation or updates are published on Zhihu, providing a channel for community interaction.\"", "from": "\"LLAMA2 SERIES\"", "keywords": "\"information dissemination, community engagement\"", "source_id": "chunk-f5af718c9d6b994d28f73e212375b2b2", "to": "\"\u77e5\u4e4e\"", "width": 8.0}, {"description": "\"MAM Adapter incorporates traditional Adapter methods as part of its unified approach.\"", "from": "\"MAM ADAPTER\"", "keywords": "\"unified adaptation, layer insertion\"", "source_id": "chunk-6fb791db271a0a4e393b0080cf334633", "to": "\"ADAPTER\"", "width": 6.0}, {"description": "\"P-Tuning v2 performs comparably to or better than fine tuning on small-scale tasks, especially in natural language inference (RTE) and sentiment analysis.\"", "from": "\"P-TUNING V2\"", "keywords": "\"performance comparison, task effectiveness\"", "source_id": "chunk-4e00824efb6ed62d0c56266d5c25ab70", "to": "\"FINE TUNING\"", "width": 14.0}, {"description": "\"The effectiveness of P-Tuning v2 may vary with prompt length, requiring optimization for different tasks.\"", "from": "\"P-TUNING V2\"", "keywords": "\"optimization consideration\"", "source_id": "chunk-4e00824efb6ed62d0c56266d5c25ab70", "to": "\"PROMPT LENGTH\"", "width": 3.0}, {"description": "\"The performance of P-Tuning v2 can vary depending on the complexity of tasks, requiring careful consideration for optimal results.\"", "from": "\"P-TUNING V2\"", "keywords": "\"effectiveness variation\"", "source_id": "chunk-4e00824efb6ed62d0c56266d5c25ab70", "to": "\"TASK COMPLEXITY\"", "width": 4.0}, {"description": "\"\u667a\u8c31 provides tutorials and guidance on deploying and fine-tuning ChatGLM3-6B models.\"", "from": "\"\u667a\u8c31\"", "keywords": "\"tutorial provision\"", "source_id": "chunk-0e87e307fcbe65dbc1b036277c963d52", "to": "\"CHATGLM3-6B \"", "width": 1.0}, {"description": "\"\u667a\u8c31 offers guidance on implementing Function Call in the deployment of advanced language models like ChatGLM3-6B.\"", "from": "\"\u667a\u8c31\"", "keywords": "\"functionality implementation\"", "source_id": "chunk-0e87e307fcbe65dbc1b036277c963d52", "to": "\"FUNCTION CALL\"", "width": 2.0}, {"description": "\"The LoRA training method is applicable for enhancing models such as ChatGLM2-INT4 through fine-tuning.\"", "from": "\"CHATGLM2-INT4 \"", "keywords": "\"training methodology, model improvement\"", "source_id": "chunk-0e87e307fcbe65dbc1b036277c963d52", "to": "\"LORA TRAINING \"", "width": 3.0}, {"description": "\"Both RAG and LLM Agent technologies are part of a broader effort to enhance information retrieval and generation through advanced techniques.\"", "from": "\"RAG (RETRIEVAL-AUGMENTED GENERATION)\"", "keywords": "\"technological advancement, information enhancement\"", "source_id": "chunk-f5b8c806db414a91b4dbd808e6798006", "to": "\"LLM AGENT TECHNOLOGY\"", "width": 7.0}, {"description": "\"The MetaGPT paper likely discusses or references the Agents Framework as part of ongoing research into advanced AI systems.\"", "from": "\"METAGPT\"", "keywords": "\"AI research, academic contributions\"", "source_id": "chunk-74f6b594f3958fb2771f177186f3dd2c", "to": "\"AGENTS FRAMEWORK\"", "width": 9.0}, {"description": "\"Both OpenBMB/ChatDev and AgentVerse are initiatives within the broader field of AI development focused on autonomous language agents.\"", "from": "\"OPENBMB/CHATDEV\"", "keywords": "\"collaborative efforts, technological advancements\"", "source_id": "chunk-74f6b594f3958fb2771f177186f3dd2c", "to": "\"AGENTVERSE\"", "width": 8.0}, {"description": "\"The Agents Framework may build upon or reference cognitive models like the LIDA model to inform its design and application.\"", "from": "\"AGENTS FRAMEWORK\"", "keywords": "\"cognitive science, AI development\"", "source_id": "chunk-74f6b594f3958fb2771f177186f3dd2c", "to": "\"LIDA MODEL\"", "width": 7.0}, {"description": "\"Understanding phase transitions in brain evolution provides crucial insights into how human language has evolved over time.\"", "from": "\"PHASE TRANSITIONS OF BRAIN EVOLUTION\"", "keywords": "\"neuroscience, linguistics\"", "source_id": "chunk-74f6b594f3958fb2771f177186f3dd2c", "to": "\"HUMAN LANGUAGE EVOLUTION\"", "width": 6.0}, {"description": "\"The review likely touches on the LIDA model as one among several significant advancements made during the past four decades of cognitive architecture research.\"", "from": "\"A REVIEW OF 40 YEARS IN COGNITIVE ARCHITECTURE RESEARCH\"", "keywords": "\"historical perspective, theoretical frameworks\"", "source_id": "chunk-74f6b594f3958fb2771f177186f3dd2c", "to": "\"LIDA MODEL\"", "width": 5.0}, {"description": "\"The Projection mechanism aims to bridge the gap between human cognition and AI systems by enabling more sophisticated reasoning abilities.\"", "from": "\"PROJECTION MECHANISM\"", "keywords": "\"cognitive capabilities, technological innovation\"", "source_id": "chunk-74f6b594f3958fb2771f177186f3dd2c", "to": "\"HUMAN-LIKE REASONING IN AI\"", "width": 4.0}, {"description": "\"PDDL serves as a foundational language for defining tasks in planning systems within the realm of artificial intelligence research.\"", "from": "\"PLANNING DOMAIN DEFINITION LANGUAGE (PDDL)\"", "keywords": "\"standardization, automation\"", "source_id": "chunk-74f6b594f3958fb2771f177186f3dd2c", "to": "\"AI PLANNING SYSTEMS\"", "width": 3.0}, {"description": "\"\u5728\u9762\u5bf9\u590d\u6742\u4fe1\u606f\u65f6\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u53ef\u80fd\u56e0\u4e3a\u903b\u8f91\u63a8\u7406\u80fd\u529b\u4e0d\u8db3\u800c\u51fa\u73b0\u7406\u89e3\u4e0a\u7684\u504f\u5dee\uff0c\u4ece\u800c\u5bfc\u81f4\u7ed3\u8bba\u7684\u51c6\u786e\u6027\u53d7\u635f\u3002\"", "from": "\"\u903b\u8f91\u63a8\u65ad\u969c\u788d\"", "keywords": "\"\u6a21\u578b\u6027\u80fd, \u8bef\u89e3\u6e90\u6587\u672c\"", "source_id": "chunk-ae2b89823ad29ef6521a8f10eafcf639", "to": "\"\u5927\u578b\u8bed\u8a00\u6a21\u578b\"", "width": 8.0}, {"description": "\"\u5728\u9762\u5bf9\u590d\u6742\u7684\u6216\u542b\u7cca\u4e0d\u6e05\u7684\u4fe1\u606f\u65f6\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u53ef\u80fd\u65e0\u6cd5\u6b63\u786e\u89e3\u6790\u5176\u4e2d\u7684\u91cd\u8981\u7ec6\u8282\uff0c\u4ece\u800c\u5f71\u54cd\u5176\u540e\u7eed\u7684\u5206\u6790\u548c\u7ed3\u8bba\u751f\u6210\u8fc7\u7a0b\u3002\"", "from": "\"\u903b\u8f91\u63a8\u65ad\u969c\u788d\"", "keywords": "\"\u590d\u6742\u4fe1\u606f, \u542b\u7cca\u4e0d\u6e05\u7684\u4fe1\u606f\"", "source_id": "chunk-ae2b89823ad29ef6521a8f10eafcf639", "to": "\"\u8bef\u89e3\u6e90\u6587\u672c\u4e2d\u7684\u4fe1\u606f\"", "width": 6.0}, {"description": "\"\u5728\u751f\u6210\u8f93\u51fa\u8fc7\u7a0b\u4e2d\uff0c\u5982\u679c\u6a21\u578b\u4f9d\u8d56\u4e8e\u9884\u8bad\u7ec3\u65f6\u7684\u77e5\u8bc6\u800c\u4e0d\u662f\u5f53\u524d\u7684\u5177\u4f53\u60c5\u5883\u4fe1\u606f\uff0c\u5219\u53ef\u80fd\u5bfc\u81f4\u5176\u4ea7\u751f\u4e0d\u51c6\u786e\u6216\u4e0d\u5408\u903b\u8f91\u7684\u56de\u7b54\u3002\"", "from": "\"\u4e0a\u4e0b\u6587\u4e0e\u5185\u7f6e\u77e5\u8bc6\u7684\u51b2\u7a81\"", "keywords": "\"\u9884\u8bad\u7ec3\u9636\u6bb5, \u4e0a\u4e0b\u6587\u7406\u89e3\"", "source_id": "chunk-ae2b89823ad29ef6521a8f10eafcf639", "to": "\"\u5927\u6a21\u578b\u8f93\u51fa\"", "width": 7.0}, {"description": "\"\u5f53\u63d0\u4f9b\u7ed9\u6a21\u578b\u7684\u4fe1\u606f\u5305\u542b\u8bef\u5bfc\u6027\u5047\u8bbe\u6216\u9519\u8bef\u65f6\uff0c\u6a21\u578b\u53ef\u80fd\u4f1a\u57fa\u4e8e\u8fd9\u4e9b\u9519\u8bef\u751f\u6210\u5e7b\u89c9\u5f0f\u7684\u56de\u7b54\u3002\"", "from": "\"\u9519\u8bef\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\"", "keywords": "\"\u4fe1\u606f\u51c6\u786e\u6027, \u5e7b\u89c9\u95ee\u9898\"", "source_id": "chunk-ae2b89823ad29ef6521a8f10eafcf639", "to": "\"\u5927\u578b\u8bed\u8a00\u6a21\u578b\u56de\u7b54\"", "width": 9.0}, {"description": "\"\u5f53\u8f93\u5165\u7ed9\u6a21\u578b\u7684\u4fe1\u606f\u4e2d\u5305\u542b\u4e0d\u51c6\u786e\u6216\u5177\u6709\u8bef\u5bfc\u6027\u7684\u5047\u8bbe\u65f6\uff0c\u8fd9\u4e9b\u5047\u8bbe\u53ef\u80fd\u5bfc\u81f4\u6a21\u578b\u5f97\u51fa\u9519\u8bef\u7684\u63a8\u8bba\u548c\u7ed3\u8bba\u3002\"", "from": "\"\u9519\u8bef\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\"", "keywords": "\"\u8bef\u5bfc\u6027\u4fe1\u606f, \u63a8\u7406\u51c6\u786e\u6027\"", "source_id": "chunk-ae2b89823ad29ef6521a8f10eafcf639", "to": "\"\u8bef\u5bfc\u6027\u5047\u8bbe\"", "width": 8.0}, {"description": "\"\u5f53\u9762\u4e34\u9ad8\u5ea6\u590d\u6742\u7684\u63a8\u7406\u4efb\u52a1\u65f6\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u53ef\u80fd\u7531\u4e8e\u5176\u81ea\u8eab\u7684\u9650\u5236\u800c\u96be\u4ee5\u8fdb\u884c\u6709\u6548\u7684\u903b\u8f91\u63a8\u65ad\u548c\u4fe1\u606f\u6574\u5408\u3002\"", "from": "\"\u903b\u8f91\u63a8\u7406\u80fd\u529b\u4e0d\u8db3\"", "keywords": "\"\u63a8\u7406\u4efb\u52a1, \u4fe1\u606f\u5904\u7406\"", "source_id": "chunk-ae2b89823ad29ef6521a8f10eafcf639", "to": "\"\u590d\u6742\u4fe1\u606f\u5904\u7406\u4e0d\u5f53\"", "width": 5.0}, {"description": "\"RLHF often benefits from well-crafted prompts, which can guide models towards generating more human-like responses.\"", "from": "\"RLHF\"", "keywords": "\"training methods, techniques\"", "source_id": "chunk-b43020db5fae0ade6540f46dc8c909d7", "to": "\"PROMPT ENGINEERING\"", "width": 8.0}, {"description": "\"DPO aims to achieve similar or better performance than RLHF with fewer computational requirements.\"", "from": "\"RLHF\"", "keywords": "\"comparison, optimization approach\"", "source_id": "chunk-115db5344fc770c67e60120f710f8c9e", "to": "\"DPO\"", "width": 5.0}, {"description": "\"Feedback loops in RLHF may exacerbate Model Flattery if not properly managed, leading to overly aligned or biased model behavior.\"", "from": "\"MODEL FLATTERY\"", "keywords": "\"conceptual relationships\"", "source_id": "chunk-b43020db5fae0ade6540f46dc8c909d7", "to": "\"FEEDBACK LOOPS\"", "width": 9.0}, {"description": "\"Top-p decoding offers a balance between Greedy decoding\u0027s efficiency and broader exploration, enhancing model creativity and accuracy.\"", "from": "\"TOP-P DECODING\"", "keywords": "\"decoding strategies\"", "source_id": "chunk-b43020db5fae0ade6540f46dc8c909d7", "to": "\"GREEDY DECODING\"", "width": 2.0}, {"description": "\"Intervention in the multi-head attention mechanism is part of the Factual-Nucleus approach to enhance factual correctness during decoding.\"", "from": "\"MULTI-HEAD ATTENTION MECHANISM INTERVENTION\"", "keywords": "\"attention mechanisms, accuracy enhancement\"", "source_id": "chunk-b43020db5fae0ade6540f46dc8c909d7", "to": "\"FACTUAL-NUCLEUS\"", "width": 3.0}, {"description": "\"The use of residual connections allows DOLA to analyze layer-specific predictions for more accurate and coherent output.\"", "from": "\"RESIDUAL CONNECTIONS IN TRANSFORMERS\"", "keywords": "\"architecture features, decoding techniques\"", "source_id": "chunk-b43020db5fae0ade6540f46dc8c909d7", "to": "\"DOLA (DISTILLED OUTPUT LAYER ATTENTION)\"", "width": 4.0}, {"description": "\"Both Chain-of-Verification and Self-Reflection aim to improve model-generated content by iterative refinement and validation.\"", "from": "\"CHAIN-OF-VERIFICATION\"", "keywords": "\"post-processing methods\"", "source_id": "chunk-b43020db5fae0ade6540f46dc8c909d7", "to": "\"SELF-REFLECTION\"", "width": 5.0}, {"description": "\"KL-guided-sampling optimizes Context-aware Decoding parameters dynamically, enhancing context relevance without internal bias.\"", "from": "\"CONTEXT-AWARE DECODING (CAD)\"", "keywords": "\"dynamic optimization\"", "source_id": "chunk-b43020db5fae0ade6540f46dc8c909d7", "to": "\"KL-GUIDED-SAMPLING\"", "width": 6.0}, {"description": "\"Contrastive-Decoding builds on Context-aware Decoding principles but introduces an additional step for refining predictions with noise distribution.\"", "from": "\"CONTEXT-AWARE DECODING (CAD)\"", "keywords": "\"refinement techniques\"", "source_id": "chunk-b43020db5fae0ade6540f46dc8c909d7", "to": "\"CONTRASTIVE-DECODING\"", "width": 7.0}, {"description": "\"Token probability adjustment is an important part of CAD, allowing models to adapt their output based on contextual relevance.\"", "from": "\"CONTEXT-AWARE DECODING (CAD)\"", "keywords": "\"technique relationships\"", "source_id": "chunk-b43020db5fae0ade6540f46dc8c909d7", "to": "\"TOKEN PROBABILITY ADJUSTMENT\"", "width": 11.0}, {"description": "\"Combining intrinsic rewards with external validation can help balance a model\u0027s reliance on internal and external feedback for better performance.\"", "from": "\"INTRINSIC REWARD\"", "keywords": "\"balance of incentives\"", "source_id": "chunk-b43020db5fae0ade6540f46dc8c909d7", "to": "\"EXTERNAL VALIDATION\"", "width": 10.0}, {"description": "\"GPT\u6a21\u578b\u5728\u81ea\u7136\u8bed\u8a00\u751f\u6210\u548c\u7406\u89e3\u4efb\u52a1\u4e2d\u5c55\u73b0\u4e86\u5f3a\u5927\u7684\u80fd\u529b\u3002\"", "from": "\"\u5927\u8bed\u8a00\u6a21\u578b\"", "keywords": "\"\u6280\u672f\u53d1\u5c55, \u5e94\u7528\u5b9e\u4f8b\"|\u003e1", "source_id": "chunk-83f4aea6a8402d9c9f99736cbb2135d4", "to": "\"GPT\"", "width": 1.0}, {"description": "\"\u51e0\u4e4e\u6240\u6709\u73b0\u4ee3\u7684\u5927\u8bed\u8a00\u6a21\u578b\u90fd\u4f1a\u7ecf\u5386\u4e00\u4e2a\u6216\u591a\u4e2a\u9884\u8bad\u7ec3\u9636\u6bb5\u6765\u83b7\u5f97\u77e5\u8bc6\u548c\u6280\u80fd\u3002\"", "from": "\"\u5927\u8bed\u8a00\u6a21\u578b\"", "keywords": "\"\u6280\u672f\u53d1\u5c55, \u8bad\u7ec3\u8fc7\u7a0b\"|\u003e1", "source_id": "chunk-83f4aea6a8402d9c9f99736cbb2135d4", "to": "\"\u9884\u8bad\u7ec3\"", "width": 1.0}, {"description": "\"\u901a\u8fc7\u9002\u5f53\u7684\u5fae\u8c03\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5177\u4f53\u5e94\u7528\u4e2d\u7684\u6027\u80fd\u548c\u6548\u679c\u3002\"", "from": "\"\u5927\u8bed\u8a00\u6a21\u578b\"", "keywords": "\"\u6280\u672f\u53d1\u5c55, \u8bad\u7ec3\u8fc7\u7a0b\"|\u003e1", "source_id": "chunk-83f4aea6a8402d9c9f99736cbb2135d4", "to": "\"\u5fae\u8c03\"", "width": 1.0}, {"description": "\"\u5927\u8bed\u8a00\u6a21\u578b\u901a\u5e38\u5177\u6709\u5f88\u5f3a\u7684\u4e0a\u4e0b\u6587\u611f\u77e5\u80fd\u529b\uff0c\u4f7f\u5176\u5728\u5404\u79cd\u590d\u6742\u7684NLP\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002\"", "from": "\"\u5927\u8bed\u8a00\u6a21\u578b\"", "keywords": "\"\u6280\u672f\u7279\u6027, \u5e94\u7528\u6548\u679c\"|\u003e1", "source_id": "chunk-83f4aea6a8402d9c9f99736cbb2135d4", "to": "\"\u4e0a\u4e0b\u6587\u611f\u77e5\"", "width": 1.0}, {"description": "\"\u5206\u8bcd\u548c\u8bcd\u5411\u91cf\u662f\u7406\u89e3\u5927\u8bed\u8a00\u6a21\u578b\u7684\u57fa\u7840\u77e5\u8bc6\u3002\"", "from": "\"\u5206\u8bcd\u4e0e\u8bcd\u5411\u91cf\"", "keywords": "\"\u6280\u672f\u57fa\u7840,\u5e94\u7528\u539f\u7406\"|\u003e2", "source_id": "chunk-83f4aea6a8402d9c9f99736cbb2135d4", "to": "\"\u8bed\u8a00\u6a21\u578b\u57fa\u7840\"", "width": 1.0}, {"description": "\"\u4e24\u8005\u5171\u540c\u63d0\u9ad8\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u957f\u6587\u672c\u4e0a\u7684\u8868\u73b0\u80fd\u529b\u3002\"", "from": "\"\u6ce8\u610f\u529b\u673a\u5236\"", "keywords": "\"\u6280\u672f\u6539\u8fdb, \u4e0a\u4e0b\u6587\u5efa\u6a21\"", "source_id": "chunk-b3e463d24adf84b28a5376fc9c10716b", "to": "\"\u6a21\u578b\u7ed3\u6784\u4f18\u5316\"", "width": 8.0}, {"description": "\"\u53e5\u6cd5\u5206\u6790\u4e3a\u89c2\u70b9\u62bd\u53d6\u63d0\u4f9b\u6280\u672f\u652f\u6301\uff0c\u4f46\u51c6\u786e\u6027\u4ecd\u9700\u6539\u8fdb\u3002\"", "from": "\"\u53e5\u6cd5\u5206\u6790\"", "keywords": "\"\u6280\u672f\u5e94\u7528, \u51c6\u786e\u6027\u6311\u6218\"", "source_id": "chunk-5b0fc972b273420601544dc3a8897744", "to": "\"\u89c2\u70b9\u62bd\u53d6\"", "width": 7.0}, {"description": "\"\u53e5\u6cd5\u5206\u6790\u5728\u60c5\u611f\u5206\u6790\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u662f\u5176\u51c6\u786e\u7387\u4ecd\u7136\u6709\u5f85\u63d0\u9ad8\u3002\"", "from": "\"\u53e5\u6cd5\u5206\u6790\"", "keywords": "\"\u6280\u672f\u5e94\u7528, \u6027\u80fd\u63d0\u5347\u9700\u6c42\"", "source_id": "chunk-5b0fc972b273420601544dc3a8897744", "to": "\"\u60c5\u611f\u5206\u6790\"", "width": 8.0}, {"description": "\"\u57fa\u4e8e\u53e5\u6cd5\u7ed3\u6784\u6811\u7684LSTM\u6df1\u5ea6\u5b66\u4e60\u7f51\u7edc\u53d7\u5236\u4e8e\u53e5\u6cd5\u5206\u6790\u51c6\u786e\u6027\u7684\u5f71\u54cd\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u6539\u8fdb\u4ee5\u63d0\u9ad8\u7cbe\u786e\u5ea6\u3002\"", "from": "\"\u53e5\u6cd5\u5206\u6790\"", "keywords": "\"\u6280\u672f\u4f9d\u8d56\u5173\u7cfb, \u6027\u80fd\u63d0\u5347\u9700\u6c42\"", "source_id": "chunk-5b0fc972b273420601544dc3a8897744", "to": "\"LSTM\u6df1\u5ea6\u5b66\u4e60\u7f51\u7edc\"", "width": 10.0}, {"description": "\"The variable x is utilized within the context of a gated activation function.\"", "from": "\"X\"", "keywords": "\"mathematical application\"", "source_id": "chunk-7291acaf81f6616df2f753d76e28b121", "to": "\"\u95e8\u63a7\u6fc0\u6d3b\u51fd\u6570\"", "width": 10.0}, {"description": "\"The split_head method reshapes input tensor x according to specified head number or default if none provided.\"", "from": "\"X\"", "keywords": "\"tensor manipulation, dimension splitting\"|\u003e6", "source_id": "chunk-bdde321da03a10cd546e17bd2a065594", "to": "\"SELF.SPLIT_HEAD\"", "width": 1.0}, {"description": "\"\u95e8\u63a7\u6fc0\u6d3b\u51fd\u6570\u662f\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u4e2d\u7684\u4e00\u4e2a\u7ec4\u6210\u90e8\u5206\uff0c\u7528\u4e8e\u63a7\u5236\u4fe1\u606f\u6d41\u3002\"", "from": "\"\u95e8\u63a7\u6fc0\u6d3b\u51fd\u6570\"", "keywords": "\"architecture component\"", "source_id": "chunk-7291acaf81f6616df2f753d76e28b121", "to": "\"\u795e\u7ecf\u7f51\u7edc\"", "width": 3.0}, {"description": "\"\u95e8\u63a7\u6fc0\u6d3b\u51fd\u6570\u901a\u8fc7\u8c03\u8282\u7f51\u7edc\u4e2d\u7684\u4fe1\u606f\u6d41\u52a8\u6765\u63a7\u5236\u795e\u7ecf\u5143\u4e4b\u95f4\u7684\u901a\u4fe1\u3002\"", "from": "\"\u95e8\u63a7\u6fc0\u6d3b\u51fd\u6570\"", "keywords": "\"functionality\"", "source_id": "chunk-7291acaf81f6616df2f753d76e28b121", "to": "\"\u4fe1\u606f\u6d41\"", "width": 4.0}, {"description": "\"\u4e24\u8005\u5728\u7edf\u8ba1\u548c\u8ba1\u7b97\u6548\u7387\u4e0a\u5f62\u6210\u5bf9\u6bd4\uff0c\u53cd\u6620\u4e86\u8bed\u8a00\u5efa\u6a21\u6280\u672f\u7684\u53d1\u5c55\u8d8b\u52bf\u3002", "from": "\"N-GRAM\u6a21\u578b\"", "keywords": "\"efficiency comparison, language modeling evolution\"", "source_id": "chunk-3265869f4b91b0e4feb100fa049dcf4b", "to": "\"\u795e\u7ecf\u8bed\u8a00\u6a21\u578b\"", "width": 7.0}, {"description": "\"NVIDIA has developed and publicly released TensorRT-LLM to enhance the efficiency of large language models.\"", "from": "\"NVIDIA\"", "keywords": "\"development, public release\"", "source_id": "chunk-4a4088e85fc27ef2f659b63294a50ca9", "to": "\"TENSORRT-LLM\"", "width": 8.0}, {"description": "\"TensorRT-LLM is specifically designed to optimize the performance and inference capabilities of Large Language Models.\"", "from": "\"TENSORRT-LLM\"", "keywords": "\"optimization, technology enhancement\"", "source_id": "chunk-4a4088e85fc27ef2f659b63294a50ca9", "to": "\"LARGE LANGUAGE MODELS (LLMS)\"", "width": 7.0}, {"description": "\"TensorRT-LLM reduces latency in Large Language Models, allowing them to provide faster responses.\"", "from": "\"TENSORRT-LLM\"", "keywords": "\"optimization, performance enhancement\"", "source_id": "chunk-4a4088e85fc27ef2f659b63294a50ca9", "to": "\"LATENCY\"", "width": 8.0}, {"description": "\"TensorRT-LLM increases throughput in Large Language Models, allowing them to handle more requests efficiently.\"", "from": "\"TENSORRT-LLM\"", "keywords": "\"optimization, performance enhancement\"", "source_id": "chunk-4a4088e85fc27ef2f659b63294a50ca9", "to": "\"THROUGHPUT\"", "width": 9.0}, {"description": "\"TensorRT-LLM optimizes how Large Language Models use available hardware resources, leading to better performance.\"", "from": "\"TENSORRT-LLM\"", "keywords": "\"optimization, resource management\"", "source_id": "chunk-4a4088e85fc27ef2f659b63294a50ca9", "to": "\"HARDWARE RESOURCES UTILIZATION\"", "width": 10.0}, {"description": "\"During the Inference Phase, Large Language Models analyze input text and produce human-like responses.\"", "from": "\"LARGE LANGUAGE MODELS (LLMS)\"", "keywords": "\"operation phase, prediction generation\"", "source_id": "chunk-4a4088e85fc27ef2f659b63294a50ca9", "to": "\"INFERENCE PHASE\"", "width": 7.0}, {"description": "\"RoPE enhances the performance of Transformer models by providing superior positional encoding compared to other methods like ALiBi.\"\u003cSEP\u003e\"RoPE enhances the performance of Transformer models by providing superior positional encoding compared to other methods.\"\u003cSEP\u003e\"RoPE is utilized in Transformer models for enhancing position encoding and improving overall performance.\"", "from": "\"ROPE\"", "keywords": "\"model enhancement, advanced techniques\"", "source_id": "chunk-76bc2665b54b51813a049bc7dbb25def", "to": "\"TRANSFORMER MODELS\"", "width": 18.0}, {"description": "\"The Pathways vision was proposed by Google as part of their AI strategy.\"", "from": "\"PATHWAYS VISION\"", "keywords": "\"AI strategy, generalized models\"", "source_id": "chunk-75724a68b2c0f46a2e2ec23c1411363f", "to": "\"GOOGLE\"", "width": 7.0}, {"description": "\"The Pathways vision incorporates ensemble learning strategies for developing flexible and generalized AI models.\"", "from": "\"PATHWAYS VISION\"", "keywords": "\"AI strategy, generalized models\"", "source_id": "chunk-75724a68b2c0f46a2e2ec23c1411363f", "to": "\"ENSEMBLE LEARNING\"", "width": 13.0}, {"description": "\"This event utilizes curriculum learning principles to guide the evolution of diverse ensembles.\"", "from": "\"DIVERSE ENSEMBLE EVOLUTION: CURRICULUM DATA-MODEL MARRIAGE\"", "keywords": "\"curriculum data, ensemble learning\"", "source_id": "chunk-75724a68b2c0f46a2e2ec23c1411363f", "to": "\"CURRICULUM LEARNING\"", "width": 12.0}, {"description": "\"During transformer training, dropout settings help in avoiding overfitting by randomly dropping units.\"", "from": "\"DROPOUT SETTING\"", "keywords": "\"overfitting prevention, training dynamics\"", "source_id": "chunk-93bfe637d3d9fb461bff179751f9157c", "to": "\"TRANSFORMER TRAINING\"", "width": 7.0}, {"description": "\"Both dropout and batch normalization are techniques to improve model performance; they complement each other by addressing different aspects of overfitting.\"", "from": "\"DROPOUT SETTING\"", "keywords": "\"technique comparison, training dynamics\"", "source_id": "chunk-93bfe637d3d9fb461bff179751f9157c", "to": "\"BATCH NORMALIZATION\"", "width": 11.0}, {"description": "\"Dropout is one form of regularization; other forms include L1 and L2 penalties.\"", "from": "\"DROPOUT SETTING\"", "keywords": "\"technique comparison, overfitting prevention\"", "source_id": "chunk-93bfe637d3d9fb461bff179751f9157c", "to": "\"REGULARIZATION TECHNIQUES\"", "width": 13.0}, {"description": "\"While transformers use attention mechanisms to mask scores, BERT employs a different approach through token masking during training.\"", "from": "\"BERT MASKING\"", "keywords": "\"model differences, pre-training techniques\"", "source_id": "chunk-93bfe637d3d9fb461bff179751f9157c", "to": "\"TRANSFORMER ATTENTION MASKING\"", "width": 9.0}, {"description": "\"The learning rate in Adam optimizer determines how much to change weights at each step, impacting training speed and convergence.\"", "from": "\"ADAM OPTIMIZER\"", "keywords": "\"training process, optimization\"", "source_id": "chunk-93bfe637d3d9fb461bff179751f9157c", "to": "\"LEARNING RATE\"", "width": 10.0}, {"description": "\"Effective weight initialization can lead to better performance even with the same learning rate settings.\"", "from": "\"WEIGHT INITIALIZATION\"", "keywords": "\"initial conditions, optimization\"", "source_id": "chunk-93bfe637d3d9fb461bff179751f9157c", "to": "\"LEARNING RATE\"", "width": 12.0}, {"description": "\"Using early stopping can prevent overfitting by halting training at the optimal point based on validation metrics.\"", "from": "\"EARLY STOPPING\"", "keywords": "\"training process, optimization\"", "source_id": "chunk-93bfe637d3d9fb461bff179751f9157c", "to": "\"TRAINING DYNAMICS\"", "width": 14.0}, {"description": "\"The learning rate is a critical hyperparameter that needs to be set appropriately for Transformer model training.\"", "from": "\"LEARNING RATE\"", "keywords": "\"training process, adaptation speed\"", "source_id": "chunk-93bfe637d3d9fb461bff179751f9157c", "to": "\"TRANSFORMER TRAINING\"", "width": 6.0}, {"description": "\"In the testing phase, remember to apply the dropout rate consistently across input layers.\"", "from": "\"DROPOUT RATE\"", "keywords": "\"testing process, consistency\"", "source_id": "chunk-93bfe637d3d9fb461bff179751f9157c", "to": "\"TESTING PHASE\"", "width": 8.0}, {"description": "\"People in the community are adopting MQA and GQA, indicating a shift towards these technologies.\"", "from": "\"MQA AND GQA\"", "keywords": "\"adoption, preference\"", "source_id": "chunk-b12fb948a61e556d12a7d3e123196d7a", "to": "\"PEOPLE\"", "width": 8.0}, {"description": "\"The UL2 model is more affected by multi-epoch training than the MLM model.\"", "from": "\"UL2 MODEL\"", "keywords": "\"performance degradation, comparison\"", "source_id": "chunk-9c1eb6ec6cc7c8742be47f032e1488fc", "to": "\"MLM MODEL\"", "width": 2.0}, {"description": "\"The UL2 model\u0027s poor performance with multi-epochs might be improved by implementing dropout regularization.\"", "from": "\"UL2 MODEL\"", "keywords": "\"technique improvement suggestion\"", "source_id": "chunk-9c1eb6ec6cc7c8742be47f032e1488fc", "to": "\"DROPOUT TECHNIQUE\"", "width": 5.0}, {"description": "\"The Galactica model successfully uses dropout to mitigate the negative effects of multi-epochs training.\"", "from": "\"DROPOUT TECHNIQUE\"", "keywords": "\"regularization, performance enhancement\"", "source_id": "chunk-9c1eb6ec6cc7c8742be47f032e1488fc", "to": "\"GALACTICA MODEL\"", "width": 4.0}, {"description": "\"Both GPT-3 and LLaMA models do not utilize dropout due to computational overhead.\"", "from": "\"GPT-3\"", "keywords": "\"omission of technique, similar architecture\"", "source_id": "chunk-9c1eb6ec6cc7c8742be47f032e1488fc", "to": "\"LLAMA MODEL\"", "width": 6.0}, {"description": "\"The MoE model\u0027s performance trends can be used as a proxy for predicting optimal hyperparameters in large language models during training.\"", "from": "\"MOE MODEL\"", "keywords": "\"hyperparameter tuning, predictive modeling\"", "source_id": "chunk-9c1eb6ec6cc7c8742be47f032e1488fc", "to": "\"LARGE MODELS TRAINING OPTIMIZATION\"", "width": 8.0}, {"description": "\"After computing attention scores, these scores are used to weight the value tensor for output generation.\"", "from": "\"VALUE\"", "keywords": "\"weighting, output generation\"|\u003e3", "source_id": "chunk-bdde321da03a10cd546e17bd2a065594", "to": "\"ATTENTION_SCORES\"", "width": 1.0}, {"description": "\"The operation calculates attention scores by performing matrix multiplication between query and key matrices transposed and normalizing them.\"", "from": "\"ATTENTION_SCORES\"", "keywords": "\"matrix operations, normalization\"|\u003e7", "source_id": "chunk-bdde321da03a10cd546e17bd2a065594", "to": "\"TORCH.MATMUL(QUERY, KEY.TRANSPOSE(-1, -2)) / TORCH.SQRT(TORCH.TENSOR(SELF.HEAD_DIM))\"", "width": 1.0}, {"description": "\"If provided, the attention_mask modifies the scores by adding a negative value multiplied by the mask, dampening unwanted attention.\"", "from": "\"ATTENTION_SCORES\"", "keywords": "\"masking, score adjustment\"|\u003e8", "source_id": "chunk-bdde321da03a10cd546e17bd2a065594", "to": "\"ATTENTION_MASK != NONE -\u003e ATTENTION_SCORES += ATTENTION_MASK * -1E-9\"", "width": 1.0}, {"description": "\"The attention_mask modifies the scores by adding negative values in certain positions, influencing the final attention weights.\"", "from": "\"ATTENTION_SCORES\"", "keywords": "\"score adjustment, masking\"|\u003e6", "source_id": "chunk-bdde321da03a10cd546e17bd2a065594", "to": "\"ATTENTION_MASK\"", "width": 1.0}, {"description": "\"The query and key tensors are involved in calculating attention scores through matrix multiplication.\"", "from": "\"KEY\"", "keywords": "\"matrix operations, score calculation\"|\u003e2", "source_id": "chunk-bdde321da03a10cd546e17bd2a065594", "to": "\"QUERY\"", "width": 1.0}, {"description": "\"The result of the matrix multiplication is normalized along a specific dimension (score_dim) during the softmax computation.\"", "from": "\"SCORE_DIM\"", "keywords": "\"normalization, score calculation\"|\u003e4", "source_id": "chunk-bdde321da03a10cd546e17bd2a065594", "to": "\"TORCH.MATMUL(QUERY, KEY.TRANSPOSE(-1, -2))\"", "width": 1.0}, {"description": "\"Softmax normalization is applied over a specified dimension (softmax_dim) to produce attention probabilities.\"", "from": "\"SOFTMAX_DIM\"", "keywords": "\"probability generation, normalization\"|\u003e5", "source_id": "chunk-bdde321da03a10cd546e17bd2a065594", "to": "\"TORCH.SOFTMAX(...)\"", "width": 1.0}, {"description": "\"The method calculates scaled dot product attention and generates an output tensor that is a weighted combination of input values based on attention probabilities.\"", "from": "\"OUTPUT\"", "keywords": "\"attention calculation, output generation\"|\u003e7", "source_id": "chunk-bdde321da03a10cd546e17bd2a065594", "to": "\"SELF.SCALE_DOT_PRODUCT_ATTENTION(QUERY, KEY, VALUE)\"", "width": 1.0}, {"description": "\"The Swish activation function can be used as an alternative to the traditional GLU block, enhancing model performance when applied within transformer architectures.\"", "from": "\"SWISH ACTIVATION FUNCTION\"", "keywords": "\"enhanced nonlinearity, improved convergence\"", "source_id": "chunk-ec973faa85f0a6d3398456bdc53c2faf", "to": "\"GLU BLOCK\"", "width": 14.0}, {"description": "\"Swish can be seen as a smooth, non-monotonic variant of ReLU, offering better performance on certain datasets due to its continuous derivative.\"", "from": "\"SWISH ACTIVATION FUNCTION\"", "keywords": "\"enhanced gradient flow, improved model accuracy\"", "source_id": "chunk-ec973faa85f0a6d3398456bdc53c2faf", "to": "\"RELU ACTIVATION FUNCTION\"", "width": 7.0}, {"description": "\"Swish incorporates the benefits of sigmoid by applying it as part of its formulation, but unlike sigmoid, Swish doesn\u0027t suffer from the vanishing gradient problem.\"", "from": "\"SWISH ACTIVATION FUNCTION\"", "keywords": "\"enhanced model training efficiency\"", "source_id": "chunk-ec973faa85f0a6d3398456bdc53c2faf", "to": "\"SIGMOID FUNCTION\"", "width": 7.0}, {"description": "\"Swish helps mitigate the vanishing gradient problem by ensuring that the activation function remains responsive over a wide range of input values.\"", "from": "\"SWISH ACTIVATION FUNCTION\"", "keywords": "\"improved training dynamics\"", "source_id": "chunk-ec973faa85f0a6d3398456bdc53c2faf", "to": "\"VANISHING GRADIENT PROBLEM\"", "width": 7.0}, {"description": "\"\u5143\u6a21\u578b\u8bad\u7ec3\u652f\u6301\u540e\u7eed\u7684\u6301\u7eed\u5b66\u4e60\u8fc7\u7a0b\uff0c\u786e\u4fdd\u6a21\u578b\u5728\u65b0\u6570\u636e\u4e0a\u4fdd\u6301\u6027\u80fd\u3002\"", "from": "\"\u5143\u6a21\u578b\u8bad\u7ec3\"", "keywords": "\"\u9002\u5e94\u6027, \u6570\u636e\u66f4\u65b0\"", "source_id": "chunk-b226b02552d812a52faba8fd5d6a1167", "to": "\"\u6301\u7eed\u5b66\u4e60\"", "width": 6.0}, {"description": "\"\u901a\u8fc7\u540c\u65f6\u8fdb\u884c\u5143\u6a21\u578b\u8bad\u7ec3\u548c\u591a\u4efb\u52a1\u5b66\u4e60\u6765\u63d0\u9ad8\u7279\u5b9a\u9886\u57df\u7684\u6cdb\u5316\u80fd\u529b\u3002\"", "from": "\"\u5143\u6a21\u578b\u8bad\u7ec3\"", "keywords": "\"\u6280\u80fd\u63d0\u5347, \u6cdb\u5316\u589e\u5f3a\"", "source_id": "chunk-b226b02552d812a52faba8fd5d6a1167", "to": "\"\u591a\u4efb\u52a1\u5b66\u4e60\"", "width": 7.0}, {"description": "\"\u5143\u6a21\u578b\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u53ef\u4ee5\u4f7f\u7528\u5728\u7ebf\u5b66\u4e60\u65b9\u6cd5\u6765\u9002\u5e94\u65b0\u6570\u636e\uff0c\u4ee5\u4fdd\u6301\u9ad8\u7cbe\u5ea6\u3002\"", "from": "\"\u5143\u6a21\u578b\u8bad\u7ec3\"", "keywords": "\"\u66f4\u65b0\u7b56\u7565, \u6570\u636e\u9002\u5e94\u6027\"", "source_id": "chunk-b226b02552d812a52faba8fd5d6a1167", "to": "\"\u5728\u7ebf\u5b66\u4e60\"", "width": 6.0}, {"description": "\"\u901a\u8fc7\u6a21\u578b\u84b8\u998f\u6280\u672f\uff0c\u53ef\u4ee5\u5728\u5143\u6a21\u578b\u8bad\u7ec3\u4e2d\u51cf\u5c11\u590d\u6742\u5ea6\u5e76\u63d0\u9ad8\u6548\u7387\u3002\"", "from": "\"\u5143\u6a21\u578b\u8bad\u7ec3\"", "keywords": "\"\u4f18\u5316\u7b56\u7565, \u6a21\u578b\u7cbe\u7b80\"", "source_id": "chunk-b226b02552d812a52faba8fd5d6a1167", "to": "\"\u6a21\u578b\u84b8\u998f\"", "width": 7.0}, {"description": "\"\u4f7f\u7528LIME\u5de5\u5177\u53ef\u4ee5\u8be6\u7ec6\u5730\u7406\u89e3\u5143\u6a21\u578b\u5728\u7279\u5b9a\u5b9e\u4f8b\u4e0a\u7684\u51b3\u7b56\u8fc7\u7a0b\u3002\"", "from": "\"\u6a21\u578b\u89e3\u91ca\u6027\"", "keywords": "\"\u5c40\u90e8\u89e3\u91ca\u6027, \u53ef\u89c6\u5316\"", "source_id": "chunk-b226b02552d812a52faba8fd5d6a1167", "to": "\"LIME\"", "width": 9.0}, {"description": "\"\u901a\u8fc7SHAP\u5de5\u5177\uff0c\u53ef\u4ee5\u7cfb\u7edf\u5730\u5206\u6790\u7279\u5f81\u5bf9\u9884\u6d4b\u7ed3\u679c\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u4f9b\u5168\u5c40\u548c\u5c40\u90e8\u7684\u53ef\u89e3\u91ca\u6027\u3002\"", "from": "\"\u6a21\u578b\u89e3\u91ca\u6027\"", "keywords": "\"\u5168\u5c40/\u5c40\u90e8\u89e3\u91ca\u6027, \u5f71\u54cd\u8bc4\u4f30\"", "source_id": "chunk-b226b02552d812a52faba8fd5d6a1167", "to": "\"SHAP\"", "width": 10.0}, {"description": "\"\u6301\u7eed\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u91c7\u7528\u5728\u7ebf\u5b66\u4e60\u65b9\u6cd5\u4e0d\u65ad\u66f4\u65b0\u6a21\u578b\u4ee5\u9002\u5e94\u53d8\u5316\u7684\u6570\u636e\u73af\u5883\u3002\"", "from": "\"\u6301\u7eed\u5b66\u4e60\"", "keywords": "\"\u6570\u636e\u66f4\u65b0, \u8fed\u4ee3\u6539\u8fdb\"", "source_id": "chunk-b226b02552d812a52faba8fd5d6a1167", "to": "\"\u5728\u7ebf\u5b66\u4e60\"", "width": 8.0}]);

                  nodeColors = {};
                  allNodes = nodes.get({ returnType: "Object" });
                  for (nodeId in allNodes) {
                    nodeColors[nodeId] = allNodes[nodeId].color;
                  }
                  allEdges = edges.get({ returnType: "Object" });
                  // adding nodes and edges to the graph
                  data = {nodes: nodes, edges: edges};

                  var options = {
    "configure": {
        "enabled": false
    },
    "edges": {
        "color": {
            "inherit": true
        },
        "smooth": {
            "enabled": true,
            "type": "dynamic"
        }
    },
    "interaction": {
        "dragNodes": true,
        "hideEdgesOnDrag": false,
        "hideNodesOnDrag": false
    },
    "physics": {
        "enabled": true,
        "stabilization": {
            "enabled": true,
            "fit": true,
            "iterations": 1000,
            "onlyDynamicEdges": false,
            "updateInterval": 50
        }
    }
};

                  


                  

                  network = new vis.Network(container, data, options);

                  

                  

                  


                  
                      network.on("stabilizationProgress", function(params) {
                          document.getElementById('loadingBar').removeAttribute("style");
                          var maxWidth = 496;
                          var minWidth = 20;
                          var widthFactor = params.iterations/params.total;
                          var width = Math.max(minWidth,maxWidth * widthFactor);
                          document.getElementById('bar').style.width = width + 'px';
                          document.getElementById('text').innerHTML = Math.round(widthFactor*100) + '%';
                      });
                      network.once("stabilizationIterationsDone", function() {
                          document.getElementById('text').innerHTML = '100%';
                          document.getElementById('bar').style.width = '496px';
                          document.getElementById('loadingBar').style.opacity = 0;
                          // really clean the dom element
                          setTimeout(function () {document.getElementById('loadingBar').style.display = 'none';}, 500);
                      });
                  

                  return network;

              }
              drawGraph();
        </script>
    </body>
</html>