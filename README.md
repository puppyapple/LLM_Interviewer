折腾了到今天，终于构建起来一个`AI`面试官的雏形啦。

```bash
https://github.com/puppyapple/LLM_Interviewer
```

在`Cursor`的帮助下，我还给它配了一个**酷炫**（自认为）的`UI`。

话不多说先上效果图：

![UI](https://erxuanyi-1257355350.cos.ap-beijing.myqcloud.com/UI_all-2024-11-07-15-44-41.png)

这里的所有交互可都不是空架子，下面按`UI`来介绍一下我自己设计的一些功能点。

## API选择

目前在代码层实现了以下几个`API`接口的支持：

- `OpenAI`：原生的`OpenAI API`
- `Qwen`：`Qwen`的闭源`API`
- `Azure`：`Azure OpenAI API`
- `Ollama`：`Ollama`的本地`API`（但其实也是用的`OpenAI`的兼容模式）

`API`目前的配置还有些原始，（具体的模型选择以及`API Key`的设置暂时需要在源码的文件中修改），后续会进行优化。
不过这些都是无伤大雅的小问题，不影响使用，重要的还是核心的功能。

## 工作路径

由于整个项目涉及到**本地知识库**以及**简历**等文件的上传，以及构建`RAG`之后的索引还有**交互的部分历史结果**的保存，所以需要一个固定的路径来存储这些数据。

这个文本框就是用来设置这个工作路径的，之后所有的数据都会**自动**在这个路径下建立文件夹保存。

## 本地知识库

接下来是重点功能了，首先是**知识库**的构建。

这个知识库直接服务于`RAG`，但不是用来回答问题，相反地，是用来帮助我们的`AI`面试官生成问题的。

![知识库](https://erxuanyi-1257355350.cos.ap-beijing.myqcloud.com/kb-2024-11-07-16-23-36.png)

### 知识库文件上传

提供两种方式：

- 一种是**点击选择/拖拽文件**上传，也支持**拖拽文件夹**上传。

- 另一种是**输入文件路径**（会递归地读取文件夹下的所有文件）

目前支持的文件类型有：

- `txt`
- `pdf`
- `docx`
- `md`

> 当文件较多的时候推荐使用填写路径的方式，因为前一方式会展示上传文件的列表，很多的时候影响前端页面观感。

### 知识库索引缓存

知识库构建后生成的索引（`RAG`）会缓存到本地，所以如果知识库没有发生变动，下次启动的时候可以选择缓存列表中的索引直接加载。

> 这里为了减小复杂的外部依赖，没有使用任何`ES`或者`Milvus`之类的外部储存，而是用的`In Memory`的存储方式。

索引缓存的根路径是工作路径下的`knowledge_base_indexes`文件夹。

用户可以为将要构建的索引自定义一个**缓存名称**，不设置则默认使用**kb_n**作为缓存名称，`n`为索引的序号。

### 知识库索引构建

设置好缓存相关的参数后，点击**开始构建**按钮即可开始知识库的自动构建过程。

当知识库文件较多的时候，构建的过程可能需要等待一段时间。

（我自己测试的时候用了95个markdown文件，构建了大概2分钟）

⚠️后续的**简历解析**是要依赖知识库的，如果知识库没有更新，那么可以直接在缓存列表中**选择索引加载**而不需要二次构建。

## 简历解析

![简历解析](https://erxuanyi-1257355350.cos.ap-beijing.myqcloud.com/resume-2024-11-07-16-23-04.png)

上传简历后，点击**开始解析**按钮即可开始简历的解析过程。

具体的解析逻辑可以参考之前的两篇文章：

- [不会看简历的AI不是好面试官｜从零手搓AI面试官｜Day05](https://mp.weixin.qq.com/s/GdNS5QHRsSHdVHM9z9lqdg)
- [大模型：就许你们整天找我问问问，逮着机会看我不考死你｜从零手搓AI面试官｜Day06](https://mp.weixin.qq.com/s/GjzQQ5RhWJq9MBmaf_pTyg)

解析的最终结果是生成了一个**面试问题的列表**，这组问题会展示在下面的「问题文件」框中，可以点击进行加载，而不需要重新解析。

⚠️ 后续的**面试**环节中，如果不依赖新的简历，那么可以直接在**问题缓存列表中**选择问题加载，也不需要二次解析。

## 面试

接下来是最至关重要的**面试**交互。

这里其实也很简单，采用了和常规的大模型对话框一样的**对话气泡**的交互方式。

![面试](https://erxuanyi-1257355350.cos.ap-beijing.myqcloud.com/interview_2-2024-11-07-17-30-02.png)

### 点击开始面试

点击**开始面试**按钮后，`AI`面试官会根据上面解析好的问题开始面试。

目前面试的逻辑有以下几种：

- 应试者明确表示不会的题目，`AI`面试官会跳过，并直接进入下一题。
- 大模型评估回答正确的题目，`AI`面试官也会直接进入下一题。
- 大模型评估回答中有错误的话，`AI`面试官会指出错误，并提示用户重新回答。
- 大模型评估回答正确但细节不足的话，`AI`面试官会针对细节进行追问。

⚠️ 当然，这些逻辑都是通过`Prompt`模板来控制的，具体效果完全取决于`Prompt`模板的设计和所用**大模型的能力**。

点击**保存记录**按钮可以讲对话记录保存到`json`文件中并能点击下载。

## 小结一下

自己折腾的这整个项目，算是在很低成本的条件下，实现了一个`AI面试官`的应用雏形。

在这个大体的应用框架下，里面的`Prompt`模板、`RAG`效果、**面试流程**逻辑以及大模型的选择等方面，都有很大的优化空间和定制化空间。

尽管还相当简陋，但在这个过程中我自己对简单的大模型应用构建有了一些自己的理解，可能很初级，但确实是自己一路摸索过来的，希望过程中的东西多上能够给到大家一些帮助和启发。
折腾了到今天，终于构建起来一个`AI`面试官的雏形啦。

```bash
https://github.com/puppyapple/LLM_Interviewer
```

在`Cursor`的帮助下，我还给它配了一个**酷炫**（自认为）的`UI`。

> 前端`UI`的代码`gradio.py`并没有上传到仓库中，有需要的朋友可以付费阅读全文获取（搬砖不易，请多多支持）；
> 不过即使没有`UI`代码，整个项目的核心功能也是完整的。

话不多说先上效果图：

![UI](https://erxuanyi-1257355350.cos.ap-beijing.myqcloud.com/UI_all-2024-11-07-15-44-41.png)

这里的所有交互可都不是空架子，下面按`UI`来介绍一下我自己设计的一些功能点。

## API选择

目前在代码层实现了以下几个`API`接口的支持：

- `OpenAI`：原生的`OpenAI API`
- `Qwen`：`Qwen`的闭源`API`
- `Azure`：`Azure OpenAI API`
- `Ollama`：`Ollama`的本地`API`（但其实也是用的`OpenAI`的兼容模式）

`API`目前的配置还有些原始，（具体的模型选择以及`API Key`的设置暂时需要在源码的文件中修改），后续会进行优化。
不过这些都是无伤大雅的小问题，不影响使用，重要的还是核心的功能。

## 工作路径

由于整个项目涉及到**本地知识库**以及**简历**等文件的上传，以及构建`RAG`之后的索引还有**交互的部分历史结果**的保存，所以需要一个固定的路径来存储这些数据。

这个文本框就是用来设置这个工作路径的，之后所有的数据都会**自动**在这个路径下建立文件夹保存。

## 本地知识库

接下来是重点功能了，首先是**知识库**的构建。

这个知识库直接服务于`RAG`，但不是用来回答问题，相反地，是用来帮助我们的`AI`面试官生成问题的。

![知识库](https://erxuanyi-1257355350.cos.ap-beijing.myqcloud.com/kb-2024-11-07-16-23-36.png)

### 知识库文件上传

提供两种方式：

- 一种是**点击选择/拖拽文件**上传，也支持**拖拽文件夹**上传。

- 另一种是**输入文件路径**（会递归地读取文件夹下的所有文件）

目前支持的文件类型有：

- `txt`
- `pdf`
- `docx`
- `md`

> 当文件较多的时候推荐使用填写路径的方式，因为前一方式会展示上传文件的列表，很多的时候影响前端页面观感。

### 知识库索引缓存

知识库构建后生成的索引（`RAG`）会缓存到本地，所以如果知识库没有发生变动，下次启动的时候可以选择缓存列表中的索引直接加载。

> 这里为了减小复杂的外部依赖，没有使用任何`ES`或者`Milvus`之类的外部储存，而是用的`In Memory`的存储方式。

索引缓存的根路径是工作路径下的`knowledge_base_indexes`文件夹。

用户可以为将要构建的索引自定义一个**缓存名称**，不设置则默认使用**kb_n**作为缓存名称，`n`为索引的序号。

### 知识库索引构建

设置好缓存相关的参数后，点击**开始构建**按钮即可开始知识库的自动构建过程。

当知识库文件较多的时候，构建的过程可能需要等待一段时间。

（我自己测试的时候用了95个markdown文件，构建了大概2分钟）

⚠️后续的**简历解析**是要依赖知识库的，如果知识库没有更新，那么可以直接在缓存列表中**选择索引加载**而不需要二次构建。

## 简历解析

![简历解析](https://erxuanyi-1257355350.cos.ap-beijing.myqcloud.com/resume-2024-11-07-16-23-04.png)

上传简历后，点击**开始解析**按钮即可开始简历的解析过程。

具体的解析逻辑可以参考之前的两篇文章：

- [不会看简历的AI不是好面试官｜从零手搓AI面试官｜Day05](https://mp.weixin.qq.com/s/GdNS5QHRsSHdVHM9z9lqdg)
- [大模型：就许你们整天找我问问问，逮着机会看我不考死你｜从零手搓AI面试官｜Day06](https://mp.weixin.qq.com/s/GjzQQ5RhWJq9MBmaf_pTyg)

解析的最终结果是生成了一个**面试问题的列表**，这组问题会展示在下面的「问题文件」框中，可以点击进行加载，而不需要重新解析。

⚠️ 后续的**面试**环节中，如果不依赖新的简历，那么可以直接在**问题缓存列表中**选择问题加载，也不需要二次解析。

## 面试

接下来是最至关重要的**面试**交互。

这里其实也很简单，采用了和常规的大模型对话框一样的**对话气泡**的交互方式。

![面试](https://erxuanyi-1257355350.cos.ap-beijing.myqcloud.com/interview_2-2024-11-07-17-30-02.png)

### 点击开始面试

点击**开始面试**按钮后，`AI`面试官会根据上面解析好的问题开始面试。

目前面试的逻辑有以下几种：

- 应试者明确表示不会的题目，`AI`面试官会跳过，并直接进入下一题。
- 大模型评估回答正确的题目，`AI`面试官也会直接进入下一题。
- 大模型评估回答中有错误的话，`AI`面试官会指出错误，并提示用户重新回答。
- 大模型评估回答正确但细节不足的话，`AI`面试官会针对细节进行追问。

⚠️ 当然，这些逻辑都是通过`Prompt`模板来控制的，具体效果完全取决于`Prompt`模板的设计和所用**大模型的能力**。

点击**保存记录**按钮可以讲对话记录保存到`json`文件中并能点击下载。

## 小结一下

自己折腾的这整个项目，算是在很低成本的条件下，实现了一个`AI面试官`的应用雏形。

在这个大体的应用框架下，里面的`Prompt`模板、`RAG`效果、**面试流程**逻辑以及大模型的选择等方面，都有很大的优化空间和定制化空间。

尽管还相当简陋，但在这个过程中我自己对简单的大模型应用构建有了一些自己的理解，可能很初级，但确实是自己一路摸索过来的，希望过程中的东西多上能够给到大家一些帮助和启发。
